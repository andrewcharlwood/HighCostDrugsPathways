{"type":"system","subtype":"init","cwd":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign","session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","tools":["Task","TaskOutput","Bash","Glob","Grep","ExitPlanMode","Read","Edit","Write","NotebookEdit","WebFetch","TodoWrite","WebSearch","TaskStop","AskUserQuestion","Skill","EnterPlanMode","ToolSearch","mcp__snowflake-mcp__test_connection","mcp__snowflake-mcp__list_databases","mcp__snowflake-mcp__list_schemas","mcp__snowflake-mcp__list_tables","mcp__snowflake-mcp__list_views","mcp__snowflake-mcp__describe_table","mcp__snowflake-mcp__read_data","mcp__snowflake-mcp__get_system_health","mcp__snowflake-mcp__describe_query","mcp__snowflake-mcp__execute_async","mcp__snowflake-mcp__get_query_status","mcp__snowflake-mcp__get_async_results","mcp__snowflake-mcp__list_async_queries","mcp__snowflake-mcp__read_data_paginated","mcp__snowflake-mcp__read_data_pandas"],"mcp_servers":[{"name":"Context7","status":"failed"},{"name":"snowflake-mcp","status":"connected"}],"model":"claude-opus-4-6","permissionMode":"bypassPermissions","slash_commands":["keybindings-help","debug","frontend-design","sc:analyze","sc:build","sc:cleanup","sc:design","sc:document","sc:estimate","sc:explain","sc:git","sc:implement","sc:improve","sc:index","sc:load","sc:spawn","sc:task","sc:test","sc:troubleshoot","sc:workflow","compact","context","cost","init","pr-comments","release-notes","review","security-review","insights"],"apiKeySource":"none","claude_code_version":"2.1.32","output_style":"default","agents":["Bash","general-purpose","statusline-setup","Explore","Plan","code-reviewer","documentation-specialist","performance-optimizer","medicines-intelligence-analyst","project-analyst","team-configurator","tech-lead-orchestrator","data-scientist","postgres-expert","sql-pro","django-api-developer","django-backend-expert","django-orm-expert","laravel-backend-expert","laravel-eloquent-expert","actix-expert","android-expert","angular-expert","angularjs-expert","ansible-expert","aspnet-core-expert","astro-expert","auth0-expert","ava-expert","braintree-expert","bullmq-expert","bun-expert","c-expert","cassandra-expert","celery-expert","circleci-expert","clojure-expert","cockroachdb-expert","cpp-expert","csharp-expert","css-expert","cypress-expert","dart-expert","deno-expert","django-expert","docker-expert","dynamodb-expert","elasticsearch-expert","electron-expert","elixir-expert","elk-expert","erlang-expert","expo-expert","express-expert","fastapi-expert","fastify-expert","fiber-expert","flask-expert","flutter-expert","flyway-expert","gin-expert","github-actions-expert","gitlab-ci-expert","go-expert","grafana-expert","graphql-expert","grpc-expert","haskell-expert","html-expert","ios-expert","jasmine-expert","java-expert","javascript-expert","jenkins-expert","jest-expert","jquery-expert","jwt-expert","kafka-expert","keycloak-expert","knex-expert","kotlin-expert","kubernetes-expert","langchain-expert","laravel-expert","liquibase-expert","loki-expert","lua-expert","mariadb-expert","mocha-expert","mongodb-expert","mongoose-expert","mqtt-expert","mssql-expert","mysql-expert","nats-expert","neo4j-expert","nestjs-expert","nextjs-expert","nodejs-expert","numpy-expert","oauth-oidc-expert","ocaml-expert","openai-api-expert","openapi-expert","opensearch-expert","opentelemetry-expert","owasp-top10-expert","pandas-expert","perl-expert","phoenix-expert","php-expert","playwright-expert","prisma-expert","prometheus-expert","pulumi-expert","puppeteer-expert","python-expert","pytorch-expert","rabbitmq-expert","rails-expert","react-expert","react-native-expert","redis-expert","remix-expert","rest-expert","rollup-expert","ruby-expert","rust-expert","scala-expert","scikit-learn-expert","selenium-expert","sequelize-expert","sidekiq-expert","sns-expert","solidjs-expert","spring-boot-expert","sql-expert","sqlite-expert","sqs-expert","stripe-expert","svelte-expert","swift-expert","swiftui-expert","tailwind-expert","tauri-expert","tensorflow-expert","terraform-expert","testcafe-expert","trpc-expert","typeorm-expert","typescript-expert","vector-db-expert","vitest-expert","vue-expert","webpack-expert","websocket-expert","rails-activerecord-expert","rails-api-developer","react-component-architect","react-nextjs-expert","vue-component-architect","vue-nuxt-expert","api-architect","backend-developer","frontend-developer","tailwind-frontend-expert"],"skills":["keybindings-help","debug","frontend-design"],"plugins":[],"uuid":"70fb7fb3-a35a-4954-a255-238886012b3e"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01AmHJeFkVboeNcrtAuYLvsq","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nI'll start by reading the required files in order."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":69693,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":69693},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"0194f08b-0e05-4d93-b9d5-d96aa0e6cada"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01AmHJeFkVboeNcrtAuYLvsq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01F4x3S4QUyLD3XGDze33rDL","name":"Read","input":{"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\progress.txt"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":69693,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":69693},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"7550d9fe-2b37-4877-b106-dbc5d1c342be"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01F4x3S4QUyLD3XGDze33rDL","type":"tool_result","content":"     1ÔåÆ# Progress Log - Drug-Aware Indication Matching\n     2ÔåÆ\n     3ÔåÆ## Project Context\n     4ÔåÆ\n     5ÔåÆThis project extends the indication-based pathway charts (Phase 1-5 complete) with drug-aware matching.\n     6ÔåÆ\n     7ÔåÆ**Previous state**: Patients get ONE indication based on their most recent GP diagnosis match (SNOMED cluster codes). This ignores which drugs the patient is taking.\n     8ÔåÆ\n     9ÔåÆ**New goal**: Match each drug to an indication by cross-referencing the patient's GP diagnoses AND the drug's Search_Term mapping from DimSearchTerm.csv.\n    10ÔåÆ\n    11ÔåÆ## Key Data/Patterns\n    12ÔåÆ\n    13ÔåÆ### DimSearchTerm.csv\n    14ÔåÆ- Located at `data/DimSearchTerm.csv`\n    15ÔåÆ- Columns: Search_Term, CleanedDrugName (pipe-separated), PrimaryDirectorate\n    16ÔåÆ- ~165 rows mapping clinical conditions to drug name fragments\n    17ÔåÆ- Drug fragments are substrings that match standardized drug names from HCD data\n    18ÔåÆ- Some entries have generic fragments: INHALED, CONTINUOUS, STANDARD-DOSE, PEGYLATED\n    19ÔåÆ\n    20ÔåÆ### Current get_patient_indication_groups() in diagnosis_lookup.py\n    21ÔåÆ- Uses CLUSTER_MAPPING_SQL as CTE in Snowflake query\n    22ÔåÆ- Returns ONLY the most recent match per patient (QUALIFY ROW_NUMBER() = 1)\n    23ÔåÆ- Needs to return ALL matching Search_Terms per patient (remove QUALIFY)\n    24ÔåÆ- Batches 500 patients per query\n    25ÔåÆ\n    26ÔåÆ### Modified UPID approach\n    27ÔåÆ- Current: UPID = Provider Code[:3] + PersonKey (e.g., \"RMV12345\")\n    28ÔåÆ- New: UPID = original + \"|\" + search_term (e.g., \"RMV12345|rheumatoid arthritis\")\n    29ÔåÆ- The pipe delimiter \"|\" is safe because existing UPIDs are alphanumeric\n    30ÔåÆ- generate_icicle_chart_indication() treats UPID as an opaque identifier ÔÇö modified UPIDs work transparently\n    31ÔåÆ- The \" - \" delimiter in pathway ids is used for hierarchy levels, not within UPIDs\n    32ÔåÆ\n    33ÔåÆ### PseudoNHSNoLinked mapping\n    34ÔåÆ- HCD data has PseudoNHSNoLinked column that matches PatientPseudonym in GP records\n    35ÔåÆ- PersonKey is provider-specific local ID ÔÇö do NOT use for GP matching\n    36ÔåÆ- One PseudoNHSNoLinked can map to multiple UPIDs (multi-provider patients)\n    37ÔåÆ- GP match lookup: PseudoNHSNoLinked ÔåÆ list of matched Search_Terms\n    38ÔåÆ\n    39ÔåÆ### Drug matching logic\n    40ÔåÆ- For each HCD row (UPID + Drug Name):\n    41ÔåÆ  1. Get patient's GP-matched Search_Terms with code_frequency (via PseudoNHSNoLinked)\n    42ÔåÆ  2. Get which Search_Terms list this drug (from DimSearchTerm.csv)\n    43ÔåÆ  3. Intersection = valid indications\n    44ÔåÆ  4. If 1: use it. If multiple: pick highest code_frequency (most GP coding = most likely indication). If 0: fallback to directory.\n    45ÔåÆ- Modified UPID groups drugs under same indication together naturally\n    46ÔåÆ- code_frequency = COUNT(*) of matching SNOMED codes per Search_Term per patient in GP records\n    47ÔåÆ- GP code time range: only count codes from MIN(Intervention Date) onwards (the HCD data window)\n    48ÔåÆ  - Reduces noise from old/irrelevant diagnoses, makes frequency more meaningful\n    49ÔåÆ  - Pass earliest_hcd_date as parameter to get_patient_indication_groups()\n    50ÔåÆ- Tiebreaker rationale: 47 RA codes vs 2 crohn's codes ÔåÆ RA is clearly the active condition\n    51ÔåÆ\n    52ÔåÆ### Known edge cases\n    53ÔåÆ- Some DimSearchTerm drug fragments are generic (INHALED, ORAL, CONTINUOUS)\n    54ÔåÆ  - These could match broadly but are constrained by GP diagnosis requirement\n    55ÔåÆ- A patient visiting multiple providers has multiple UPIDs\n    56ÔåÆ  - Each UPID gets its own drug-indication matching independently\n    57ÔåÆ- Same Search_Term appears twice in DimSearchTerm.csv with different directorates\n    58ÔåÆ  - e.g., \"diabetes\" ÔåÆ DIABETIC MEDICINE and OPHTHALMOLOGY\n    59ÔåÆ  - For indication charts, we use Search_Term not directorate, so this is fine\n    60ÔåÆ\n    61ÔåÆ## Iteration Log\n    62ÔåÆ\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"beac806e-c22e-4aab-a184-a3ce3c94446f","tool_use_result":{"type":"text","file":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\progress.txt","content":"# Progress Log - Drug-Aware Indication Matching\n\n## Project Context\n\nThis project extends the indication-based pathway charts (Phase 1-5 complete) with drug-aware matching.\n\n**Previous state**: Patients get ONE indication based on their most recent GP diagnosis match (SNOMED cluster codes). This ignores which drugs the patient is taking.\n\n**New goal**: Match each drug to an indication by cross-referencing the patient's GP diagnoses AND the drug's Search_Term mapping from DimSearchTerm.csv.\n\n## Key Data/Patterns\n\n### DimSearchTerm.csv\n- Located at `data/DimSearchTerm.csv`\n- Columns: Search_Term, CleanedDrugName (pipe-separated), PrimaryDirectorate\n- ~165 rows mapping clinical conditions to drug name fragments\n- Drug fragments are substrings that match standardized drug names from HCD data\n- Some entries have generic fragments: INHALED, CONTINUOUS, STANDARD-DOSE, PEGYLATED\n\n### Current get_patient_indication_groups() in diagnosis_lookup.py\n- Uses CLUSTER_MAPPING_SQL as CTE in Snowflake query\n- Returns ONLY the most recent match per patient (QUALIFY ROW_NUMBER() = 1)\n- Needs to return ALL matching Search_Terms per patient (remove QUALIFY)\n- Batches 500 patients per query\n\n### Modified UPID approach\n- Current: UPID = Provider Code[:3] + PersonKey (e.g., \"RMV12345\")\n- New: UPID = original + \"|\" + search_term (e.g., \"RMV12345|rheumatoid arthritis\")\n- The pipe delimiter \"|\" is safe because existing UPIDs are alphanumeric\n- generate_icicle_chart_indication() treats UPID as an opaque identifier ÔÇö modified UPIDs work transparently\n- The \" - \" delimiter in pathway ids is used for hierarchy levels, not within UPIDs\n\n### PseudoNHSNoLinked mapping\n- HCD data has PseudoNHSNoLinked column that matches PatientPseudonym in GP records\n- PersonKey is provider-specific local ID ÔÇö do NOT use for GP matching\n- One PseudoNHSNoLinked can map to multiple UPIDs (multi-provider patients)\n- GP match lookup: PseudoNHSNoLinked ÔåÆ list of matched Search_Terms\n\n### Drug matching logic\n- For each HCD row (UPID + Drug Name):\n  1. Get patient's GP-matched Search_Terms with code_frequency (via PseudoNHSNoLinked)\n  2. Get which Search_Terms list this drug (from DimSearchTerm.csv)\n  3. Intersection = valid indications\n  4. If 1: use it. If multiple: pick highest code_frequency (most GP coding = most likely indication). If 0: fallback to directory.\n- Modified UPID groups drugs under same indication together naturally\n- code_frequency = COUNT(*) of matching SNOMED codes per Search_Term per patient in GP records\n- GP code time range: only count codes from MIN(Intervention Date) onwards (the HCD data window)\n  - Reduces noise from old/irrelevant diagnoses, makes frequency more meaningful\n  - Pass earliest_hcd_date as parameter to get_patient_indication_groups()\n- Tiebreaker rationale: 47 RA codes vs 2 crohn's codes ÔåÆ RA is clearly the active condition\n\n### Known edge cases\n- Some DimSearchTerm drug fragments are generic (INHALED, ORAL, CONTINUOUS)\n  - These could match broadly but are constrained by GP diagnosis requirement\n- A patient visiting multiple providers has multiple UPIDs\n  - Each UPID gets its own drug-indication matching independently\n- Same Search_Term appears twice in DimSearchTerm.csv with different directorates\n  - e.g., \"diabetes\" ÔåÆ DIABETIC MEDICINE and OPHTHALMOLOGY\n  - For indication charts, we use Search_Term not directorate, so this is fine\n\n## Iteration Log\n","numLines":62,"startLine":1,"totalLines":62}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01AmHJeFkVboeNcrtAuYLvsq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01H4MUkGEtVTgC4r4KagJZWB","name":"Read","input":{"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":69693,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":69693},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"ab84b832-6d9d-4c56-bfd4-9220ca73acd7"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01H4MUkGEtVTgC4r4KagJZWB","type":"tool_result","content":"     1ÔåÆ# Implementation Plan - Drug-Aware Indication Matching\n     2ÔåÆ\n     3ÔåÆ## Project Overview\n     4ÔåÆ\n     5ÔåÆUpdate the indication-based pathway charts so that patient indications are matched **per drug**, not just per patient. Currently, each patient gets ONE indication (most recent GP diagnosis match). This ignores which drugs the patient is actually taking.\n     6ÔåÆ\n     7ÔåÆ### The Problem\n     8ÔåÆ\n     9ÔåÆA patient on ADALIMUMAB + OMALIZUMAB currently gets assigned a single indication (e.g., \"rheumatoid arthritis\" ÔÇö the most recent GP match). But:\n    10ÔåÆ- ADALIMUMAB is used for rheumatoid arthritis, axial spondyloarthritis, crohn's disease, etc.\n    11ÔåÆ- OMALIZUMAB is used for asthma, allergic asthma, urticaria\n    12ÔåÆ\n    13ÔåÆThese are different clinical pathways and should be treated as separate treatment journeys.\n    14ÔåÆ\n    15ÔåÆ### The Solution\n    16ÔåÆ\n    17ÔåÆMatch each drug to an indication by cross-referencing:\n    18ÔåÆ1. **GP diagnosis** ÔÇö which Search_Terms the patient has matching SNOMED codes for\n    19ÔåÆ2. **Drug mapping** ÔÇö which Search_Terms list each drug (from `DimSearchTerm.csv`)\n    20ÔåÆ\n    21ÔåÆOnly assign a drug to an indication if BOTH conditions are met. If a patient's drugs map to different indications, they become separate pathways (via modified UPID).\n    22ÔåÆ\n    23ÔåÆ### Key Design Decisions\n    24ÔåÆ\n    25ÔåÆ| Aspect | Decision |\n    26ÔåÆ|--------|----------|\n    27ÔåÆ| Drug-indication source | `data/DimSearchTerm.csv` ÔÇö Search_Term ÔåÆ CleanedDrugName mapping |\n    28ÔåÆ| UPID modification | `{original_UPID}\\|{search_term}` for drugs with matched indication |\n    29ÔåÆ| GP diagnosis matching | Return ALL matches per patient (not just most recent) |\n    30ÔåÆ| Drug matching | Substring match: HCD drug name contains DimSearchTerm fragment |\n    31ÔåÆ| Multiple indication matches per drug | Use highest GP code frequency as tiebreaker (COUNT of matching SNOMED codes per Search_Term) |\n    32ÔåÆ| GP code time range | Only codes from MIN(Intervention Date) onwards ÔÇö restricts to HCD data window |\n    33ÔåÆ| No indication match | Fallback to directory (same as current behavior) |\n    34ÔåÆ| Same patient, different indications | Separate pathways via different modified UPIDs |\n    35ÔåÆ\n    36ÔåÆ### Examples\n    37ÔåÆ\n    38ÔåÆ**Patient on ADALIMUMAB + GOLIMUMAB, GP dx: axial spondyloarthritis + asthma**\n    39ÔåÆ- axial spondyloarthritis drug list includes both ADALIMUMAB and GOLIMUMAB\n    40ÔåÆ- ÔåÆ Both drugs grouped under \"axial spondyloarthritis\", single pathway\n    41ÔåÆ- Modified UPID: `RMV12345|axial spondyloarthritis`\n    42ÔåÆ\n    43ÔåÆ**Patient on ADALIMUMAB + OMALIZUMAB, GP dx: axial spondyloarthritis + asthma**\n    44ÔåÆ- axial spondyloarthritis lists ADALIMUMAB but not OMALIZUMAB\n    45ÔåÆ- asthma lists OMALIZUMAB but not ADALIMUMAB\n    46ÔåÆ- ÔåÆ Two separate pathways:\n    47ÔåÆ  - `RMV12345|axial spondyloarthritis` with ADALIMUMAB\n    48ÔåÆ  - `RMV12345|asthma` with OMALIZUMAB\n    49ÔåÆ\n    50ÔåÆ**Patient on ADALIMUMAB, GP dx: rheumatoid arthritis (47 codes) + crohn's disease (2 codes)**\n    51ÔåÆ- Both Search_Terms list ADALIMUMAB AND patient has GP dx for both\n    52ÔåÆ- ÔåÆ Tiebreaker: highest code frequency ÔÇö rheumatoid arthritis has 47 matching SNOMED codes vs 2 for crohn's\n    53ÔåÆ- ÔåÆ Single pathway under rheumatoid arthritis (more clinical activity = more likely the treatment indication)\n    54ÔåÆ\n    55ÔåÆ---\n    56ÔåÆ\n    57ÔåÆ## Phase 1: Update Snowflake Query & Drug Mapping\n    58ÔåÆ\n    59ÔåÆ### 1.1 Update `get_patient_indication_groups()` to return ALL matches with frequency\n    60ÔåÆ- [ ] Modify the Snowflake query in `get_patient_indication_groups()` (diagnosis_lookup.py):\n    61ÔåÆ  - Remove `QUALIFY ROW_NUMBER() OVER (PARTITION BY ... ORDER BY EventDateTime DESC) = 1`\n    62ÔåÆ  - Return ALL matching Search_Terms per patient with code frequency:\n    63ÔåÆ    ```sql\n    64ÔåÆ    SELECT pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n    65ÔåÆ           aic.Search_Term AS \"Search_Term\",\n    66ÔåÆ           COUNT(*) AS \"code_frequency\"\n    67ÔåÆ    FROM PrimaryCareClinicalCoding pc\n    68ÔåÆ    JOIN AllIndicationCodes aic ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\n    69ÔåÆ    WHERE pc.\"PatientPseudonym\" IN (...)\n    70ÔåÆ      AND pc.\"EventDateTime\" >= :earliest_hcd_date\n    71ÔåÆ    GROUP BY pc.\"PatientPseudonym\", aic.Search_Term\n    72ÔåÆ    ```\n    73ÔåÆ  - `code_frequency` = number of matching SNOMED codes per Search_Term per patient\n    74ÔåÆ  - Higher frequency = more clinical activity = stronger signal for tiebreaker\n    75ÔåÆ  - `earliest_hcd_date` = `MIN(Intervention Date)` from the HCD DataFrame ÔÇö restricts GP codes to the HCD data window, reducing noise from old/irrelevant diagnoses\n    76ÔåÆ- [ ] Accept `earliest_hcd_date` parameter in `get_patient_indication_groups()` and pass to query\n    77ÔåÆ- [ ] Keep batch processing (500 patients per query)\n    78ÔåÆ- [ ] Update return type: DataFrame now has multiple rows per patient (PatientPseudonym, Search_Term, code_frequency)\n    79ÔåÆ- [ ] Verify: Query returns more rows than before (patients with multiple matching diagnoses)\n    80ÔåÆ\n    81ÔåÆ### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n    82ÔåÆ- [ ] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n    83ÔåÆ  - Loads `data/DimSearchTerm.csv`\n    84ÔåÆ  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n    85ÔåÆ  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n    86ÔåÆ  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n    87ÔåÆ- [ ] Add function `drug_matches_search_term(drug_name: str, search_term: str, mapping: dict) -> bool`:\n    88ÔåÆ  - Checks if the drug name matches any fragment in the Search_Term's drug list\n    89ÔåÆ  - Match logic: any fragment from DimSearchTerm is a substring of the drug name (case-insensitive)\n    90ÔåÆ- [ ] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"\n    91ÔåÆ\n    92ÔåÆ---\n    93ÔåÆ\n    94ÔåÆ## Phase 2: Drug-Aware Indication Matching Logic\n    95ÔåÆ\n    96ÔåÆ### 2.1 Create `assign_drug_indications()` function\n    97ÔåÆ- [ ] Add to `diagnosis_lookup.py` or `pathway_pipeline.py`:\n    98ÔåÆ  ```\n    99ÔåÆ  def assign_drug_indications(\n   100ÔåÆ      df: pd.DataFrame,              # HCD data with UPID, Drug Name columns\n   101ÔåÆ      gp_matches_df: pd.DataFrame,   # PatientPseudonym ÔåÆ list of matched Search_Terms\n   102ÔåÆ      drug_mapping: dict,             # From load_drug_indication_mapping()\n   103ÔåÆ  ) -> tuple[pd.DataFrame, pd.DataFrame]:\n   104ÔåÆ      Returns: (modified_df, indication_df)\n   105ÔåÆ      - modified_df: HCD data with UPID replaced by {UPID}|{indication}\n   106ÔåÆ      - indication_df: mapping modified_UPID ÔåÆ Search_Term\n   107ÔåÆ  ```\n   108ÔåÆ- [ ] Logic per UPID + Drug Name pair:\n   109ÔåÆ  1. Get patient's GP-matched Search_Terms with code_frequency (from gp_matches_df via PseudoNHSNoLinked)\n   110ÔåÆ  2. Get which Search_Terms include this drug (from drug_mapping)\n   111ÔåÆ  3. Intersection = valid indications for this drug-patient pair\n   112ÔåÆ  4. If 1 match: use it\n   113ÔåÆ  5. If multiple matches: use highest code_frequency as tiebreaker (most GP coding activity = most likely treatment indication)\n   114ÔåÆ  6. If 0 matches: use fallback directory\n   115ÔåÆ- [ ] Modify UPID in df rows: `{original_UPID}|{matched_search_term}`\n   116ÔåÆ- [ ] Build indication_df: `{modified_UPID}` ÔåÆ `Search_Term` (or fallback label)\n   117ÔåÆ- [ ] Verify: Function compiles, handles edge cases (no GP match, no drug match)\n   118ÔåÆ\n   119ÔåÆ### 2.2 Handle tiebreaker for multiple indication matches\n   120ÔåÆ- [ ] When a drug matches multiple Search_Terms AND patient has GP dx for multiple:\n   121ÔåÆ  - Use `code_frequency` from the GP query (COUNT of matching SNOMED codes per Search_Term)\n   122ÔåÆ  - Higher code_frequency = more clinical activity for that condition = more likely treatment indication\n   123ÔåÆ  - E.g., patient with 47 RA codes and 2 crohn's codes ÔåÆ ADALIMUMAB assigned to RA\n   124ÔåÆ  - code_frequency is already returned by the updated query in Task 1.1\n   125ÔåÆ- [ ] Verify: Tiebreaker logic correctly picks highest-frequency diagnosis\n   126ÔåÆ- [ ] Verify: Tie on frequency (rare but possible) falls back to alphabetical Search_Term for determinism\n   127ÔåÆ\n   128ÔåÆ---\n   129ÔåÆ\n   130ÔåÆ## Phase 3: Pipeline Integration\n   131ÔåÆ\n   132ÔåÆ### 3.1 Update `refresh_pathways.py` indication processing\n   133ÔåÆ- [ ] In the `elif current_chart_type == \"indication\":` block:\n   134ÔåÆ  1. Call `get_patient_indication_groups()` as before (but now returns ALL matches)\n   135ÔåÆ  2. Load drug mapping: `drug_mapping = load_drug_indication_mapping()`\n   136ÔåÆ  3. Call `assign_drug_indications(df, gp_matches_df, drug_mapping)`\n   137ÔåÆ  4. Use modified_df (with indication-aware UPIDs) for pathway processing\n   138ÔåÆ  5. Use indication_df for the indication mapping\n   139ÔåÆ- [ ] Pass modified_df (not original df) to `process_indication_pathway_for_date_filter()`\n   140ÔåÆ- [ ] Verify: Pipeline compiles, `python -m py_compile cli/refresh_pathways.py`\n   141ÔåÆ\n   142ÔåÆ### 3.2 Test with dry run\n   143ÔåÆ- [ ] Run `python -m cli.refresh_pathways --chart-type indication --dry-run -v`\n   144ÔåÆ- [ ] Verify:\n   145ÔåÆ  - Modified UPIDs appear in pipeline log (e.g., `RMV12345|rheumatoid arthritis`)\n   146ÔåÆ  - Patient counts are reasonable (will be higher than before since same patient can appear under multiple indications)\n   147ÔåÆ  - Drug-indication matching is logged (match rate, fallback rate)\n   148ÔåÆ  - Pathway hierarchy shows drug-specific grouping under correct indications\n   149ÔåÆ\n   150ÔåÆ---\n   151ÔåÆ\n   152ÔåÆ## Phase 4: Full Refresh & Validation\n   153ÔåÆ\n   154ÔåÆ### 4.1 Full refresh with both chart types\n   155ÔåÆ- [ ] Run `python -m cli.refresh_pathways --chart-type all`\n   156ÔåÆ- [ ] Verify:\n   157ÔåÆ  - Both chart types generate data\n   158ÔåÆ  - Directory charts unchanged (no modified UPIDs)\n   159ÔåÆ  - Indication charts reflect drug-aware matching\n   160ÔåÆ\n   161ÔåÆ### 4.2 Validate indication chart correctness\n   162ÔåÆ- [ ] Check that drugs under an indication all appear in that Search_Term's drug list\n   163ÔåÆ- [ ] Verify that a patient on drugs for different indications creates separate pathway branches\n   164ÔåÆ- [ ] Verify that drugs sharing an indication are grouped in the same pathway\n   165ÔåÆ- [ ] Log: patient count comparison (old vs new approach)\n   166ÔåÆ\n   167ÔåÆ### 4.3 Validate Reflex UI\n   168ÔåÆ- [ ] Run `python -m reflex compile` to verify app compiles\n   169ÔåÆ- [ ] Verify chart type toggle still works\n   170ÔåÆ- [ ] Verify indication chart shows correct hierarchy\n   171ÔåÆ\n   172ÔåÆ---\n   173ÔåÆ\n   174ÔåÆ## Completion Criteria\n   175ÔåÆ\n   176ÔåÆAll tasks marked `[x]` AND:\n   177ÔåÆ- [ ] App compiles without errors (`reflex compile` succeeds)\n   178ÔåÆ- [ ] Both chart types generate pathway data\n   179ÔåÆ- [ ] Indication charts show drug-specific indication matching\n   180ÔåÆ- [ ] Drugs under the same indication for the same patient are in one pathway\n   181ÔåÆ- [ ] Drugs under different indications for the same patient create separate pathways\n   182ÔåÆ- [ ] Fallback works for drugs with no indication match\n   183ÔåÆ- [ ] Full refresh completes successfully\n   184ÔåÆ- [ ] Existing directory charts are unaffected\n   185ÔåÆ\n   186ÔåÆ---\n   187ÔåÆ\n   188ÔåÆ## Reference\n   189ÔåÆ\n   190ÔåÆ### DimSearchTerm.csv Structure\n   191ÔåÆ```\n   192ÔåÆSearch_Term,CleanedDrugName,PrimaryDirectorate\n   193ÔåÆrheumatoid arthritis,ABATACEPT|ADALIMUMAB|ANAKINRA|BARICITINIB|...,RHEUMATOLOGY\n   194ÔåÆasthma,BENRALIZUMAB|DUPILUMAB|INHALED|MEPOLIZUMAB|OMALIZUMAB|RESLIZUMAB,THORACIC MEDICINE\n   195ÔåÆ```\n   196ÔåÆ\n   197ÔåÆ### Modified UPID Format\n   198ÔåÆ```\n   199ÔåÆOriginal:  RMV12345\n   200ÔåÆModified:  RMV12345|rheumatoid arthritis\n   201ÔåÆFallback:  RMV12345|RHEUMATOLOGY (no GP dx)\n   202ÔåÆ```\n   203ÔåÆ\n   204ÔåÆ### Current vs New Indication Flow\n   205ÔåÆ```\n   206ÔåÆCURRENT:\n   207ÔåÆ  Patient ÔåÆ GP dx (most recent) ÔåÆ single Search_Term ÔåÆ one pathway\n   208ÔåÆ\n   209ÔåÆNEW:\n   210ÔåÆ  Patient + Drug A ÔåÆ GP dx matching Drug A ÔåÆ Search_Term X\n   211ÔåÆ  Patient + Drug B ÔåÆ GP dx matching Drug B ÔåÆ Search_Term Y\n   212ÔåÆ  ÔåÆ If X == Y: one pathway under X\n   213ÔåÆ  ÔåÆ If X != Y: two pathways (modified UPIDs)\n   214ÔåÆ```\n   215ÔåÆ\n   216ÔåÆ### Key Files\n   217ÔåÆ\n   218ÔåÆ| File | Changes |\n   219ÔåÆ|------|---------|\n   220ÔåÆ| `data_processing/diagnosis_lookup.py` | Update query, add drug mapping functions |\n   221ÔåÆ| `data_processing/pathway_pipeline.py` | Possibly minor changes for modified UPIDs |\n   222ÔåÆ| `cli/refresh_pathways.py` | Integrate drug-aware matching into pipeline |\n   223ÔåÆ| `data/DimSearchTerm.csv` | Reference data (read-only) |\n   224ÔåÆ| `analysis/pathway_analyzer.py` | No changes expected (UPID changes are transparent) |\n   225ÔåÆ| `pathways_app/pathways_app.py` | No changes expected |\n   226ÔåÆ\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"74e2d991-28c6-4518-b9ab-018ee80ffe2b","tool_use_result":{"type":"text","file":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md","content":"# Implementation Plan - Drug-Aware Indication Matching\n\n## Project Overview\n\nUpdate the indication-based pathway charts so that patient indications are matched **per drug**, not just per patient. Currently, each patient gets ONE indication (most recent GP diagnosis match). This ignores which drugs the patient is actually taking.\n\n### The Problem\n\nA patient on ADALIMUMAB + OMALIZUMAB currently gets assigned a single indication (e.g., \"rheumatoid arthritis\" ÔÇö the most recent GP match). But:\n- ADALIMUMAB is used for rheumatoid arthritis, axial spondyloarthritis, crohn's disease, etc.\n- OMALIZUMAB is used for asthma, allergic asthma, urticaria\n\nThese are different clinical pathways and should be treated as separate treatment journeys.\n\n### The Solution\n\nMatch each drug to an indication by cross-referencing:\n1. **GP diagnosis** ÔÇö which Search_Terms the patient has matching SNOMED codes for\n2. **Drug mapping** ÔÇö which Search_Terms list each drug (from `DimSearchTerm.csv`)\n\nOnly assign a drug to an indication if BOTH conditions are met. If a patient's drugs map to different indications, they become separate pathways (via modified UPID).\n\n### Key Design Decisions\n\n| Aspect | Decision |\n|--------|----------|\n| Drug-indication source | `data/DimSearchTerm.csv` ÔÇö Search_Term ÔåÆ CleanedDrugName mapping |\n| UPID modification | `{original_UPID}\\|{search_term}` for drugs with matched indication |\n| GP diagnosis matching | Return ALL matches per patient (not just most recent) |\n| Drug matching | Substring match: HCD drug name contains DimSearchTerm fragment |\n| Multiple indication matches per drug | Use highest GP code frequency as tiebreaker (COUNT of matching SNOMED codes per Search_Term) |\n| GP code time range | Only codes from MIN(Intervention Date) onwards ÔÇö restricts to HCD data window |\n| No indication match | Fallback to directory (same as current behavior) |\n| Same patient, different indications | Separate pathways via different modified UPIDs |\n\n### Examples\n\n**Patient on ADALIMUMAB + GOLIMUMAB, GP dx: axial spondyloarthritis + asthma**\n- axial spondyloarthritis drug list includes both ADALIMUMAB and GOLIMUMAB\n- ÔåÆ Both drugs grouped under \"axial spondyloarthritis\", single pathway\n- Modified UPID: `RMV12345|axial spondyloarthritis`\n\n**Patient on ADALIMUMAB + OMALIZUMAB, GP dx: axial spondyloarthritis + asthma**\n- axial spondyloarthritis lists ADALIMUMAB but not OMALIZUMAB\n- asthma lists OMALIZUMAB but not ADALIMUMAB\n- ÔåÆ Two separate pathways:\n  - `RMV12345|axial spondyloarthritis` with ADALIMUMAB\n  - `RMV12345|asthma` with OMALIZUMAB\n\n**Patient on ADALIMUMAB, GP dx: rheumatoid arthritis (47 codes) + crohn's disease (2 codes)**\n- Both Search_Terms list ADALIMUMAB AND patient has GP dx for both\n- ÔåÆ Tiebreaker: highest code frequency ÔÇö rheumatoid arthritis has 47 matching SNOMED codes vs 2 for crohn's\n- ÔåÆ Single pathway under rheumatoid arthritis (more clinical activity = more likely the treatment indication)\n\n---\n\n## Phase 1: Update Snowflake Query & Drug Mapping\n\n### 1.1 Update `get_patient_indication_groups()` to return ALL matches with frequency\n- [ ] Modify the Snowflake query in `get_patient_indication_groups()` (diagnosis_lookup.py):\n  - Remove `QUALIFY ROW_NUMBER() OVER (PARTITION BY ... ORDER BY EventDateTime DESC) = 1`\n  - Return ALL matching Search_Terms per patient with code frequency:\n    ```sql\n    SELECT pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n           aic.Search_Term AS \"Search_Term\",\n           COUNT(*) AS \"code_frequency\"\n    FROM PrimaryCareClinicalCoding pc\n    JOIN AllIndicationCodes aic ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\n    WHERE pc.\"PatientPseudonym\" IN (...)\n      AND pc.\"EventDateTime\" >= :earliest_hcd_date\n    GROUP BY pc.\"PatientPseudonym\", aic.Search_Term\n    ```\n  - `code_frequency` = number of matching SNOMED codes per Search_Term per patient\n  - Higher frequency = more clinical activity = stronger signal for tiebreaker\n  - `earliest_hcd_date` = `MIN(Intervention Date)` from the HCD DataFrame ÔÇö restricts GP codes to the HCD data window, reducing noise from old/irrelevant diagnoses\n- [ ] Accept `earliest_hcd_date` parameter in `get_patient_indication_groups()` and pass to query\n- [ ] Keep batch processing (500 patients per query)\n- [ ] Update return type: DataFrame now has multiple rows per patient (PatientPseudonym, Search_Term, code_frequency)\n- [ ] Verify: Query returns more rows than before (patients with multiple matching diagnoses)\n\n### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [ ] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`\n  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n- [ ] Add function `drug_matches_search_term(drug_name: str, search_term: str, mapping: dict) -> bool`:\n  - Checks if the drug name matches any fragment in the Search_Term's drug list\n  - Match logic: any fragment from DimSearchTerm is a substring of the drug name (case-insensitive)\n- [ ] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"\n\n---\n\n## Phase 2: Drug-Aware Indication Matching Logic\n\n### 2.1 Create `assign_drug_indications()` function\n- [ ] Add to `diagnosis_lookup.py` or `pathway_pipeline.py`:\n  ```\n  def assign_drug_indications(\n      df: pd.DataFrame,              # HCD data with UPID, Drug Name columns\n      gp_matches_df: pd.DataFrame,   # PatientPseudonym ÔåÆ list of matched Search_Terms\n      drug_mapping: dict,             # From load_drug_indication_mapping()\n  ) -> tuple[pd.DataFrame, pd.DataFrame]:\n      Returns: (modified_df, indication_df)\n      - modified_df: HCD data with UPID replaced by {UPID}|{indication}\n      - indication_df: mapping modified_UPID ÔåÆ Search_Term\n  ```\n- [ ] Logic per UPID + Drug Name pair:\n  1. Get patient's GP-matched Search_Terms with code_frequency (from gp_matches_df via PseudoNHSNoLinked)\n  2. Get which Search_Terms include this drug (from drug_mapping)\n  3. Intersection = valid indications for this drug-patient pair\n  4. If 1 match: use it\n  5. If multiple matches: use highest code_frequency as tiebreaker (most GP coding activity = most likely treatment indication)\n  6. If 0 matches: use fallback directory\n- [ ] Modify UPID in df rows: `{original_UPID}|{matched_search_term}`\n- [ ] Build indication_df: `{modified_UPID}` ÔåÆ `Search_Term` (or fallback label)\n- [ ] Verify: Function compiles, handles edge cases (no GP match, no drug match)\n\n### 2.2 Handle tiebreaker for multiple indication matches\n- [ ] When a drug matches multiple Search_Terms AND patient has GP dx for multiple:\n  - Use `code_frequency` from the GP query (COUNT of matching SNOMED codes per Search_Term)\n  - Higher code_frequency = more clinical activity for that condition = more likely treatment indication\n  - E.g., patient with 47 RA codes and 2 crohn's codes ÔåÆ ADALIMUMAB assigned to RA\n  - code_frequency is already returned by the updated query in Task 1.1\n- [ ] Verify: Tiebreaker logic correctly picks highest-frequency diagnosis\n- [ ] Verify: Tie on frequency (rare but possible) falls back to alphabetical Search_Term for determinism\n\n---\n\n## Phase 3: Pipeline Integration\n\n### 3.1 Update `refresh_pathways.py` indication processing\n- [ ] In the `elif current_chart_type == \"indication\":` block:\n  1. Call `get_patient_indication_groups()` as before (but now returns ALL matches)\n  2. Load drug mapping: `drug_mapping = load_drug_indication_mapping()`\n  3. Call `assign_drug_indications(df, gp_matches_df, drug_mapping)`\n  4. Use modified_df (with indication-aware UPIDs) for pathway processing\n  5. Use indication_df for the indication mapping\n- [ ] Pass modified_df (not original df) to `process_indication_pathway_for_date_filter()`\n- [ ] Verify: Pipeline compiles, `python -m py_compile cli/refresh_pathways.py`\n\n### 3.2 Test with dry run\n- [ ] Run `python -m cli.refresh_pathways --chart-type indication --dry-run -v`\n- [ ] Verify:\n  - Modified UPIDs appear in pipeline log (e.g., `RMV12345|rheumatoid arthritis`)\n  - Patient counts are reasonable (will be higher than before since same patient can appear under multiple indications)\n  - Drug-indication matching is logged (match rate, fallback rate)\n  - Pathway hierarchy shows drug-specific grouping under correct indications\n\n---\n\n## Phase 4: Full Refresh & Validation\n\n### 4.1 Full refresh with both chart types\n- [ ] Run `python -m cli.refresh_pathways --chart-type all`\n- [ ] Verify:\n  - Both chart types generate data\n  - Directory charts unchanged (no modified UPIDs)\n  - Indication charts reflect drug-aware matching\n\n### 4.2 Validate indication chart correctness\n- [ ] Check that drugs under an indication all appear in that Search_Term's drug list\n- [ ] Verify that a patient on drugs for different indications creates separate pathway branches\n- [ ] Verify that drugs sharing an indication are grouped in the same pathway\n- [ ] Log: patient count comparison (old vs new approach)\n\n### 4.3 Validate Reflex UI\n- [ ] Run `python -m reflex compile` to verify app compiles\n- [ ] Verify chart type toggle still works\n- [ ] Verify indication chart shows correct hierarchy\n\n---\n\n## Completion Criteria\n\nAll tasks marked `[x]` AND:\n- [ ] App compiles without errors (`reflex compile` succeeds)\n- [ ] Both chart types generate pathway data\n- [ ] Indication charts show drug-specific indication matching\n- [ ] Drugs under the same indication for the same patient are in one pathway\n- [ ] Drugs under different indications for the same patient create separate pathways\n- [ ] Fallback works for drugs with no indication match\n- [ ] Full refresh completes successfully\n- [ ] Existing directory charts are unaffected\n\n---\n\n## Reference\n\n### DimSearchTerm.csv Structure\n```\nSearch_Term,CleanedDrugName,PrimaryDirectorate\nrheumatoid arthritis,ABATACEPT|ADALIMUMAB|ANAKINRA|BARICITINIB|...,RHEUMATOLOGY\nasthma,BENRALIZUMAB|DUPILUMAB|INHALED|MEPOLIZUMAB|OMALIZUMAB|RESLIZUMAB,THORACIC MEDICINE\n```\n\n### Modified UPID Format\n```\nOriginal:  RMV12345\nModified:  RMV12345|rheumatoid arthritis\nFallback:  RMV12345|RHEUMATOLOGY (no GP dx)\n```\n\n### Current vs New Indication Flow\n```\nCURRENT:\n  Patient ÔåÆ GP dx (most recent) ÔåÆ single Search_Term ÔåÆ one pathway\n\nNEW:\n  Patient + Drug A ÔåÆ GP dx matching Drug A ÔåÆ Search_Term X\n  Patient + Drug B ÔåÆ GP dx matching Drug B ÔåÆ Search_Term Y\n  ÔåÆ If X == Y: one pathway under X\n  ÔåÆ If X != Y: two pathways (modified UPIDs)\n```\n\n### Key Files\n\n| File | Changes |\n|------|---------|\n| `data_processing/diagnosis_lookup.py` | Update query, add drug mapping functions |\n| `data_processing/pathway_pipeline.py` | Possibly minor changes for modified UPIDs |\n| `cli/refresh_pathways.py` | Integrate drug-aware matching into pipeline |\n| `data/DimSearchTerm.csv` | Reference data (read-only) |\n| `analysis/pathway_analyzer.py` | No changes expected (UPID changes are transparent) |\n| `pathways_app/pathways_app.py` | No changes expected |\n","numLines":226,"startLine":1,"totalLines":226}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01AmHJeFkVboeNcrtAuYLvsq","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01QmDa9ndnDcgrx2HvD33Pcx","name":"Read","input":{"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\guardrails.md"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":69693,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":69693},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"79721215-dee0-4ea6-9ce3-57b42867aa29"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01QmDa9ndnDcgrx2HvD33Pcx","type":"tool_result","content":"     1ÔåÆ# Guardrails\n     2ÔåÆ\n     3ÔåÆKnown failure patterns. Read EVERY iteration. Follow ALL of these rules.\n     4ÔåÆIf you discover a new failure pattern during your work, add it to this file.\n     5ÔåÆ\n     6ÔåÆ---\n     7ÔåÆ\n     8ÔåÆ## Drug-Indication Matching Guardrails\n     9ÔåÆ\n    10ÔåÆ### Match drugs to indications, not just patients to indications\n    11ÔåÆ- **When**: Building the indication mapping for pathway charts\n    12ÔåÆ- **Rule**: Each drug must be validated against BOTH the patient's GP diagnoses AND the drug-to-indication mapping from DimSearchTerm.csv. A patient being diagnosed with rheumatoid arthritis does NOT mean all their drugs are for rheumatoid arthritis.\n    13ÔåÆ- **Why**: The previous approach assigned ONE indication per patient (most recent GP dx), ignoring which drugs actually treat which conditions. This produced misleading pathways.\n    14ÔåÆ\n    15ÔåÆ### Use DimSearchTerm.csv for drug-to-Search_Term mapping\n    16ÔåÆ- **When**: Determining which Search_Term a drug belongs to\n    17ÔåÆ- **Rule**: Load `data/DimSearchTerm.csv`. The `CleanedDrugName` column has pipe-separated drug name fragments. Match HCD drug names against these fragments using substring matching (case-insensitive).\n    18ÔåÆ- **Why**: This CSV is the authoritative mapping of which drugs are used for which clinical indications.\n    19ÔåÆ\n    20ÔåÆ### Use substring matching for drug fragments\n    21ÔåÆ- **When**: Matching HCD drug names against DimSearchTerm CleanedDrugName fragments\n    22ÔåÆ- **Rule**: Check if any fragment from DimSearchTerm is a SUBSTRING of the HCD drug name (case-insensitive). E.g., \"PEGYLATED\" should match \"PEGYLATED LIPOSOMAL DOXORUBICIN\".\n    23ÔåÆ- **Why**: DimSearchTerm contains both full drug names (ADALIMUMAB) and partial fragments (PEGYLATED, INHALED). Exact match would miss the partial ones.\n    24ÔåÆ\n    25ÔåÆ### Modified UPID uses pipe delimiter\n    26ÔåÆ- **When**: Creating indication-aware UPIDs\n    27ÔåÆ- **Rule**: Format is `{original_UPID}|{search_term}`. Use pipe `|` as delimiter. Do NOT use ` - ` (hyphen with spaces) as that's used for pathway hierarchy levels in the `ids` column.\n    28ÔåÆ- **Why**: The `ids` column uses \" - \" to separate hierarchy levels (e.g., \"N&WICS - NNUH - rheumatoid arthritis - ADALIMUMAB\"). Using the same delimiter in UPIDs would break hierarchy parsing.\n    29ÔåÆ\n    30ÔåÆ### Return ALL GP matches per patient, not just most recent\n    31ÔåÆ- **When**: Querying Snowflake for patient GP diagnoses\n    32ÔåÆ- **Rule**: Remove `QUALIFY ROW_NUMBER() OVER (PARTITION BY ... ORDER BY EventDateTime DESC) = 1`. Return ALL matching Search_Terms per patient with `GROUP BY + COUNT(*)` for code_frequency.\n    33ÔåÆ- **Why**: A patient may have GP diagnoses for both rheumatoid arthritis AND asthma. We need ALL matches to cross-reference with their drugs.\n    34ÔåÆ\n    35ÔåÆ### Restrict GP code lookup to HCD data window\n    36ÔåÆ- **When**: Building the WHERE clause for the GP record query\n    37ÔåÆ- **Rule**: Add `AND pc.\"EventDateTime\" >= :earliest_hcd_date` where `earliest_hcd_date` is `MIN(Intervention Date)` from the HCD DataFrame. Pass this as a parameter to `get_patient_indication_groups()`.\n    38ÔåÆ- **Why**: Old GP codes from years before treatment started add noise. A diagnosis coded 10 years ago may no longer be relevant. Restricting to the HCD window ensures code_frequency reflects recent clinical activity for the conditions being actively treated.\n    39ÔåÆ\n    40ÔåÆ### Tiebreaker: highest GP code frequency when a drug matches multiple indications\n    41ÔåÆ- **When**: A single drug maps to multiple Search_Terms AND the patient has GP dx for multiple\n    42ÔåÆ- **Rule**: Use `code_frequency` (COUNT of matching SNOMED codes per Search_Term per patient) from the GP query. The Search_Term with the most matching codes in the patient's GP record wins. If tied, use alphabetical Search_Term for determinism.\n    43ÔåÆ- **Why**: E.g., ADALIMUMAB is listed under rheumatoid arthritis, crohn's disease, psoriatic arthritis, etc. A patient with 47 RA codes and 2 crohn's codes is almost certainly on ADALIMUMAB for RA. Frequency of GP coding is a much stronger signal of clinical intent than recency ÔÇö a recent one-off asthma check doesn't mean ADALIMUMAB is for asthma.\n    44ÔåÆ\n    45ÔåÆ### Same patient, different indications = separate modified UPIDs\n    46ÔåÆ- **When**: A patient's drugs map to different Search_Terms\n    47ÔåÆ- **Rule**: Create separate modified UPIDs for each indication. E.g., `RMV12345|rheumatoid arthritis` and `RMV12345|asthma`. These are treated as separate \"patients\" by the pathway analyzer.\n    48ÔåÆ- **Why**: This is the core design ÔÇö drugs for different indications should create separate treatment pathways, even for the same physical patient.\n    49ÔåÆ\n    50ÔåÆ### Fallback to directory for unmatched drugs\n    51ÔåÆ- **When**: A drug doesn't match any Search_Term OR the patient has no GP dx for any of the drug's Search_Terms\n    52ÔåÆ- **Rule**: Use fallback format: `{UPID}|{Directory} (no GP dx)`. The indication_df maps this to `\"{Directory} (no GP dx)\"`.\n    53ÔåÆ- **Why**: Maintains consistent behavior with the previous approach for patients/drugs without GP diagnosis matches.\n    54ÔåÆ\n    55ÔåÆ### Don't modify directory chart processing\n    56ÔåÆ- **When**: Making changes to the indication matching logic\n    57ÔåÆ- **Rule**: Only modify the indication chart path (`elif current_chart_type == \"indication\":`). Directory charts use unmodified UPIDs and directory-based grouping.\n    58ÔåÆ- **Why**: Directory charts work correctly and should not be affected by indication matching changes.\n    59ÔåÆ\n    60ÔåÆ---\n    61ÔåÆ\n    62ÔåÆ## Snowflake Query Guardrails\n    63ÔåÆ\n    64ÔåÆ### Use PseudoNHSNoLinked for GP record matching\n    65ÔåÆ- **When**: Querying GP records (PrimaryCareClinicalCoding) for patient diagnoses\n    66ÔåÆ- **Rule**: Use `PseudoNHSNoLinked` column from HCD data, NOT `PersonKey` (LocalPatientID)\n    67ÔåÆ- **Why**: PersonKey is provider-specific local ID. Only PseudoNHSNoLinked matches PatientPseudonym in GP records.\n    68ÔåÆ\n    69ÔåÆ### Embed cluster query as CTE in Snowflake\n    70ÔåÆ- **When**: Looking up patient indications during data refresh\n    71ÔåÆ- **Rule**: Use the `CLUSTER_MAPPING_SQL` content as a WITH clause in the patient lookup query\n    72ÔåÆ- **Why**: This ensures we always use the complete cluster mapping and don't need local storage\n    73ÔåÆ\n    74ÔåÆ### Quote mixed-case column aliases in Snowflake SQL\n    75ÔåÆ- **When**: Writing SELECT queries that return results to Python code\n    76ÔåÆ- **Rule**: Use `AS \"ColumnName\"` (quoted) for any column alias you'll access by name in Python\n    77ÔåÆ- **Why**: Snowflake uppercases unquoted identifiers. `SELECT foo AS Search_Term` returns `SEARCH_TERM`, so `row.get('Search_Term')` returns None. Fix: `SELECT foo AS \"Search_Term\"`\n    78ÔåÆ\n    79ÔåÆ### Build indication_df from all unique UPIDs, not PseudoNHSNoLinked\n    80ÔåÆ- **When**: Creating the indication mapping DataFrame for pathway processing\n    81ÔåÆ- **Rule**: Use `df.drop_duplicates(subset=['UPID'])` not `drop_duplicates(subset=['PseudoNHSNoLinked'])`\n    82ÔåÆ- **Why**: A patient visiting multiple providers has multiple UPIDs. Using unique PseudoNHSNoLinked only maps one UPID per patient, leaving others as NaN.\n    83ÔåÆ\n    84ÔåÆ---\n    85ÔåÆ\n    86ÔåÆ## Data Processing Guardrails\n    87ÔåÆ\n    88ÔåÆ### Copy DataFrames in functions that modify columns\n    89ÔåÆ- **When**: Writing functions like `prepare_data()` that modify DataFrame columns\n    90ÔåÆ- **Rule**: Always `df = df.copy()` at the start of any function that modifies column values on the input DataFrame\n    91ÔåÆ- **Why**: `prepare_data()` mapped Provider Code ÔåÆ Name in-place. When called multiple times on the same DataFrame, only the first call worked. The fix: `df.copy()` prevents destructive mutation.\n    92ÔåÆ\n    93ÔåÆ### Include chart_type in UNIQUE constraints for pathway_nodes\n    94ÔåÆ- **When**: Creating or modifying the pathway_nodes table schema\n    95ÔåÆ- **Rule**: The UNIQUE constraint MUST include `chart_type`: `UNIQUE(date_filter_id, chart_type, ids)`\n    96ÔåÆ- **Why**: Without `chart_type`, `INSERT OR REPLACE` silently overwrites directory chart nodes when indication chart nodes are inserted.\n    97ÔåÆ\n    98ÔåÆ### Handle NaN in Directory when building fallback labels\n    99ÔåÆ- **When**: Creating fallback indication labels for patients without GP diagnosis match\n   100ÔåÆ- **Rule**: Check `pd.notna(directory)` before concatenating to string. Use `\"UNKNOWN (no GP dx)\"` for NaN cases.\n   101ÔåÆ- **Why**: NaN handling prevents TypeError and ensures meaningful fallback labels.\n   102ÔåÆ\n   103ÔåÆ### Use parameterized queries for SQLite\n   104ÔåÆ- **When**: Building WHERE clauses with user-selected filters\n   105ÔåÆ- **Rule**: Use `?` placeholders and pass params tuple ÔÇö never string interpolation\n   106ÔåÆ- **Why**: Prevents SQL injection and handles special characters in drug/directory names\n   107ÔåÆ\n   108ÔåÆ### Use existing pathway_analyzer functions\n   109ÔåÆ- **When**: Processing pathway data for the icicle chart\n   110ÔåÆ- **Rule**: Reuse functions from `analysis/pathway_analyzer.py` ÔÇö don't reinvent\n   111ÔåÆ- **Why**: The existing code handles edge cases (empty groups, statistics calculation, color mapping)\n   112ÔåÆ\n   113ÔåÆ---\n   114ÔåÆ\n   115ÔåÆ## Reflex Guardrails\n   116ÔåÆ\n   117ÔåÆ### Use .to() methods for Var operations in rx.foreach\n   118ÔåÆ- **When**: Working with items inside `rx.foreach` render functions\n   119ÔåÆ- **Rule**: Use `item.to(int)` for numeric comparisons, `item.to_string()` for text operations\n   120ÔåÆ- **Why**: Items from rx.foreach are Var objects, not plain Python values.\n   121ÔåÆ\n   122ÔåÆ### Use rx.cond for conditional rendering, not Python if\n   123ÔåÆ- **When**: Conditionally showing/hiding components or changing styles based on state\n   124ÔåÆ- **Rule**: Use `rx.cond(condition, true_component, false_component)` ÔÇö not Python `if`\n   125ÔåÆ- **Why**: Python `if` evaluates at definition time; `rx.cond` evaluates reactively at render time\n   126ÔåÆ\n   127ÔåÆ---\n   128ÔåÆ\n   129ÔåÆ## Process Guardrails\n   130ÔåÆ\n   131ÔåÆ### One task per iteration\n   132ÔåÆ- **When**: Temptation to do additional tasks after completing the current one\n   133ÔåÆ- **Rule**: Complete ONE task, validate it, commit it, update progress, then stop\n   134ÔåÆ- **Why**: Multiple tasks increase error risk and make failures harder to diagnose\n   135ÔåÆ\n   136ÔåÆ### Never mark complete without validation\n   137ÔåÆ- **When**: Task feels \"done\" but hasn't been tested\n   138ÔåÆ- **Rule**: All validation tiers must pass before marking `[x]`\n   139ÔåÆ- **Why**: \"Feels done\" is not \"is done\"\n   140ÔåÆ\n   141ÔåÆ### Write explicit handoff notes\n   142ÔåÆ- **When**: Every iteration, before stopping\n   143ÔåÆ- **Rule**: The \"Next iteration should\" section must contain specific, actionable guidance\n   144ÔåÆ- **Why**: The next iteration has zero memory. If you don't write it down, it's lost.\n   145ÔåÆ\n   146ÔåÆ### Check existing code for patterns\n   147ÔåÆ- **When**: Unsure how to implement something\n   148ÔåÆ- **Rule**: Look at `pathways_app/pathways_app.py`, `analysis/pathway_analyzer.py`, `cli/refresh_pathways.py`\n   149ÔåÆ- **Why**: The existing codebase has solved many quirks already\n   150ÔåÆ\n   151ÔåÆ<!--\n   152ÔåÆADD NEW GUARDRAILS BELOW as failures are observed during the loop.\n   153ÔåÆ\n   154ÔåÆFormat:\n   155ÔåÆ### [Short descriptive name]\n   156ÔåÆ- **When**: What situation triggers this guardrail?\n   157ÔåÆ- **Rule**: What must you do (or not do)?\n   158ÔåÆ- **Why**: What failure prompted adding this guardrail?\n   159ÔåÆ-->\n   160ÔåÆ\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"223ba63a-c935-45d5-9a45-75474de07dfb","tool_use_result":{"type":"text","file":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\guardrails.md","content":"# Guardrails\n\nKnown failure patterns. Read EVERY iteration. Follow ALL of these rules.\nIf you discover a new failure pattern during your work, add it to this file.\n\n---\n\n## Drug-Indication Matching Guardrails\n\n### Match drugs to indications, not just patients to indications\n- **When**: Building the indication mapping for pathway charts\n- **Rule**: Each drug must be validated against BOTH the patient's GP diagnoses AND the drug-to-indication mapping from DimSearchTerm.csv. A patient being diagnosed with rheumatoid arthritis does NOT mean all their drugs are for rheumatoid arthritis.\n- **Why**: The previous approach assigned ONE indication per patient (most recent GP dx), ignoring which drugs actually treat which conditions. This produced misleading pathways.\n\n### Use DimSearchTerm.csv for drug-to-Search_Term mapping\n- **When**: Determining which Search_Term a drug belongs to\n- **Rule**: Load `data/DimSearchTerm.csv`. The `CleanedDrugName` column has pipe-separated drug name fragments. Match HCD drug names against these fragments using substring matching (case-insensitive).\n- **Why**: This CSV is the authoritative mapping of which drugs are used for which clinical indications.\n\n### Use substring matching for drug fragments\n- **When**: Matching HCD drug names against DimSearchTerm CleanedDrugName fragments\n- **Rule**: Check if any fragment from DimSearchTerm is a SUBSTRING of the HCD drug name (case-insensitive). E.g., \"PEGYLATED\" should match \"PEGYLATED LIPOSOMAL DOXORUBICIN\".\n- **Why**: DimSearchTerm contains both full drug names (ADALIMUMAB) and partial fragments (PEGYLATED, INHALED). Exact match would miss the partial ones.\n\n### Modified UPID uses pipe delimiter\n- **When**: Creating indication-aware UPIDs\n- **Rule**: Format is `{original_UPID}|{search_term}`. Use pipe `|` as delimiter. Do NOT use ` - ` (hyphen with spaces) as that's used for pathway hierarchy levels in the `ids` column.\n- **Why**: The `ids` column uses \" - \" to separate hierarchy levels (e.g., \"N&WICS - NNUH - rheumatoid arthritis - ADALIMUMAB\"). Using the same delimiter in UPIDs would break hierarchy parsing.\n\n### Return ALL GP matches per patient, not just most recent\n- **When**: Querying Snowflake for patient GP diagnoses\n- **Rule**: Remove `QUALIFY ROW_NUMBER() OVER (PARTITION BY ... ORDER BY EventDateTime DESC) = 1`. Return ALL matching Search_Terms per patient with `GROUP BY + COUNT(*)` for code_frequency.\n- **Why**: A patient may have GP diagnoses for both rheumatoid arthritis AND asthma. We need ALL matches to cross-reference with their drugs.\n\n### Restrict GP code lookup to HCD data window\n- **When**: Building the WHERE clause for the GP record query\n- **Rule**: Add `AND pc.\"EventDateTime\" >= :earliest_hcd_date` where `earliest_hcd_date` is `MIN(Intervention Date)` from the HCD DataFrame. Pass this as a parameter to `get_patient_indication_groups()`.\n- **Why**: Old GP codes from years before treatment started add noise. A diagnosis coded 10 years ago may no longer be relevant. Restricting to the HCD window ensures code_frequency reflects recent clinical activity for the conditions being actively treated.\n\n### Tiebreaker: highest GP code frequency when a drug matches multiple indications\n- **When**: A single drug maps to multiple Search_Terms AND the patient has GP dx for multiple\n- **Rule**: Use `code_frequency` (COUNT of matching SNOMED codes per Search_Term per patient) from the GP query. The Search_Term with the most matching codes in the patient's GP record wins. If tied, use alphabetical Search_Term for determinism.\n- **Why**: E.g., ADALIMUMAB is listed under rheumatoid arthritis, crohn's disease, psoriatic arthritis, etc. A patient with 47 RA codes and 2 crohn's codes is almost certainly on ADALIMUMAB for RA. Frequency of GP coding is a much stronger signal of clinical intent than recency ÔÇö a recent one-off asthma check doesn't mean ADALIMUMAB is for asthma.\n\n### Same patient, different indications = separate modified UPIDs\n- **When**: A patient's drugs map to different Search_Terms\n- **Rule**: Create separate modified UPIDs for each indication. E.g., `RMV12345|rheumatoid arthritis` and `RMV12345|asthma`. These are treated as separate \"patients\" by the pathway analyzer.\n- **Why**: This is the core design ÔÇö drugs for different indications should create separate treatment pathways, even for the same physical patient.\n\n### Fallback to directory for unmatched drugs\n- **When**: A drug doesn't match any Search_Term OR the patient has no GP dx for any of the drug's Search_Terms\n- **Rule**: Use fallback format: `{UPID}|{Directory} (no GP dx)`. The indication_df maps this to `\"{Directory} (no GP dx)\"`.\n- **Why**: Maintains consistent behavior with the previous approach for patients/drugs without GP diagnosis matches.\n\n### Don't modify directory chart processing\n- **When**: Making changes to the indication matching logic\n- **Rule**: Only modify the indication chart path (`elif current_chart_type == \"indication\":`). Directory charts use unmodified UPIDs and directory-based grouping.\n- **Why**: Directory charts work correctly and should not be affected by indication matching changes.\n\n---\n\n## Snowflake Query Guardrails\n\n### Use PseudoNHSNoLinked for GP record matching\n- **When**: Querying GP records (PrimaryCareClinicalCoding) for patient diagnoses\n- **Rule**: Use `PseudoNHSNoLinked` column from HCD data, NOT `PersonKey` (LocalPatientID)\n- **Why**: PersonKey is provider-specific local ID. Only PseudoNHSNoLinked matches PatientPseudonym in GP records.\n\n### Embed cluster query as CTE in Snowflake\n- **When**: Looking up patient indications during data refresh\n- **Rule**: Use the `CLUSTER_MAPPING_SQL` content as a WITH clause in the patient lookup query\n- **Why**: This ensures we always use the complete cluster mapping and don't need local storage\n\n### Quote mixed-case column aliases in Snowflake SQL\n- **When**: Writing SELECT queries that return results to Python code\n- **Rule**: Use `AS \"ColumnName\"` (quoted) for any column alias you'll access by name in Python\n- **Why**: Snowflake uppercases unquoted identifiers. `SELECT foo AS Search_Term` returns `SEARCH_TERM`, so `row.get('Search_Term')` returns None. Fix: `SELECT foo AS \"Search_Term\"`\n\n### Build indication_df from all unique UPIDs, not PseudoNHSNoLinked\n- **When**: Creating the indication mapping DataFrame for pathway processing\n- **Rule**: Use `df.drop_duplicates(subset=['UPID'])` not `drop_duplicates(subset=['PseudoNHSNoLinked'])`\n- **Why**: A patient visiting multiple providers has multiple UPIDs. Using unique PseudoNHSNoLinked only maps one UPID per patient, leaving others as NaN.\n\n---\n\n## Data Processing Guardrails\n\n### Copy DataFrames in functions that modify columns\n- **When**: Writing functions like `prepare_data()` that modify DataFrame columns\n- **Rule**: Always `df = df.copy()` at the start of any function that modifies column values on the input DataFrame\n- **Why**: `prepare_data()` mapped Provider Code ÔåÆ Name in-place. When called multiple times on the same DataFrame, only the first call worked. The fix: `df.copy()` prevents destructive mutation.\n\n### Include chart_type in UNIQUE constraints for pathway_nodes\n- **When**: Creating or modifying the pathway_nodes table schema\n- **Rule**: The UNIQUE constraint MUST include `chart_type`: `UNIQUE(date_filter_id, chart_type, ids)`\n- **Why**: Without `chart_type`, `INSERT OR REPLACE` silently overwrites directory chart nodes when indication chart nodes are inserted.\n\n### Handle NaN in Directory when building fallback labels\n- **When**: Creating fallback indication labels for patients without GP diagnosis match\n- **Rule**: Check `pd.notna(directory)` before concatenating to string. Use `\"UNKNOWN (no GP dx)\"` for NaN cases.\n- **Why**: NaN handling prevents TypeError and ensures meaningful fallback labels.\n\n### Use parameterized queries for SQLite\n- **When**: Building WHERE clauses with user-selected filters\n- **Rule**: Use `?` placeholders and pass params tuple ÔÇö never string interpolation\n- **Why**: Prevents SQL injection and handles special characters in drug/directory names\n\n### Use existing pathway_analyzer functions\n- **When**: Processing pathway data for the icicle chart\n- **Rule**: Reuse functions from `analysis/pathway_analyzer.py` ÔÇö don't reinvent\n- **Why**: The existing code handles edge cases (empty groups, statistics calculation, color mapping)\n\n---\n\n## Reflex Guardrails\n\n### Use .to() methods for Var operations in rx.foreach\n- **When**: Working with items inside `rx.foreach` render functions\n- **Rule**: Use `item.to(int)` for numeric comparisons, `item.to_string()` for text operations\n- **Why**: Items from rx.foreach are Var objects, not plain Python values.\n\n### Use rx.cond for conditional rendering, not Python if\n- **When**: Conditionally showing/hiding components or changing styles based on state\n- **Rule**: Use `rx.cond(condition, true_component, false_component)` ÔÇö not Python `if`\n- **Why**: Python `if` evaluates at definition time; `rx.cond` evaluates reactively at render time\n\n---\n\n## Process Guardrails\n\n### One task per iteration\n- **When**: Temptation to do additional tasks after completing the current one\n- **Rule**: Complete ONE task, validate it, commit it, update progress, then stop\n- **Why**: Multiple tasks increase error risk and make failures harder to diagnose\n\n### Never mark complete without validation\n- **When**: Task feels \"done\" but hasn't been tested\n- **Rule**: All validation tiers must pass before marking `[x]`\n- **Why**: \"Feels done\" is not \"is done\"\n\n### Write explicit handoff notes\n- **When**: Every iteration, before stopping\n- **Rule**: The \"Next iteration should\" section must contain specific, actionable guidance\n- **Why**: The next iteration has zero memory. If you don't write it down, it's lost.\n\n### Check existing code for patterns\n- **When**: Unsure how to implement something\n- **Rule**: Look at `pathways_app/pathways_app.py`, `analysis/pathway_analyzer.py`, `cli/refresh_pathways.py`\n- **Why**: The existing codebase has solved many quirks already\n\n<!--\nADD NEW GUARDRAILS BELOW as failures are observed during the loop.\n\nFormat:\n### [Short descriptive name]\n- **When**: What situation triggers this guardrail?\n- **Rule**: What must you do (or not do)?\n- **Why**: What failure prompted adding this guardrail?\n-->\n","numLines":160,"startLine":1,"totalLines":160}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_017fn8KZ5s3cf5FG7P2vCaV8","type":"message","role":"assistant","content":[{"type":"text","text":"Reading progress.txt, IMPLEMENTATION_PLAN.md, and guardrails.md. The iteration log in progress.txt is empty ÔÇö this is the **first iteration**. All tasks in IMPLEMENTATION_PLAN.md are `[ ]` (not started).\n\nLet me check recent commits and read the key source files I'll be modifying."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8926,"cache_read_input_tokens":69693,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8926},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"bb3fd7a3-e9f2-4cc5-87bc-b686667ebb8d"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_017fn8KZ5s3cf5FG7P2vCaV8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01M1dohqj5mtBidiAzPMTdms","name":"Bash","input":{"command":"cd \"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\" && git log --oneline -5","description":"Check recent git commits"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8926,"cache_read_input_tokens":69693,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8926},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"89d0273e-d467-4e69-b93d-d717a18f2f82"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_017fn8KZ5s3cf5FG7P2vCaV8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013gSjU7MeMnCV9sYiUzUdur","name":"Read","input":{"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8926,"cache_read_input_tokens":69693,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8926},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"d256c030-4c2a-4550-882b-1acc1314c45e"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_017fn8KZ5s3cf5FG7P2vCaV8","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017M3RrBqP3sNRb87Zq5SxJe","name":"Read","input":{"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data\\DimSearchTerm.csv"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":8926,"cache_read_input_tokens":69693,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":8926},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"041f3b0c-e1a1-4776-99a7-d0a34c85d983"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01M1dohqj5mtBidiAzPMTdms","type":"tool_result","content":"1c4d2c0 docs: mark project complete - all tasks done, viewport testing blocked by env (Iteration 9)\nfed9094 docs: update CLAUDE.md with indication chart architecture and CLI docs (Task 5.2)\n4884e0a fix: recreate pathway_nodes with correct UNIQUE constraint and validate end-to-end (Task 5.1)\n6331d44 fix: prevent DataFrame mutation in prepare_data() causing indication charts to fail\n6f88a59 feat: add chart type toggle for Directory/Indication views (Task 4.1, 4.2, 4.3)","is_error":false}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"93417201-6e24-461b-9746-82013c3bd536","tool_use_result":{"stdout":"1c4d2c0 docs: mark project complete - all tasks done, viewport testing blocked by env (Iteration 9)\nfed9094 docs: update CLAUDE.md with indication chart architecture and CLI docs (Task 5.2)\n4884e0a fix: recreate pathway_nodes with correct UNIQUE constraint and validate end-to-end (Task 5.1)\n6331d44 fix: prevent DataFrame mutation in prepare_data() causing indication charts to fail\n6f88a59 feat: add chart type toggle for Directory/Indication views (Task 4.1, 4.2, 4.3)\r","stderr":"","interrupted":false,"isImage":false}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017M3RrBqP3sNRb87Zq5SxJe","type":"tool_result","content":"     1ÔåÆSearch_Term,CleanedDrugName,PrimaryDirectorate\n     2ÔåÆacute coronary syndrome,ABCIXIMAB|CLOPIDOGREL|PRASUGREL|RIVAROXABAN|TICAGRELOR,CARDIOLOGY\n     3ÔåÆacute lymphoblastic leukaemia,BLINATUMOMAB|DASATINIB|INOTUZUMAB|PEGASPARGASE|PONATINIB|TISAGENLECLEUCEL,CLINICAL HAEMATOLOGY\n     4ÔåÆacute myeloid leukaemia,AZACITIDINE|DECITABINE|GEMTUZUMAB|GILTERITINIB|GLASDEGIB|LIPOSOMAL|MIDOSTAURIN|ORAL|VENETOCLAX,CLINICAL HAEMATOLOGY\n     5ÔåÆacute promyelocytic leukaemia,ARSENIC|GEMTUZUMAB,CLINICAL HAEMATOLOGY\n     6ÔåÆallergic asthma,OMALIZUMAB,THORACIC MEDICINE\n     7ÔåÆallergic rhinitis,SQ,ENT\n     8ÔåÆalzheimer's disease,DONEPEZIL,NEUROLOGY\n     9ÔåÆamyloidosis,VUTRISIRAN,CLINICAL HAEMATOLOGY\n    10ÔåÆanaemia,ERYTHROPOIESIS-STIMULATING|ERYTHROPOIETIN,CLINICAL HAEMATOLOGY\n    11ÔåÆanaplastic large cell lymphoma,BRENTUXIMAB,CLINICAL HAEMATOLOGY\n    12ÔåÆankylosing spondylitis,ADALIMUMAB|GOLIMUMAB|SECUKINUMAB|UPADACITINIB,RHEUMATOLOGY\n    13ÔåÆapixaban,ANDEXANET,CARDIOLOGY\n    14ÔåÆaplastic anaemia,ELTROMBOPAG,CLINICAL HAEMATOLOGY\n    15ÔåÆarthritis,ETANERCEPT,RHEUMATOLOGY\n    16ÔåÆasthma,BENRALIZUMAB|DUPILUMAB|INHALED|MEPOLIZUMAB|OMALIZUMAB|RESLIZUMAB,THORACIC MEDICINE\n    17ÔåÆatopic dermatitis,ABROCITINIB|ALCLOMETASONE|BARICITINIB|CRISABOROLE|DUPILUMAB|PIMECROLIMUS,DERMATOLOGY\n    18ÔåÆatrial fibrillation,APIXABAN|DABIGATRAN|DRONEDARONE|EDOXABAN|RIVAROXABAN|VERNAKALANT,CARDIOLOGY\n    19ÔåÆattention deficit hyperactivity disorder,ATOMOXETINE,MENTAL HEALTH\n    20ÔåÆattention-deficit hyperactivity disorder,METHYLPHENIDATE,MENTAL HEALTH\n    21ÔåÆaxial spondyloarthritis,ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB|SECUKINUMAB|UPADACITINIB,RHEUMATOLOGY\n    22ÔåÆbasal cell carcinoma,VISMODEGIB,DERMATOLOGY\n    23ÔåÆbipolar disorder,LOXAPINE|OLANZAPINE,MENTAL HEALTH\n    24ÔåÆbladder,MIRABEGRON,MEDICAL ONCOLOGY\n    25ÔåÆbrca,OLAPARIB,MEDICAL ONCOLOGY\n    26ÔåÆbreast cancer,ABEMACICLIB|ALPELISIB|ANASTROZOLE|ATEZOLIZUMAB|BEVACIZUMAB|CAPECITABINE|DENOSUMAB|DOCETAXEL|ERIBULIN|EVEROLIMUS|FULVESTRANT|GEMCITABINE|INTRABEAM|LAPATINIB|NERATINIB|OLAPARIB|PACLITAXEL|PALBOCICLI|PALBOCICLIB|PEMBROLIZUMAB|PERTUZUMAB|RIBOCICLIB|SACITUZUMAB|TRASTUZUMAB|TUCATINIB|VINORELBINE,MEDICAL ONCOLOGY\n    27ÔåÆcardiomyopathy,TAFAMIDIS,CARDIOLOGY\n    28ÔåÆcardiovascular disease,ATORVASTATIN,CARDIOLOGY\n    29ÔåÆcervical cancer,TOPOTECAN,MEDICAL ONCOLOGY\n    30ÔåÆcholangiocarcinoma,PEMIGATINIB,MEDICAL ONCOLOGY\n    31ÔåÆchoroidal neovascularisation,AFLIBERCEPT|RANIBIZUMAB,OPHTHALMOLOGY\n    32ÔåÆchronic kidney disease,DAPAGLIFLOZIN|IMLIFIDASE|ROXADUSTAT,NEPHROLOGY\n    33ÔåÆchronic liver disease,AVATROMBOPAG|LUSUTROMBOPAG,GASTROENTEROLOGY\n    34ÔåÆchronic lymphocytic leukaemia,ACALABRUTINIB|BENDAMUSTINE|DUVELISIB|IBRUTINIB|IDELALISIB|OBINUTUZUMAB|OFATUMUMAB|RITUXIMAB|VENETOCLAX,CLINICAL HAEMATOLOGY\n    35ÔåÆchronic myeloid leukaemia,ASCIMINIB|BOSUTINIB|STANDARD-DOSE|DASATINIB|DASITINIB|NILOTINIB|PONATINIB,CLINICAL HAEMATOLOGY\n    36ÔåÆchronic obstructive pulmonary disease,ROFLUMILAST,THORACIC MEDICINE\n    37ÔåÆcolon cancer,CAPECITABINE,MEDICAL ONCOLOGY\n    38ÔåÆcolorectal cancer,BEVACIZUMAB|CAPECITABINE|IRINOTECAN,MEDICAL ONCOLOGY\n    39ÔåÆconstipation,LUBIPROSTONE|METHYLNALTREXONE|NALDEMEDINE|NALOXEGOL|PRUCALOPRIDE,GASTROENTEROLOGY\n    40ÔåÆcovid-19,NIRMATRELVIR,INFECTIOUS DISEASES\n    41ÔåÆcrohn's disease,INFLIXIMAB|VEDOLIZUMAB,GASTROENTEROLOGY\n    42ÔåÆcutaneous t-cell lymphoma,BRENTUXIMAB|CHLORMETHINE,CLINICAL HAEMATOLOGY\n    43ÔåÆcystic fibrosis,COLISTIMETHATE|LUMACAFTOR|MANNITOL,THORACIC MEDICINE\n    44ÔåÆcytomegalovirus,LETERMOVIR|MARIBAVIR,INFECTIOUS DISEASES\n    45ÔåÆdeep vein thrombosis,APIXABAN|DABIGATRAN|EDOXABAN|RIVAROXABAN,VASCULAR SURGERY\n    46ÔåÆdepression,ESKETAMINE,MENTAL HEALTH\n    47ÔåÆdiabetes,ERTUGLIFLOZIN|INHALED|AFLIBERCEPT|BROLUCIZUMAB|DEXAMETHASONE|FARICIMAB|FLUOCINOLONE|RANIBIZUMAB,DIABETIC MEDICINE\n    48ÔåÆdiabetes,ERTUGLIFLOZIN|INHALED|AFLIBERCEPT|BROLUCIZUMAB|DEXAMETHASONE|FARICIMAB|FLUOCINOLONE|RANIBIZUMAB,OPHTHALMOLOGY\n    49ÔåÆdiabetic retinopathy,RANIBUZIMAB,OPHTHALMOLOGY\n    50ÔåÆdiffuse large b-cell lymphoma,AXICABTAGENE|POLATUZUMAB|TISAGENLECLEUCEL,CLINICAL HAEMATOLOGY\n    51ÔåÆdravet syndrome,CANNABIDIOL|FENFLURAMINE,NEUROLOGY\n    52ÔåÆdrug misuse,BUPRENORPHINE|NALTREXONE,MENTAL HEALTH\n    53ÔåÆdry eye,CICLOSPORIN,OPHTHALMOLOGY\n    54ÔåÆdyspepsia,LANSOPRAZOLE,GASTROENTEROLOGY\n    55ÔåÆendometrial cancer,DOSTARLIMAB,MEDICAL ONCOLOGY\n    56ÔåÆepilepsy,CENOBAMATE|GABAPENTIN|RETIGABINE,NEUROLOGY\n    57ÔåÆfallopian tube,BEVACIZUMAB|NIRAPARIB|OLAPARIB|RUCAPARIB,MEDICAL ONCOLOGY\n    58ÔåÆfollicular lymphoma,DUVELISIB|IDELALISIB|LENALIDOMIDE|OBINUTUZUMAB|RITUXIMAB|TISAGENLECLEUCEL,CLINICAL HAEMATOLOGY\n    59ÔåÆgastric cancer,CAPECITABINE|RAMUCIRUMAB|TRASTUZUMAB|TRIFLURIDINE,MEDICAL ONCOLOGY\n    60ÔåÆgastro-oesophageal junction,NIVOLUMAB|PEMBROLIZUMAB,MEDICAL ONCOLOGY\n    61ÔåÆgiant cell arteritis,TOCILIZUMAB,RHEUMATOLOGY\n    62ÔåÆglioma,CARMUSTINE,MEDICAL ONCOLOGY\n    63ÔåÆgout,CANAKINUMAB|FEBUXOSTAT|LESINURAD,RHEUMATOLOGY\n    64ÔåÆgraft versus host disease,RUXOLITINIB,CLINICAL HAEMATOLOGY\n    65ÔåÆgranulomatosis with polyangiitis,AVACOPAN|MEPOLIZUMAB,RHEUMATOLOGY\n    66ÔåÆgrowth hormone deficiency,SOMATROPIN,ENDOCRINOLOGY\n    67ÔåÆhand eczema,ALITRETINOIN,DERMATOLOGY\n    68ÔåÆheart failure,DAPAGLIFLOZIN|EMPAGLIFLOZIN|IVABRADINE|SACUBITRIL|VERICIGUAT,CARDIOLOGY\n    69ÔåÆhepatitis b,ADEFOVIR,GASTROENTEROLOGY\n    70ÔåÆhepatitis c,BOCEPREVIR|DACLATASVIR|ELBASVIR|GLECAPREVIR|INTERFERON|LEDIPASVIR|OMBITASVIR|PEGINTERFERON|PEGYLATED|SIMEPREVIR|SOFOSBUVIR|TELAPREVIR,GASTROENTEROLOGY\n    71ÔåÆhepatocellular carcinoma,ATEZOLIZUMAB|CABOZANTINIB|LENVATINIB|RAMUCIRUMAB|REGORAFENIB|SELECTIVE|SORAFENIB,MEDICAL ONCOLOGY\n    72ÔåÆhiv,CABOTEGRAVIR,INFECTIOUS DISEASES\n    73ÔåÆhodgkin lymphoma,BRENTUXIMAB|NIVOLUMAB|PEMBROLIZUMAB,CLINICAL HAEMATOLOGY\n    74ÔåÆhormone receptor,ABEMACICLIB,MEDICAL ONCOLOGY\n    75ÔåÆhypercholesterolaemia,EZETIMIBE,CARDIOLOGY\n    76ÔåÆhyperparathyroidism,CINACALCET|ETELCALCETIDE,ENDOCRINOLOGY\n    77ÔåÆimmune thrombocytopenia,AVATROMBOPAG|FOSTAMATINIB,CLINICAL HAEMATOLOGY\n    78ÔåÆinfluenza,AMANTADINE|ZANAMIVIR|BALOXAVIR,INFECTIOUS DISEASES\n    79ÔåÆinsomnia,ZALEPLON,NEUROLOGY\n    80ÔåÆirritable bowel syndrome,ELUXADOLINE,GASTROENTEROLOGY\n    81ÔåÆischaemic stroke,ALTEPLASE,STROKE MEDICINE\n    82ÔåÆjuvenile idiopathic arthritis,ABATECEPT|CANAKINUMAB|TOCILIZUMAB|TOFACITINIB,RHEUMATOLOGY\n    83ÔåÆkidney transplant,BASILIXIMAB,NEPHROLOGY\n    84ÔåÆleukaemia,FLUDARABINE|IMATINIB,CLINICAL HAEMATOLOGY\n    85ÔåÆlung cancer,ATEZOLIZUMAB|DURVALUMAB|GEFITINIB|ORAL|NINTEDANIB,MEDICAL ONCOLOGY\n    86ÔåÆlymphoma,BENDAMUSTINE|CRIZOTINIB|PIXANTRONE|RITUXIMAB,CLINICAL HAEMATOLOGY\n    87ÔåÆmacular degeneration,AFLIBERCEPT|BROLUCIZUMAB|FARICIMAB|RANIBIZUMAB,OPHTHALMOLOGY\n    88ÔåÆmacular oedema,AFLIBERCEPT|RANIBIZUMAB,OPHTHALMOLOGY\n    89ÔåÆmajor depressive episodes,AGOMELATINE|VORTIOXETINE,MENTAL HEALTH\n    90ÔåÆmalignant melanoma,VEMURAFENIB,MEDICAL ONCOLOGY\n    91ÔåÆmalignant pleural mesothelioma,NIVOLUMAB|PEMETREXED,MEDICAL ONCOLOGY\n    92ÔåÆmanic episode,ARIPIPRAZOLE,MENTAL HEALTH\n    93ÔåÆmantle cell lymphoma,AUTOLOGOUS|BORTEZOMIB|IBRUTINIB|LENALIDOMIDE|TEMSIROLIMUS,CLINICAL HAEMATOLOGY\n    94ÔåÆmelanoma,COBIMETINIB|DABRAFENIB|ENCORAFENIB|IPILIMUMAB|NIVOLUMAB|PEMBROLIZUMAB|TALIMOGENE|TRAMETINIB,MEDICAL ONCOLOGY\n    95ÔåÆmerkel cell carcinoma,AVELUMAB,MEDICAL ONCOLOGY\n    96ÔåÆmigraine,BOTULINUM|EPTINEZUMAB|ERENUMAB|FREMANEZUMAB|GALCANEZUMAB,NEUROLOGY\n    97ÔåÆmotor neurone disease,RILUZOLE,NEUROLOGY\n    98ÔåÆmultiple myeloma,BORTEZOMIB|THALIDOMIDE|CARFILZOMIB|DARATUMUMAB|DENOSUMAB|ELOTUZUMAB|ISATUXIMAB|IXAZOMIB|LENALIDOMIDE|PANOBINOSTAT|POMALIDOMIDE|SELINEXOR|TECLISTAMAB,CLINICAL HAEMATOLOGY\n    99ÔåÆmultiple sclerosis,ALEMTUZUMAB|BETA|CLADRIBINE|DACLIZUMAB|DIMETHYL|DIROXIMEL|FINGOLIMOD|INTERFERON|NATALIZUMAB|OCRELIZUMAB|OZANIMOD|PEGINTERFERON|PONESIMOD|SIPONIMOD|TERIFLUNOMIDE,NEUROLOGY\n   100ÔåÆmyelodysplastic,LENALIDOMIDE|LUSPATERCEPT,CLINICAL HAEMATOLOGY\n   101ÔåÆmyelofibrosis,FEDRATINIB|RUXOLITINIB,CLINICAL HAEMATOLOGY\n   102ÔåÆmyocardial infarction,ALTEPLASE|BIVALIRUDIN|TICAGRELOR,CARDIOLOGY\n   103ÔåÆmyotonia,MEXILETINE,NEUROLOGY\n   104ÔåÆnarcolepsy,SOLRIAMFETOL,NEUROLOGY\n   105ÔåÆneuroendocrine tumour,EVEROLIMUS|LUTETIUM,MEDICAL ONCOLOGY\n   106ÔåÆnon-small cell lung cancer,ATEZOLIZMAB|DOCETAXEL|ERLOTINIB|PEMETREXED,MEDICAL ONCOLOGY\n   107ÔåÆnon-small-cell lung cancer,AFATINIB|ALECTINIB|AMIVANTAMAB|ATEZOLIZUMAB|BEVACIZUMAB|BRIGATINIB|CEMIPLIMAB|CERITINIB|CRIZOTINIB|DABRAFENIB|DACOMITINIB|DURVALUMAB|ENTRECTINIB|ERLOTINIB|GEFITINIB|LORLATINIB|MOBOCERTINIB|NECITUMUMAB|NIVOLUMAB|OSIMERTINIB|PACLITAXEL|PEMBROLIZUMAB|PEMETREXED|PRALSETINIB|RAMUCIRUMAB|SELPERCATINIB|SOTORASIB|TEPOTINIB,MEDICAL ONCOLOGY\n   108ÔåÆobesity,LIRAGLUTIDE|NALTREXONE|ORLISTAT|SEMAGLUTIDE|SIBUTRAMINE,ENDOCRINOLOGY\n   109ÔåÆoesophageal cancer,NIVOLUMAB,MEDICAL ONCOLOGY\n   110ÔåÆosteoarthritis,CELECOXIB,RHEUMATOLOGY\n   111ÔåÆosteoporosis,ALENDRONATE|DENOSUMAB|ORAL|ROMOSOZUMAB,RHEUMATOLOGY\n   112ÔåÆosteosarcoma,MIFAMURTIDE,MEDICAL ONCOLOGY\n   113ÔåÆovarian cancer,BEVACIZUMAB|PACLITAXEL|PEGYLATED|TOPOTECAN|TRABECTEDIN,MEDICAL ONCOLOGY\n   114ÔåÆoverweight,RIMONABANT,ENDOCRINOLOGY\n   115ÔåÆpancreatic cancer,GEMCITABINE|OLAPARIB|PACLITAXEL|PEGYLATED,MEDICAL ONCOLOGY\n   116ÔåÆparoxysmal nocturnal haemoglobinuria,PEGCETACOPLAN|RAVULIZUMAB,CLINICAL HAEMATOLOGY\n   117ÔåÆperipheral arterial disease,NAFTIDROFYRYL,VASCULAR SURGERY\n   118ÔåÆplaque psoriasis,ADALIMUMAB|APREMILAST|BIMEKIZUMAB|BRODALUMAB|CERTOLIZUMAB|GUSELKUMAB|INFLIXIMAB|IXEKIZUMAB|RISANKIZUMAB|SECUKINUMAB|TILDRAKIZUAMB|USTEKINUMAB,DERMATOLOGY\n   119ÔåÆpolycystic kidney disease,TOLVAPTAN,NEPHROLOGY\n   120ÔåÆpolycythaemia vera,RUXOLITINIB,CLINICAL HAEMATOLOGY\n   121ÔåÆpregnancy,ROUTINE,OBSTETRICS\n   122ÔåÆprimary biliary cholangitis,OBETICHOLIC,GASTROENTEROLOGY\n   123ÔåÆprimary hypercholesterolaemia,ALIROCUMAB|EVOLOCUMAB,CARDIOLOGY\n   124ÔåÆprostate cancer,ABIRATERONE|APALUTAMIDE|CABAZITAXEL|DAROLUTAMIDE|DEGARELIX|DENOSUMAB|DOCETAXEL|ENZALUTAMIDE|OLAPARIB|PADELIPORFIN|RADIUM-|RADIUM|SIPULEUCEL-T,MEDICAL ONCOLOGY\n   125ÔåÆpsoriasis,EFALUZIMAB,DERMATOLOGY\n   126ÔåÆpsoriatic arthritis,ABATACEPT|ADALIMUMAB|APREMILAST|CERTOLIZUMAB|ETANERCEPT|GOLIMUMAB|GUSELKUMAB|IXEKIZUMAB|RISANKIZUMAB|TOFACITINIB|UPADACITINIB|USTEKINUMAB,RHEUMATOLOGY\n   127ÔåÆpulmonary embolism,APIXABAN|DABIGATRAN|EDOXABAN|RIVAROXABAN,THORACIC MEDICINE\n   128ÔåÆpulmonary fibrosis,NINTEDANIB|PIRFENIDONE,THORACIC MEDICINE\n   129ÔåÆrelapsing multiple sclerosis,OFATUMUMAB,NEUROLOGY\n   130ÔåÆrenal cell carcinoma,AVELUMAB|AXITINIB|BEVACIZUMAB|CABOZANTINIB|EVEROLIMUS|LENVATINIB|NIVOLUMAB|PAZOPANIB|PEMBROLIZUMAB|SUNITINIB|TIVOZANIB,MEDICAL ONCOLOGY\n   131ÔåÆrenal transplantation,BASILIXIMAB|INDUCTION,NEPHROLOGY\n   132ÔåÆretinal vein occlusion,AFLIBERCEPT|DEXAMETHASONE|RANIBIZUMAB,OPHTHALMOLOGY\n   133ÔåÆrheumatoid arthritis,ABATACEPT|ADALIMUMAB|ANAKINRA|BARICITINIB|CELECOXIB|CERTOLIZUMAB|ETANERCEPT|FILGOTINIB|GOLIMUMAB|RITUXIMAB|SARILUMAB|TOCILIZUMAB|TOFACITINIB|UPADACITINIB,RHEUMATOLOGY\n   134ÔåÆrivaroxaban,ANDEXANET,CARDIOLOGY\n   135ÔåÆschizophrenia,AMISULPRIDE|ARIPIPRAZOLE|LOXAPINE,MENTAL HEALTH\n   136ÔåÆseizures,CANNABIDIOL,NEUROLOGY\n   137ÔåÆsepsis,DROTRECOGIN,INFECTIOUS DISEASES\n   138ÔåÆsevere persistent allergic asthma,OMALIZUMAB,THORACIC MEDICINE\n   139ÔåÆshort bowel syndrome,TEDUGLUTIDE,GASTROENTEROLOGY\n   140ÔåÆsickle cell disease,CRIZANLIZUMAB,CLINICAL HAEMATOLOGY\n   141ÔåÆsleep apnoea,PITOLISANT|SOLRIAMFETOL,THORACIC MEDICINE\n   142ÔåÆsmoking cessation,NICOTINE|VARENICLINE,THORACIC MEDICINE\n   143ÔåÆsoft tissue sarcoma,INTRAVENOUS|NBTXR-|OLARATUMAB,MEDICAL ONCOLOGY\n   144ÔåÆspinal muscular atrophy,NUSINERSEN|RISDIPLAM,NEUROLOGY\n   145ÔåÆsquamous cell,CETUXIMAB,MEDICAL ONCOLOGY\n   146ÔåÆsquamous cell carcinoma,CEMIPLIMAB|NIVOLUMAB|PEMBROLIZUMAB,MEDICAL ONCOLOGY\n   147ÔåÆstem cell transplant,MELPHALAN|TREOSULFAN,CLINICAL HAEMATOLOGY\n   148ÔåÆstroke,APIXABAN|DABIGATRAN|EDOXABAN|RIVAROXABAN,STROKE MEDICINE\n   149ÔåÆsystemic lupus erythematosus,ANIFROLUMAB|ETANERCEPT,RHEUMATOLOGY\n   150ÔåÆsystemic mastocytosis,MIDOSTAURIN,CLINICAL HAEMATOLOGY\n   151ÔåÆthrombocytopenic purpura,ELTROMBOPAG|ROMIPLOSTIM,CLINICAL HAEMATOLOGY\n   152ÔåÆthrombotic thrombocytopenic purpura,CAPLACIZUMAB,CLINICAL HAEMATOLOGY\n   153ÔåÆthyroid cancer,CABOZANTINIB|LENVATINIB|SELPERCATINIB|VANDETANIB,MEDICAL ONCOLOGY\n   154ÔåÆtophaceous gout,PEGLOTICASE,RHEUMATOLOGY\n   155ÔåÆtransitional cell carcinoma,VINFLUNINE,MEDICAL ONCOLOGY\n   156ÔåÆtuberous sclerosis,CANNABIDIOL,NEUROLOGY\n   157ÔåÆtype 1 diabetes,CONTINUOUS|DAPAGLIFLOZIN|INSULIN|SOTAGLIFLOZIN,DIABETIC MEDICINE\n   158ÔåÆtype 2 diabetes,CANAGLIFLOZIN|CONTINUOUS|DAPAGLIFLOZIN|EMPAGLIFLOZIN|ERTUGLIFLOZIN|EXENATIDE|FINERENONE|INSULIN|LIRAGLUTIDE|PIOGLITAZONE|ROSIGLITAZONE,DIABETIC MEDICINE\n   159ÔåÆulcerative colitis,ADALIMUMAB|INFLIXIMAB|FILGOTINIB|OZANIMOD|TOFACITINIB|UPADACITINIB|USTEKINUMAB|VEDOLIZUMAB,GASTROENTEROLOGY\n   160ÔåÆurothelial carcinoma,ATEZOLIZUMAB|PEMBROLIZUMAB,MEDICAL ONCOLOGY\n   161ÔåÆurticaria,OMALIZUMAB,DERMATOLOGY\n   162ÔåÆuterine fibroids,RELUGOLIX,GYNAECOLOGY\n   163ÔåÆuveitis,ADALIMUMAB|FLUOCINOLONE,OPHTHALMOLOGY\n   164ÔåÆvascular disease,MODIFIED-RELEASE|CLOPIDOGREL,VASCULAR SURGERY\n   165ÔåÆvasculitis,RITUXIMAB,RHEUMATOLOGY\n   166ÔåÆvenous thromboembolism,APIXABAN|DABIGATRAN|RIVAROXABAN,CLINICAL HAEMATOLOGY\n   167ÔåÆ\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"d38111b3-a022-4fc2-8770-22b3382cd845","tool_use_result":{"type":"text","file":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data\\DimSearchTerm.csv","content":"Search_Term,CleanedDrugName,PrimaryDirectorate\nacute coronary syndrome,ABCIXIMAB|CLOPIDOGREL|PRASUGREL|RIVAROXABAN|TICAGRELOR,CARDIOLOGY\nacute lymphoblastic leukaemia,BLINATUMOMAB|DASATINIB|INOTUZUMAB|PEGASPARGASE|PONATINIB|TISAGENLECLEUCEL,CLINICAL HAEMATOLOGY\nacute myeloid leukaemia,AZACITIDINE|DECITABINE|GEMTUZUMAB|GILTERITINIB|GLASDEGIB|LIPOSOMAL|MIDOSTAURIN|ORAL|VENETOCLAX,CLINICAL HAEMATOLOGY\nacute promyelocytic leukaemia,ARSENIC|GEMTUZUMAB,CLINICAL HAEMATOLOGY\nallergic asthma,OMALIZUMAB,THORACIC MEDICINE\nallergic rhinitis,SQ,ENT\nalzheimer's disease,DONEPEZIL,NEUROLOGY\namyloidosis,VUTRISIRAN,CLINICAL HAEMATOLOGY\nanaemia,ERYTHROPOIESIS-STIMULATING|ERYTHROPOIETIN,CLINICAL HAEMATOLOGY\nanaplastic large cell lymphoma,BRENTUXIMAB,CLINICAL HAEMATOLOGY\nankylosing spondylitis,ADALIMUMAB|GOLIMUMAB|SECUKINUMAB|UPADACITINIB,RHEUMATOLOGY\napixaban,ANDEXANET,CARDIOLOGY\naplastic anaemia,ELTROMBOPAG,CLINICAL HAEMATOLOGY\narthritis,ETANERCEPT,RHEUMATOLOGY\nasthma,BENRALIZUMAB|DUPILUMAB|INHALED|MEPOLIZUMAB|OMALIZUMAB|RESLIZUMAB,THORACIC MEDICINE\natopic dermatitis,ABROCITINIB|ALCLOMETASONE|BARICITINIB|CRISABOROLE|DUPILUMAB|PIMECROLIMUS,DERMATOLOGY\natrial fibrillation,APIXABAN|DABIGATRAN|DRONEDARONE|EDOXABAN|RIVAROXABAN|VERNAKALANT,CARDIOLOGY\nattention deficit hyperactivity disorder,ATOMOXETINE,MENTAL HEALTH\nattention-deficit hyperactivity disorder,METHYLPHENIDATE,MENTAL HEALTH\naxial spondyloarthritis,ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB|SECUKINUMAB|UPADACITINIB,RHEUMATOLOGY\nbasal cell carcinoma,VISMODEGIB,DERMATOLOGY\nbipolar disorder,LOXAPINE|OLANZAPINE,MENTAL HEALTH\nbladder,MIRABEGRON,MEDICAL ONCOLOGY\nbrca,OLAPARIB,MEDICAL ONCOLOGY\nbreast cancer,ABEMACICLIB|ALPELISIB|ANASTROZOLE|ATEZOLIZUMAB|BEVACIZUMAB|CAPECITABINE|DENOSUMAB|DOCETAXEL|ERIBULIN|EVEROLIMUS|FULVESTRANT|GEMCITABINE|INTRABEAM|LAPATINIB|NERATINIB|OLAPARIB|PACLITAXEL|PALBOCICLI|PALBOCICLIB|PEMBROLIZUMAB|PERTUZUMAB|RIBOCICLIB|SACITUZUMAB|TRASTUZUMAB|TUCATINIB|VINORELBINE,MEDICAL ONCOLOGY\ncardiomyopathy,TAFAMIDIS,CARDIOLOGY\ncardiovascular disease,ATORVASTATIN,CARDIOLOGY\ncervical cancer,TOPOTECAN,MEDICAL ONCOLOGY\ncholangiocarcinoma,PEMIGATINIB,MEDICAL ONCOLOGY\nchoroidal neovascularisation,AFLIBERCEPT|RANIBIZUMAB,OPHTHALMOLOGY\nchronic kidney disease,DAPAGLIFLOZIN|IMLIFIDASE|ROXADUSTAT,NEPHROLOGY\nchronic liver disease,AVATROMBOPAG|LUSUTROMBOPAG,GASTROENTEROLOGY\nchronic lymphocytic leukaemia,ACALABRUTINIB|BENDAMUSTINE|DUVELISIB|IBRUTINIB|IDELALISIB|OBINUTUZUMAB|OFATUMUMAB|RITUXIMAB|VENETOCLAX,CLINICAL HAEMATOLOGY\nchronic myeloid leukaemia,ASCIMINIB|BOSUTINIB|STANDARD-DOSE|DASATINIB|DASITINIB|NILOTINIB|PONATINIB,CLINICAL HAEMATOLOGY\nchronic obstructive pulmonary disease,ROFLUMILAST,THORACIC MEDICINE\ncolon cancer,CAPECITABINE,MEDICAL ONCOLOGY\ncolorectal cancer,BEVACIZUMAB|CAPECITABINE|IRINOTECAN,MEDICAL ONCOLOGY\nconstipation,LUBIPROSTONE|METHYLNALTREXONE|NALDEMEDINE|NALOXEGOL|PRUCALOPRIDE,GASTROENTEROLOGY\ncovid-19,NIRMATRELVIR,INFECTIOUS DISEASES\ncrohn's disease,INFLIXIMAB|VEDOLIZUMAB,GASTROENTEROLOGY\ncutaneous t-cell lymphoma,BRENTUXIMAB|CHLORMETHINE,CLINICAL HAEMATOLOGY\ncystic fibrosis,COLISTIMETHATE|LUMACAFTOR|MANNITOL,THORACIC MEDICINE\ncytomegalovirus,LETERMOVIR|MARIBAVIR,INFECTIOUS DISEASES\ndeep vein thrombosis,APIXABAN|DABIGATRAN|EDOXABAN|RIVAROXABAN,VASCULAR SURGERY\ndepression,ESKETAMINE,MENTAL HEALTH\ndiabetes,ERTUGLIFLOZIN|INHALED|AFLIBERCEPT|BROLUCIZUMAB|DEXAMETHASONE|FARICIMAB|FLUOCINOLONE|RANIBIZUMAB,DIABETIC MEDICINE\ndiabetes,ERTUGLIFLOZIN|INHALED|AFLIBERCEPT|BROLUCIZUMAB|DEXAMETHASONE|FARICIMAB|FLUOCINOLONE|RANIBIZUMAB,OPHTHALMOLOGY\ndiabetic retinopathy,RANIBUZIMAB,OPHTHALMOLOGY\ndiffuse large b-cell lymphoma,AXICABTAGENE|POLATUZUMAB|TISAGENLECLEUCEL,CLINICAL HAEMATOLOGY\ndravet syndrome,CANNABIDIOL|FENFLURAMINE,NEUROLOGY\ndrug misuse,BUPRENORPHINE|NALTREXONE,MENTAL HEALTH\ndry eye,CICLOSPORIN,OPHTHALMOLOGY\ndyspepsia,LANSOPRAZOLE,GASTROENTEROLOGY\nendometrial cancer,DOSTARLIMAB,MEDICAL ONCOLOGY\nepilepsy,CENOBAMATE|GABAPENTIN|RETIGABINE,NEUROLOGY\nfallopian tube,BEVACIZUMAB|NIRAPARIB|OLAPARIB|RUCAPARIB,MEDICAL ONCOLOGY\nfollicular lymphoma,DUVELISIB|IDELALISIB|LENALIDOMIDE|OBINUTUZUMAB|RITUXIMAB|TISAGENLECLEUCEL,CLINICAL HAEMATOLOGY\ngastric cancer,CAPECITABINE|RAMUCIRUMAB|TRASTUZUMAB|TRIFLURIDINE,MEDICAL ONCOLOGY\ngastro-oesophageal junction,NIVOLUMAB|PEMBROLIZUMAB,MEDICAL ONCOLOGY\ngiant cell arteritis,TOCILIZUMAB,RHEUMATOLOGY\nglioma,CARMUSTINE,MEDICAL ONCOLOGY\ngout,CANAKINUMAB|FEBUXOSTAT|LESINURAD,RHEUMATOLOGY\ngraft versus host disease,RUXOLITINIB,CLINICAL HAEMATOLOGY\ngranulomatosis with polyangiitis,AVACOPAN|MEPOLIZUMAB,RHEUMATOLOGY\ngrowth hormone deficiency,SOMATROPIN,ENDOCRINOLOGY\nhand eczema,ALITRETINOIN,DERMATOLOGY\nheart failure,DAPAGLIFLOZIN|EMPAGLIFLOZIN|IVABRADINE|SACUBITRIL|VERICIGUAT,CARDIOLOGY\nhepatitis b,ADEFOVIR,GASTROENTEROLOGY\nhepatitis c,BOCEPREVIR|DACLATASVIR|ELBASVIR|GLECAPREVIR|INTERFERON|LEDIPASVIR|OMBITASVIR|PEGINTERFERON|PEGYLATED|SIMEPREVIR|SOFOSBUVIR|TELAPREVIR,GASTROENTEROLOGY\nhepatocellular carcinoma,ATEZOLIZUMAB|CABOZANTINIB|LENVATINIB|RAMUCIRUMAB|REGORAFENIB|SELECTIVE|SORAFENIB,MEDICAL ONCOLOGY\nhiv,CABOTEGRAVIR,INFECTIOUS DISEASES\nhodgkin lymphoma,BRENTUXIMAB|NIVOLUMAB|PEMBROLIZUMAB,CLINICAL HAEMATOLOGY\nhormone receptor,ABEMACICLIB,MEDICAL ONCOLOGY\nhypercholesterolaemia,EZETIMIBE,CARDIOLOGY\nhyperparathyroidism,CINACALCET|ETELCALCETIDE,ENDOCRINOLOGY\nimmune thrombocytopenia,AVATROMBOPAG|FOSTAMATINIB,CLINICAL HAEMATOLOGY\ninfluenza,AMANTADINE|ZANAMIVIR|BALOXAVIR,INFECTIOUS DISEASES\ninsomnia,ZALEPLON,NEUROLOGY\nirritable bowel syndrome,ELUXADOLINE,GASTROENTEROLOGY\nischaemic stroke,ALTEPLASE,STROKE MEDICINE\njuvenile idiopathic arthritis,ABATECEPT|CANAKINUMAB|TOCILIZUMAB|TOFACITINIB,RHEUMATOLOGY\nkidney transplant,BASILIXIMAB,NEPHROLOGY\nleukaemia,FLUDARABINE|IMATINIB,CLINICAL HAEMATOLOGY\nlung cancer,ATEZOLIZUMAB|DURVALUMAB|GEFITINIB|ORAL|NINTEDANIB,MEDICAL ONCOLOGY\nlymphoma,BENDAMUSTINE|CRIZOTINIB|PIXANTRONE|RITUXIMAB,CLINICAL HAEMATOLOGY\nmacular degeneration,AFLIBERCEPT|BROLUCIZUMAB|FARICIMAB|RANIBIZUMAB,OPHTHALMOLOGY\nmacular oedema,AFLIBERCEPT|RANIBIZUMAB,OPHTHALMOLOGY\nmajor depressive episodes,AGOMELATINE|VORTIOXETINE,MENTAL HEALTH\nmalignant melanoma,VEMURAFENIB,MEDICAL ONCOLOGY\nmalignant pleural mesothelioma,NIVOLUMAB|PEMETREXED,MEDICAL ONCOLOGY\nmanic episode,ARIPIPRAZOLE,MENTAL HEALTH\nmantle cell lymphoma,AUTOLOGOUS|BORTEZOMIB|IBRUTINIB|LENALIDOMIDE|TEMSIROLIMUS,CLINICAL HAEMATOLOGY\nmelanoma,COBIMETINIB|DABRAFENIB|ENCORAFENIB|IPILIMUMAB|NIVOLUMAB|PEMBROLIZUMAB|TALIMOGENE|TRAMETINIB,MEDICAL ONCOLOGY\nmerkel cell carcinoma,AVELUMAB,MEDICAL ONCOLOGY\nmigraine,BOTULINUM|EPTINEZUMAB|ERENUMAB|FREMANEZUMAB|GALCANEZUMAB,NEUROLOGY\nmotor neurone disease,RILUZOLE,NEUROLOGY\nmultiple myeloma,BORTEZOMIB|THALIDOMIDE|CARFILZOMIB|DARATUMUMAB|DENOSUMAB|ELOTUZUMAB|ISATUXIMAB|IXAZOMIB|LENALIDOMIDE|PANOBINOSTAT|POMALIDOMIDE|SELINEXOR|TECLISTAMAB,CLINICAL HAEMATOLOGY\nmultiple sclerosis,ALEMTUZUMAB|BETA|CLADRIBINE|DACLIZUMAB|DIMETHYL|DIROXIMEL|FINGOLIMOD|INTERFERON|NATALIZUMAB|OCRELIZUMAB|OZANIMOD|PEGINTERFERON|PONESIMOD|SIPONIMOD|TERIFLUNOMIDE,NEUROLOGY\nmyelodysplastic,LENALIDOMIDE|LUSPATERCEPT,CLINICAL HAEMATOLOGY\nmyelofibrosis,FEDRATINIB|RUXOLITINIB,CLINICAL HAEMATOLOGY\nmyocardial infarction,ALTEPLASE|BIVALIRUDIN|TICAGRELOR,CARDIOLOGY\nmyotonia,MEXILETINE,NEUROLOGY\nnarcolepsy,SOLRIAMFETOL,NEUROLOGY\nneuroendocrine tumour,EVEROLIMUS|LUTETIUM,MEDICAL ONCOLOGY\nnon-small cell lung cancer,ATEZOLIZMAB|DOCETAXEL|ERLOTINIB|PEMETREXED,MEDICAL ONCOLOGY\nnon-small-cell lung cancer,AFATINIB|ALECTINIB|AMIVANTAMAB|ATEZOLIZUMAB|BEVACIZUMAB|BRIGATINIB|CEMIPLIMAB|CERITINIB|CRIZOTINIB|DABRAFENIB|DACOMITINIB|DURVALUMAB|ENTRECTINIB|ERLOTINIB|GEFITINIB|LORLATINIB|MOBOCERTINIB|NECITUMUMAB|NIVOLUMAB|OSIMERTINIB|PACLITAXEL|PEMBROLIZUMAB|PEMETREXED|PRALSETINIB|RAMUCIRUMAB|SELPERCATINIB|SOTORASIB|TEPOTINIB,MEDICAL ONCOLOGY\nobesity,LIRAGLUTIDE|NALTREXONE|ORLISTAT|SEMAGLUTIDE|SIBUTRAMINE,ENDOCRINOLOGY\noesophageal cancer,NIVOLUMAB,MEDICAL ONCOLOGY\nosteoarthritis,CELECOXIB,RHEUMATOLOGY\nosteoporosis,ALENDRONATE|DENOSUMAB|ORAL|ROMOSOZUMAB,RHEUMATOLOGY\nosteosarcoma,MIFAMURTIDE,MEDICAL ONCOLOGY\novarian cancer,BEVACIZUMAB|PACLITAXEL|PEGYLATED|TOPOTECAN|TRABECTEDIN,MEDICAL ONCOLOGY\noverweight,RIMONABANT,ENDOCRINOLOGY\npancreatic cancer,GEMCITABINE|OLAPARIB|PACLITAXEL|PEGYLATED,MEDICAL ONCOLOGY\nparoxysmal nocturnal haemoglobinuria,PEGCETACOPLAN|RAVULIZUMAB,CLINICAL HAEMATOLOGY\nperipheral arterial disease,NAFTIDROFYRYL,VASCULAR SURGERY\nplaque psoriasis,ADALIMUMAB|APREMILAST|BIMEKIZUMAB|BRODALUMAB|CERTOLIZUMAB|GUSELKUMAB|INFLIXIMAB|IXEKIZUMAB|RISANKIZUMAB|SECUKINUMAB|TILDRAKIZUAMB|USTEKINUMAB,DERMATOLOGY\npolycystic kidney disease,TOLVAPTAN,NEPHROLOGY\npolycythaemia vera,RUXOLITINIB,CLINICAL HAEMATOLOGY\npregnancy,ROUTINE,OBSTETRICS\nprimary biliary cholangitis,OBETICHOLIC,GASTROENTEROLOGY\nprimary hypercholesterolaemia,ALIROCUMAB|EVOLOCUMAB,CARDIOLOGY\nprostate cancer,ABIRATERONE|APALUTAMIDE|CABAZITAXEL|DAROLUTAMIDE|DEGARELIX|DENOSUMAB|DOCETAXEL|ENZALUTAMIDE|OLAPARIB|PADELIPORFIN|RADIUM-|RADIUM|SIPULEUCEL-T,MEDICAL ONCOLOGY\npsoriasis,EFALUZIMAB,DERMATOLOGY\npsoriatic arthritis,ABATACEPT|ADALIMUMAB|APREMILAST|CERTOLIZUMAB|ETANERCEPT|GOLIMUMAB|GUSELKUMAB|IXEKIZUMAB|RISANKIZUMAB|TOFACITINIB|UPADACITINIB|USTEKINUMAB,RHEUMATOLOGY\npulmonary embolism,APIXABAN|DABIGATRAN|EDOXABAN|RIVAROXABAN,THORACIC MEDICINE\npulmonary fibrosis,NINTEDANIB|PIRFENIDONE,THORACIC MEDICINE\nrelapsing multiple sclerosis,OFATUMUMAB,NEUROLOGY\nrenal cell carcinoma,AVELUMAB|AXITINIB|BEVACIZUMAB|CABOZANTINIB|EVEROLIMUS|LENVATINIB|NIVOLUMAB|PAZOPANIB|PEMBROLIZUMAB|SUNITINIB|TIVOZANIB,MEDICAL ONCOLOGY\nrenal transplantation,BASILIXIMAB|INDUCTION,NEPHROLOGY\nretinal vein occlusion,AFLIBERCEPT|DEXAMETHASONE|RANIBIZUMAB,OPHTHALMOLOGY\nrheumatoid arthritis,ABATACEPT|ADALIMUMAB|ANAKINRA|BARICITINIB|CELECOXIB|CERTOLIZUMAB|ETANERCEPT|FILGOTINIB|GOLIMUMAB|RITUXIMAB|SARILUMAB|TOCILIZUMAB|TOFACITINIB|UPADACITINIB,RHEUMATOLOGY\nrivaroxaban,ANDEXANET,CARDIOLOGY\nschizophrenia,AMISULPRIDE|ARIPIPRAZOLE|LOXAPINE,MENTAL HEALTH\nseizures,CANNABIDIOL,NEUROLOGY\nsepsis,DROTRECOGIN,INFECTIOUS DISEASES\nsevere persistent allergic asthma,OMALIZUMAB,THORACIC MEDICINE\nshort bowel syndrome,TEDUGLUTIDE,GASTROENTEROLOGY\nsickle cell disease,CRIZANLIZUMAB,CLINICAL HAEMATOLOGY\nsleep apnoea,PITOLISANT|SOLRIAMFETOL,THORACIC MEDICINE\nsmoking cessation,NICOTINE|VARENICLINE,THORACIC MEDICINE\nsoft tissue sarcoma,INTRAVENOUS|NBTXR-|OLARATUMAB,MEDICAL ONCOLOGY\nspinal muscular atrophy,NUSINERSEN|RISDIPLAM,NEUROLOGY\nsquamous cell,CETUXIMAB,MEDICAL ONCOLOGY\nsquamous cell carcinoma,CEMIPLIMAB|NIVOLUMAB|PEMBROLIZUMAB,MEDICAL ONCOLOGY\nstem cell transplant,MELPHALAN|TREOSULFAN,CLINICAL HAEMATOLOGY\nstroke,APIXABAN|DABIGATRAN|EDOXABAN|RIVAROXABAN,STROKE MEDICINE\nsystemic lupus erythematosus,ANIFROLUMAB|ETANERCEPT,RHEUMATOLOGY\nsystemic mastocytosis,MIDOSTAURIN,CLINICAL HAEMATOLOGY\nthrombocytopenic purpura,ELTROMBOPAG|ROMIPLOSTIM,CLINICAL HAEMATOLOGY\nthrombotic thrombocytopenic purpura,CAPLACIZUMAB,CLINICAL HAEMATOLOGY\nthyroid cancer,CABOZANTINIB|LENVATINIB|SELPERCATINIB|VANDETANIB,MEDICAL ONCOLOGY\ntophaceous gout,PEGLOTICASE,RHEUMATOLOGY\ntransitional cell carcinoma,VINFLUNINE,MEDICAL ONCOLOGY\ntuberous sclerosis,CANNABIDIOL,NEUROLOGY\ntype 1 diabetes,CONTINUOUS|DAPAGLIFLOZIN|INSULIN|SOTAGLIFLOZIN,DIABETIC MEDICINE\ntype 2 diabetes,CANAGLIFLOZIN|CONTINUOUS|DAPAGLIFLOZIN|EMPAGLIFLOZIN|ERTUGLIFLOZIN|EXENATIDE|FINERENONE|INSULIN|LIRAGLUTIDE|PIOGLITAZONE|ROSIGLITAZONE,DIABETIC MEDICINE\nulcerative colitis,ADALIMUMAB|INFLIXIMAB|FILGOTINIB|OZANIMOD|TOFACITINIB|UPADACITINIB|USTEKINUMAB|VEDOLIZUMAB,GASTROENTEROLOGY\nurothelial carcinoma,ATEZOLIZUMAB|PEMBROLIZUMAB,MEDICAL ONCOLOGY\nurticaria,OMALIZUMAB,DERMATOLOGY\nuterine fibroids,RELUGOLIX,GYNAECOLOGY\nuveitis,ADALIMUMAB|FLUOCINOLONE,OPHTHALMOLOGY\nvascular disease,MODIFIED-RELEASE|CLOPIDOGREL,VASCULAR SURGERY\nvasculitis,RITUXIMAB,RHEUMATOLOGY\nvenous thromboembolism,APIXABAN|DABIGATRAN|RIVAROXABAN,CLINICAL HAEMATOLOGY\n","numLines":167,"startLine":1,"totalLines":167}}}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013gSjU7MeMnCV9sYiUzUdur","type":"tool_result","content":"     1ÔåÆ\"\"\"\n     2ÔåÆDiagnosis lookup module for NHS Patient Pathway Analysis.\n     3ÔåÆ\n     4ÔåÆProvides functions to validate patient indications by checking GP diagnosis records\n     5ÔåÆagainst SNOMED cluster codes. Uses the drug-to-cluster mapping from\n     6ÔåÆdrug_indication_clusters.csv and queries Snowflake for SNOMED codes and GP records.\n     7ÔåÆ\n     8ÔåÆKey workflow:\n     9ÔåÆ1. Get drug's valid indication clusters from local mapping\n    10ÔåÆ2. Get all SNOMED codes for those clusters from Snowflake\n    11ÔåÆ3. Check if patient has any of those SNOMED codes in GP records\n    12ÔåÆ4. Report indication validation status\n    13ÔåÆ\n    14ÔåÆIMPORTANT: HCD activity data indication codes are UNRELIABLE. This module uses\n    15ÔåÆGP/Primary Care data (PrimaryCareClinicalCoding) as the authoritative source.\n    16ÔåÆ\"\"\"\n    17ÔåÆ\n    18ÔåÆfrom dataclasses import dataclass, field\n    19ÔåÆfrom datetime import date, datetime\n    20ÔåÆfrom pathlib import Path\n    21ÔåÆfrom typing import Optional, Callable, Any, cast, TYPE_CHECKING\n    22ÔåÆimport csv\n    23ÔåÆ\n    24ÔåÆif TYPE_CHECKING:\n    25ÔåÆ    import pandas as pd\n    26ÔåÆ\n    27ÔåÆfrom core.logging_config import get_logger\n    28ÔåÆfrom data_processing.database import DatabaseManager, default_db_manager\n    29ÔåÆfrom data_processing.snowflake_connector import (\n    30ÔåÆ    SnowflakeConnector,\n    31ÔåÆ    get_connector,\n    32ÔåÆ    is_snowflake_available,\n    33ÔåÆ    is_snowflake_configured,\n    34ÔåÆ    SNOWFLAKE_AVAILABLE,\n    35ÔåÆ)\n    36ÔåÆfrom data_processing.cache import get_cache, is_cache_enabled\n    37ÔåÆ\n    38ÔåÆlogger = get_logger(__name__)\n    39ÔåÆ\n    40ÔåÆ\n    41ÔåÆ@dataclass\n    42ÔåÆclass ClusterSnomedCodes:\n    43ÔåÆ    \"\"\"SNOMED codes for a clinical coding cluster.\"\"\"\n    44ÔåÆ    cluster_id: str\n    45ÔåÆ    cluster_description: str\n    46ÔåÆ    snomed_codes: list[str] = field(default_factory=list)\n    47ÔåÆ    snomed_descriptions: dict[str, str] = field(default_factory=dict)\n    48ÔåÆ\n    49ÔåÆ    @property\n    50ÔåÆ    def code_count(self) -> int:\n    51ÔåÆ        return len(self.snomed_codes)\n    52ÔåÆ\n    53ÔåÆ\n    54ÔåÆ@dataclass\n    55ÔåÆclass IndicationValidationResult:\n    56ÔåÆ    \"\"\"Result of validating a patient's indication for a drug.\"\"\"\n    57ÔåÆ    patient_pseudonym: str\n    58ÔåÆ    drug_name: str\n    59ÔåÆ    has_valid_indication: bool\n    60ÔåÆ    matched_cluster_id: Optional[str] = None\n    61ÔåÆ    matched_snomed_code: Optional[str] = None\n    62ÔåÆ    matched_snomed_description: Optional[str] = None\n    63ÔåÆ    checked_clusters: list[str] = field(default_factory=list)\n    64ÔåÆ    total_codes_checked: int = 0\n    65ÔåÆ    source: str = \"GP_SNOMED\"  # GP_SNOMED | NONE\n    66ÔåÆ    error_message: Optional[str] = None\n    67ÔåÆ\n    68ÔåÆ\n    69ÔåÆ@dataclass\n    70ÔåÆclass DrugIndicationMatchRate:\n    71ÔåÆ    \"\"\"Match rate statistics for a drug's indication validation.\"\"\"\n    72ÔåÆ    drug_name: str\n    73ÔåÆ    total_patients: int\n    74ÔåÆ    patients_with_indication: int\n    75ÔåÆ    patients_without_indication: int\n    76ÔåÆ    match_rate: float  # 0.0 to 1.0\n    77ÔåÆ    clusters_checked: list[str] = field(default_factory=list)\n    78ÔåÆ    sample_unmatched: list[str] = field(default_factory=list)  # Sample patient IDs\n    79ÔåÆ\n    80ÔåÆ\n    81ÔåÆ@dataclass\n    82ÔåÆclass DrugSnomedMapping:\n    83ÔåÆ    \"\"\"SNOMED code mapping for a drug from ref_drug_snomed_mapping.\"\"\"\n    84ÔåÆ    snomed_code: str\n    85ÔåÆ    snomed_description: str\n    86ÔåÆ    search_term: str\n    87ÔåÆ    primary_directorate: str\n    88ÔåÆ    indication: str = \"\"\n    89ÔåÆ    ta_id: str = \"\"\n    90ÔåÆ\n    91ÔåÆ\n    92ÔåÆ@dataclass\n    93ÔåÆclass DirectSnomedMatchResult:\n    94ÔåÆ    \"\"\"Result of direct SNOMED code lookup in GP records.\"\"\"\n    95ÔåÆ    patient_pseudonym: str\n    96ÔåÆ    matched: bool\n    97ÔåÆ    snomed_code: Optional[str] = None\n    98ÔåÆ    snomed_description: Optional[str] = None\n    99ÔåÆ    search_term: Optional[str] = None\n   100ÔåÆ    primary_directorate: Optional[str] = None\n   101ÔåÆ    event_date: Optional[datetime] = None\n   102ÔåÆ    source: str = \"DIRECT_SNOMED\"  # DIRECT_SNOMED | NONE\n   103ÔåÆ\n   104ÔåÆ\n   105ÔåÆ@dataclass\n   106ÔåÆclass DirectorateAssignment:\n   107ÔåÆ    \"\"\"Result of directorate assignment for a patient-drug combination.\"\"\"\n   108ÔåÆ    upid: str\n   109ÔåÆ    drug_name: str\n   110ÔåÆ    directorate: Optional[str]\n   111ÔåÆ    search_term: Optional[str] = None\n   112ÔåÆ    source: str = \"FALLBACK\"  # DIAGNOSIS | FALLBACK\n   113ÔåÆ    snomed_code: Optional[str] = None\n   114ÔåÆ    event_date: Optional[datetime] = None\n   115ÔåÆ\n   116ÔåÆ\n   117ÔåÆdef get_drug_clusters(\n   118ÔåÆ    drug_name: str,\n   119ÔåÆ    db_manager: Optional[DatabaseManager] = None\n   120ÔåÆ) -> list[dict]:\n   121ÔåÆ    \"\"\"\n   122ÔåÆ    Get all SNOMED cluster mappings for a drug from local SQLite.\n   123ÔåÆ\n   124ÔåÆ    Args:\n   125ÔåÆ        drug_name: Drug name to look up (case-insensitive)\n   126ÔåÆ        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n   127ÔåÆ\n   128ÔåÆ    Returns:\n   129ÔåÆ        List of dicts with keys: drug_name, indication, cluster_id,\n   130ÔåÆ        cluster_description, nice_ta_reference\n   131ÔåÆ    \"\"\"\n   132ÔåÆ    if db_manager is None:\n   133ÔåÆ        db_manager = default_db_manager\n   134ÔåÆ\n   135ÔåÆ    query = \"\"\"\n   136ÔåÆ        SELECT drug_name, indication, cluster_id, cluster_description, nice_ta_reference\n   137ÔåÆ        FROM ref_drug_indication_clusters\n   138ÔåÆ        WHERE UPPER(drug_name) = UPPER(?)\n   139ÔåÆ        ORDER BY indication, cluster_id\n   140ÔåÆ    \"\"\"\n   141ÔåÆ\n   142ÔåÆ    try:\n   143ÔåÆ        with db_manager.get_connection() as conn:\n   144ÔåÆ            cursor = conn.execute(query, (drug_name,))\n   145ÔåÆ            rows = cursor.fetchall()\n   146ÔåÆ\n   147ÔåÆ            results = []\n   148ÔåÆ            for row in rows:\n   149ÔåÆ                results.append({\n   150ÔåÆ                    \"drug_name\": row[\"drug_name\"],\n   151ÔåÆ                    \"indication\": row[\"indication\"],\n   152ÔåÆ                    \"cluster_id\": row[\"cluster_id\"],\n   153ÔåÆ                    \"cluster_description\": row[\"cluster_description\"],\n   154ÔåÆ                    \"nice_ta_reference\": row[\"nice_ta_reference\"],\n   155ÔåÆ                })\n   156ÔåÆ\n   157ÔåÆ            logger.debug(f\"Found {len(results)} cluster mappings for drug '{drug_name}'\")\n   158ÔåÆ            return results\n   159ÔåÆ\n   160ÔåÆ    except Exception as e:\n   161ÔåÆ        logger.error(f\"Error getting clusters for drug '{drug_name}': {e}\")\n   162ÔåÆ        return []\n   163ÔåÆ\n   164ÔåÆ\n   165ÔåÆdef get_drug_cluster_ids(\n   166ÔåÆ    drug_name: str,\n   167ÔåÆ    db_manager: Optional[DatabaseManager] = None\n   168ÔåÆ) -> list[str]:\n   169ÔåÆ    \"\"\"\n   170ÔåÆ    Get unique cluster IDs for a drug.\n   171ÔåÆ\n   172ÔåÆ    Args:\n   173ÔåÆ        drug_name: Drug name to look up\n   174ÔåÆ        db_manager: Optional DatabaseManager\n   175ÔåÆ\n   176ÔåÆ    Returns:\n   177ÔåÆ        List of unique cluster IDs\n   178ÔåÆ    \"\"\"\n   179ÔåÆ    clusters = get_drug_clusters(drug_name, db_manager)\n   180ÔåÆ    return list(set(c[\"cluster_id\"] for c in clusters))\n   181ÔåÆ\n   182ÔåÆ\n   183ÔåÆdef get_drug_snomed_codes(\n   184ÔåÆ    drug_name: str,\n   185ÔåÆ    db_manager: Optional[DatabaseManager] = None\n   186ÔåÆ) -> list[DrugSnomedMapping]:\n   187ÔåÆ    \"\"\"\n   188ÔåÆ    Get all SNOMED codes for a drug from local ref_drug_snomed_mapping table.\n   189ÔåÆ\n   190ÔåÆ    This uses the enriched mapping CSV data loaded into SQLite, which provides\n   191ÔåÆ    direct SNOMED-to-drug mappings with Search_Term and PrimaryDirectorate.\n   192ÔåÆ\n   193ÔåÆ    Args:\n   194ÔåÆ        drug_name: Drug name to look up (case-insensitive, matches cleaned_drug_name)\n   195ÔåÆ        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n   196ÔåÆ\n   197ÔåÆ    Returns:\n   198ÔåÆ        List of DrugSnomedMapping with snomed_code, snomed_description,\n   199ÔåÆ        search_term, primary_directorate, indication, ta_id\n   200ÔåÆ    \"\"\"\n   201ÔåÆ    if db_manager is None:\n   202ÔåÆ        db_manager = default_db_manager\n   203ÔåÆ\n   204ÔåÆ    query = \"\"\"\n   205ÔåÆ        SELECT DISTINCT\n   206ÔåÆ            snomed_code,\n   207ÔåÆ            snomed_description,\n   208ÔåÆ            search_term,\n   209ÔåÆ            primary_directorate,\n   210ÔåÆ            indication,\n   211ÔåÆ            ta_id\n   212ÔåÆ        FROM ref_drug_snomed_mapping\n   213ÔåÆ        WHERE UPPER(cleaned_drug_name) = UPPER(?)\n   214ÔåÆ           OR UPPER(drug_name) = UPPER(?)\n   215ÔåÆ        ORDER BY search_term, snomed_code\n   216ÔåÆ    \"\"\"\n   217ÔåÆ\n   218ÔåÆ    try:\n   219ÔåÆ        with db_manager.get_connection() as conn:\n   220ÔåÆ            cursor = conn.execute(query, (drug_name, drug_name))\n   221ÔåÆ            rows = cursor.fetchall()\n   222ÔåÆ\n   223ÔåÆ            results = []\n   224ÔåÆ            for row in rows:\n   225ÔåÆ                results.append(DrugSnomedMapping(\n   226ÔåÆ                    snomed_code=row[\"snomed_code\"],\n   227ÔåÆ                    snomed_description=row[\"snomed_description\"] or \"\",\n   228ÔåÆ                    search_term=row[\"search_term\"] or \"\",\n   229ÔåÆ                    primary_directorate=row[\"primary_directorate\"] or \"\",\n   230ÔåÆ                    indication=row[\"indication\"] or \"\",\n   231ÔåÆ                    ta_id=row[\"ta_id\"] or \"\",\n   232ÔåÆ                ))\n   233ÔåÆ\n   234ÔåÆ            logger.debug(f\"Found {len(results)} SNOMED mappings for drug '{drug_name}'\")\n   235ÔåÆ            return results\n   236ÔåÆ\n   237ÔåÆ    except Exception as e:\n   238ÔåÆ        logger.error(f\"Error getting SNOMED codes for drug '{drug_name}': {e}\")\n   239ÔåÆ        return []\n   240ÔåÆ\n   241ÔåÆ\n   242ÔåÆdef patient_has_indication_direct(\n   243ÔåÆ    patient_pseudonym: str,\n   244ÔåÆ    drug_snomed_mappings: list[DrugSnomedMapping],\n   245ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   246ÔåÆ    before_date: Optional[date] = None,\n   247ÔåÆ) -> DirectSnomedMatchResult:\n   248ÔåÆ    \"\"\"\n   249ÔåÆ    Check if patient has any of the SNOMED codes in their GP records.\n   250ÔåÆ\n   251ÔåÆ    This is the direct SNOMED lookup - it queries PrimaryCareClinicalCoding\n   252ÔåÆ    for exact SNOMED code matches (not via cluster). Returns the most recent\n   253ÔåÆ    match by EventDateTime if multiple matches exist.\n   254ÔåÆ\n   255ÔåÆ    Args:\n   256ÔåÆ        patient_pseudonym: Patient's pseudonymised NHS number\n   257ÔåÆ        drug_snomed_mappings: List of DrugSnomedMapping from get_drug_snomed_codes()\n   258ÔåÆ        connector: Optional SnowflakeConnector (defaults to singleton)\n   259ÔåÆ        before_date: Optional date - only check diagnoses before this date\n   260ÔåÆ\n   261ÔåÆ    Returns:\n   262ÔåÆ        DirectSnomedMatchResult with match details (most recent by EventDateTime)\n   263ÔåÆ    \"\"\"\n   264ÔåÆ    result = DirectSnomedMatchResult(\n   265ÔåÆ        patient_pseudonym=patient_pseudonym,\n   266ÔåÆ        matched=False,\n   267ÔåÆ        source=\"NONE\",\n   268ÔåÆ    )\n   269ÔåÆ\n   270ÔåÆ    if not drug_snomed_mappings:\n   271ÔåÆ        return result\n   272ÔåÆ\n   273ÔåÆ    if not SNOWFLAKE_AVAILABLE:\n   274ÔåÆ        logger.warning(\"Snowflake connector not available\")\n   275ÔåÆ        return result\n   276ÔåÆ\n   277ÔåÆ    if not is_snowflake_configured():\n   278ÔåÆ        logger.warning(\"Snowflake not configured - cannot check GP records\")\n   279ÔåÆ        return result\n   280ÔåÆ\n   281ÔåÆ    if connector is None:\n   282ÔåÆ        connector = get_connector()\n   283ÔåÆ\n   284ÔåÆ    # Build lookup dict for mapping snomed_code -> (search_term, primary_directorate, snomed_description)\n   285ÔåÆ    snomed_lookup = {\n   286ÔåÆ        m.snomed_code: (m.search_term, m.primary_directorate, m.snomed_description)\n   287ÔåÆ        for m in drug_snomed_mappings\n   288ÔåÆ    }\n   289ÔåÆ\n   290ÔåÆ    # Get unique SNOMED codes\n   291ÔåÆ    snomed_codes = list(snomed_lookup.keys())\n   292ÔåÆ\n   293ÔåÆ    # Build placeholders for SNOMED codes\n   294ÔåÆ    placeholders = \", \".join([\"%s\"] * len(snomed_codes))\n   295ÔåÆ\n   296ÔåÆ    # Query to find most recent matching SNOMED code in GP records\n   297ÔåÆ    query = f'''\n   298ÔåÆ        SELECT\n   299ÔåÆ            \"SNOMEDCode\",\n   300ÔåÆ            \"EventDateTime\"\n   301ÔåÆ        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n   302ÔåÆ        WHERE \"PatientPseudonym\" = %s\n   303ÔåÆ            AND \"SNOMEDCode\" IN ({placeholders})\n   304ÔåÆ    '''\n   305ÔåÆ\n   306ÔåÆ    params: list = [patient_pseudonym] + snomed_codes\n   307ÔåÆ\n   308ÔåÆ    if before_date:\n   309ÔåÆ        query += ' AND \"EventDateTime\" < %s'\n   310ÔåÆ        params.append(before_date.isoformat())\n   311ÔåÆ\n   312ÔåÆ    query += ' ORDER BY \"EventDateTime\" DESC LIMIT 1'\n   313ÔåÆ\n   314ÔåÆ    try:\n   315ÔåÆ        results = connector.execute_dict(query, tuple(params))\n   316ÔåÆ\n   317ÔåÆ        if results:\n   318ÔåÆ            row = results[0]\n   319ÔåÆ            matched_code = row.get(\"SNOMEDCode\")\n   320ÔåÆ            event_dt = row.get(\"EventDateTime\")\n   321ÔåÆ\n   322ÔåÆ            if matched_code and matched_code in snomed_lookup:\n   323ÔåÆ                search_term, primary_dir, snomed_desc = snomed_lookup[matched_code]\n   324ÔåÆ\n   325ÔåÆ                return DirectSnomedMatchResult(\n   326ÔåÆ                    patient_pseudonym=patient_pseudonym,\n   327ÔåÆ                    matched=True,\n   328ÔåÆ                    snomed_code=matched_code,\n   329ÔåÆ                    snomed_description=snomed_desc,\n   330ÔåÆ                    search_term=search_term,\n   331ÔåÆ                    primary_directorate=primary_dir,\n   332ÔåÆ                    event_date=event_dt,\n   333ÔåÆ                    source=\"DIRECT_SNOMED\",\n   334ÔåÆ                )\n   335ÔåÆ\n   336ÔåÆ        return result\n   337ÔåÆ\n   338ÔåÆ    except Exception as e:\n   339ÔåÆ        logger.error(f\"Error checking direct SNOMED for patient '{patient_pseudonym}': {e}\")\n   340ÔåÆ        return result\n   341ÔåÆ\n   342ÔåÆ\n   343ÔåÆdef get_directorate_from_diagnosis(\n   344ÔåÆ    upid: str,\n   345ÔåÆ    drug_name: str,\n   346ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   347ÔåÆ    db_manager: Optional[DatabaseManager] = None,\n   348ÔåÆ    before_date: Optional[date] = None,\n   349ÔåÆ) -> DirectorateAssignment:\n   350ÔåÆ    \"\"\"\n   351ÔåÆ    Get directorate assignment for a patient-drug combination using diagnosis-based lookup.\n   352ÔåÆ\n   353ÔåÆ    This function attempts to assign a directorate based on the patient's GP records\n   354ÔåÆ    (direct SNOMED code matching). If no match is found, it returns a FALLBACK result\n   355ÔåÆ    indicating that the caller should use alternative assignment methods (e.g.,\n   356ÔåÆ    department_identification() from tools/data.py).\n   357ÔåÆ\n   358ÔåÆ    Workflow:\n   359ÔåÆ    1. Get all SNOMED codes for the drug from ref_drug_snomed_mapping\n   360ÔåÆ    2. Query patient's GP records for matching SNOMED codes\n   361ÔåÆ    3. If match found ÔåÆ return diagnosis-based directorate and search_term\n   362ÔåÆ    4. If no match ÔåÆ return FALLBACK result (caller handles fallback logic)\n   363ÔåÆ\n   364ÔåÆ    Args:\n   365ÔåÆ        upid: Patient's unique patient ID (Provider Code[:3] + PersonKey)\n   366ÔåÆ        drug_name: Drug name to look up\n   367ÔåÆ        connector: Optional SnowflakeConnector (defaults to singleton)\n   368ÔåÆ        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n   369ÔåÆ        before_date: Optional date - only check diagnoses before this date\n   370ÔåÆ\n   371ÔåÆ    Returns:\n   372ÔåÆ        DirectorateAssignment with directorate, search_term, and source\n   373ÔåÆ    \"\"\"\n   374ÔåÆ    result = DirectorateAssignment(\n   375ÔåÆ        upid=upid,\n   376ÔåÆ        drug_name=drug_name,\n   377ÔåÆ        directorate=None,\n   378ÔåÆ        source=\"FALLBACK\",\n   379ÔåÆ    )\n   380ÔåÆ\n   381ÔåÆ    # Step 1: Get SNOMED codes for the drug\n   382ÔåÆ    drug_snomed_mappings = get_drug_snomed_codes(drug_name, db_manager)\n   383ÔåÆ\n   384ÔåÆ    if not drug_snomed_mappings:\n   385ÔåÆ        logger.debug(f\"No SNOMED mappings found for drug '{drug_name}' - using fallback\")\n   386ÔåÆ        return result\n   387ÔåÆ\n   388ÔåÆ    # Step 2: Check Snowflake availability\n   389ÔåÆ    if not SNOWFLAKE_AVAILABLE:\n   390ÔåÆ        logger.debug(\"Snowflake not available - using fallback\")\n   391ÔåÆ        return result\n   392ÔåÆ\n   393ÔåÆ    if not is_snowflake_configured():\n   394ÔåÆ        logger.debug(\"Snowflake not configured - using fallback\")\n   395ÔåÆ        return result\n   396ÔåÆ\n   397ÔåÆ    # Step 3: Get patient pseudonym from UPID\n   398ÔåÆ    # UPID format is Provider Code (3 chars) + PersonKey\n   399ÔåÆ    # We need to query Snowflake to get the PatientPseudonym for this PersonKey\n   400ÔåÆ    # However, patient_has_indication_direct expects PatientPseudonym, not UPID\n   401ÔåÆ    # For now, we'll use UPID as the identifier - the actual integration\n   402ÔåÆ    # will need to happen at the DataFrame level where we have PersonKey\n   403ÔåÆ    #\n   404ÔåÆ    # NOTE: This function will be called from the pipeline where we have\n   405ÔåÆ    # access to PatientPseudonym. The UPID is passed for logging/tracking.\n   406ÔåÆ\n   407ÔåÆ    # Actually, looking at the pipeline, we need PatientPseudonym, not UPID.\n   408ÔåÆ    # The caller should pass the PatientPseudonym or we need to look it up.\n   409ÔåÆ    # For now, let's assume the caller will use this in a batch context\n   410ÔåÆ    # where they can map UPID -> PatientPseudonym.\n   411ÔåÆ\n   412ÔåÆ    # Let me reconsider: the function signature takes UPID but we need\n   413ÔåÆ    # PatientPseudonym for Snowflake. In the pipeline context (fetch_and_transform_data),\n   414ÔåÆ    # we'll have the PersonKey column which IS the PatientPseudonym.\n   415ÔåÆ    # So UPID = ProviderCode[:3] + PersonKey, and PersonKey = PatientPseudonym.\n   416ÔåÆ    #\n   417ÔåÆ    # We can extract PatientPseudonym from UPID by removing the first 3 chars.\n   418ÔåÆ    patient_pseudonym = upid[3:] if len(upid) > 3 else upid\n   419ÔåÆ\n   420ÔåÆ    # Step 4: Check patient's GP records for matching SNOMED codes\n   421ÔåÆ    match_result = patient_has_indication_direct(\n   422ÔåÆ        patient_pseudonym=patient_pseudonym,\n   423ÔåÆ        drug_snomed_mappings=drug_snomed_mappings,\n   424ÔåÆ        connector=connector,\n   425ÔåÆ        before_date=before_date,\n   426ÔåÆ    )\n   427ÔåÆ\n   428ÔåÆ    if match_result.matched and match_result.primary_directorate:\n   429ÔåÆ        return DirectorateAssignment(\n   430ÔåÆ            upid=upid,\n   431ÔåÆ            drug_name=drug_name,\n   432ÔåÆ            directorate=match_result.primary_directorate,\n   433ÔåÆ            search_term=match_result.search_term,\n   434ÔåÆ            source=\"DIAGNOSIS\",\n   435ÔåÆ            snomed_code=match_result.snomed_code,\n   436ÔåÆ            event_date=match_result.event_date,\n   437ÔåÆ        )\n   438ÔåÆ\n   439ÔåÆ    # No match found - return fallback result\n   440ÔåÆ    return result\n   441ÔåÆ\n   442ÔåÆ\n   443ÔåÆdef get_cluster_snomed_codes(\n   444ÔåÆ    cluster_id: str,\n   445ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   446ÔåÆ    use_cache: bool = True,\n   447ÔåÆ) -> ClusterSnomedCodes:\n   448ÔåÆ    \"\"\"\n   449ÔåÆ    Get all SNOMED codes for a cluster from Snowflake.\n   450ÔåÆ\n   451ÔåÆ    Queries the ClinicalCodingClusterSnomedCodes table to get all SNOMED codes\n   452ÔåÆ    that belong to the specified cluster.\n   453ÔåÆ\n   454ÔåÆ    Args:\n   455ÔåÆ        cluster_id: Cluster ID to look up (e.g., 'RARTH_COD', 'PSORIASIS_COD')\n   456ÔåÆ        connector: Optional SnowflakeConnector (defaults to singleton)\n   457ÔåÆ        use_cache: Whether to use cached results (default True)\n   458ÔåÆ\n   459ÔåÆ    Returns:\n   460ÔåÆ        ClusterSnomedCodes with list of SNOMED codes and descriptions\n   461ÔåÆ    \"\"\"\n   462ÔåÆ    if not SNOWFLAKE_AVAILABLE:\n   463ÔåÆ        logger.warning(\"Snowflake connector not available\")\n   464ÔåÆ        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n   465ÔåÆ\n   466ÔåÆ    if not is_snowflake_configured():\n   467ÔåÆ        logger.warning(\"Snowflake not configured - cannot get cluster codes\")\n   468ÔåÆ        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n   469ÔåÆ\n   470ÔåÆ    # Check cache first\n   471ÔåÆ    cache_key = f\"cluster_snomed_{cluster_id}\"\n   472ÔåÆ    if use_cache and is_cache_enabled():\n   473ÔåÆ        cache = get_cache()\n   474ÔåÆ        cached = cache.get(cache_key)\n   475ÔåÆ        if cached is not None and len(cached) > 0:\n   476ÔåÆ            logger.debug(f\"Using cached SNOMED codes for cluster '{cluster_id}'\")\n   477ÔåÆ            cached_dict = cached[0]  # First element is our data dict\n   478ÔåÆ            return ClusterSnomedCodes(\n   479ÔåÆ                cluster_id=cluster_id,\n   480ÔåÆ                cluster_description=str(cached_dict.get(\"description\", \"\")),\n   481ÔåÆ                snomed_codes=list(cached_dict.get(\"codes\", [])),\n   482ÔåÆ                snomed_descriptions=dict(cached_dict.get(\"descriptions\", {})),\n   483ÔåÆ            )\n   484ÔåÆ\n   485ÔåÆ    if connector is None:\n   486ÔåÆ        connector = get_connector()\n   487ÔåÆ\n   488ÔåÆ    query = '''\n   489ÔåÆ        SELECT DISTINCT\n   490ÔåÆ            \"Cluster_ID\",\n   491ÔåÆ            \"Cluster_Description\",\n   492ÔåÆ            \"SNOMEDCode\",\n   493ÔåÆ            \"SNOMEDDescription\"\n   494ÔåÆ        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n   495ÔåÆ        WHERE \"Cluster_ID\" = %s\n   496ÔåÆ        ORDER BY \"SNOMEDCode\"\n   497ÔåÆ    '''\n   498ÔåÆ\n   499ÔåÆ    try:\n   500ÔåÆ        results = connector.execute_dict(query, (cluster_id,))\n   501ÔåÆ\n   502ÔåÆ        if not results:\n   503ÔåÆ            logger.warning(f\"No SNOMED codes found for cluster '{cluster_id}'\")\n   504ÔåÆ            return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n   505ÔåÆ\n   506ÔåÆ        codes = []\n   507ÔåÆ        descriptions = {}\n   508ÔåÆ        description = results[0].get(\"Cluster_Description\", \"\") if results else \"\"\n   509ÔåÆ\n   510ÔåÆ        for row in results:\n   511ÔåÆ            code = row.get(\"SNOMEDCode\")\n   512ÔåÆ            if code:\n   513ÔåÆ                codes.append(code)\n   514ÔåÆ                descriptions[code] = row.get(\"SNOMEDDescription\", \"\")\n   515ÔåÆ\n   516ÔåÆ        logger.info(f\"Found {len(codes)} SNOMED codes for cluster '{cluster_id}'\")\n   517ÔåÆ\n   518ÔåÆ        # Cache the results (using query-based cache with fake params)\n   519ÔåÆ        if use_cache and is_cache_enabled():\n   520ÔåÆ            cache = get_cache()\n   521ÔåÆ            cache_data = [{\n   522ÔåÆ                \"description\": description,\n   523ÔåÆ                \"codes\": codes,\n   524ÔåÆ                \"descriptions\": descriptions,\n   525ÔåÆ            }]\n   526ÔåÆ            cache.set(cache_key, None, cache_data)  # type: ignore[arg-type]\n   527ÔåÆ\n   528ÔåÆ        return ClusterSnomedCodes(\n   529ÔåÆ            cluster_id=cluster_id,\n   530ÔåÆ            cluster_description=description,\n   531ÔåÆ            snomed_codes=codes,\n   532ÔåÆ            snomed_descriptions=descriptions,\n   533ÔåÆ        )\n   534ÔåÆ\n   535ÔåÆ    except Exception as e:\n   536ÔåÆ        logger.error(f\"Error getting SNOMED codes for cluster '{cluster_id}': {e}\")\n   537ÔåÆ        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n   538ÔåÆ\n   539ÔåÆ\n   540ÔåÆdef patient_has_indication(\n   541ÔåÆ    patient_pseudonym: str,\n   542ÔåÆ    cluster_ids: list[str],\n   543ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   544ÔåÆ    before_date: Optional[date] = None,\n   545ÔåÆ) -> tuple[bool, Optional[str], Optional[str], Optional[str]]:\n   546ÔåÆ    \"\"\"\n   547ÔåÆ    Check if a patient has any SNOMED codes from the specified clusters in GP records.\n   548ÔåÆ\n   549ÔåÆ    Args:\n   550ÔåÆ        patient_pseudonym: Patient's pseudonymised NHS number\n   551ÔåÆ        cluster_ids: List of cluster IDs to check against\n   552ÔåÆ        connector: Optional SnowflakeConnector\n   553ÔåÆ        before_date: Optional date - only check diagnoses before this date\n   554ÔåÆ\n   555ÔåÆ    Returns:\n   556ÔåÆ        Tuple of (has_indication, matched_cluster_id, matched_snomed_code, matched_description)\n   557ÔåÆ    \"\"\"\n   558ÔåÆ    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n   559ÔåÆ        return False, None, None, None\n   560ÔåÆ\n   561ÔåÆ    if not cluster_ids:\n   562ÔåÆ        return False, None, None, None\n   563ÔåÆ\n   564ÔåÆ    if connector is None:\n   565ÔåÆ        connector = get_connector()\n   566ÔåÆ\n   567ÔåÆ    # Build placeholders for cluster IDs\n   568ÔåÆ    placeholders = \", \".join([\"%s\"] * len(cluster_ids))\n   569ÔåÆ\n   570ÔåÆ    # Query to check if patient has any matching SNOMED code\n   571ÔåÆ    query = f'''\n   572ÔåÆ        SELECT\n   573ÔåÆ            pc.\"SNOMEDCode\",\n   574ÔåÆ            cc.\"Cluster_ID\",\n   575ÔåÆ            cc.\"SNOMEDDescription\"\n   576ÔåÆ        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\n   577ÔåÆ        INNER JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" cc\n   578ÔåÆ            ON pc.\"SNOMEDCode\" = cc.\"SNOMEDCode\"\n   579ÔåÆ        WHERE pc.\"PatientPseudonym\" = %s\n   580ÔåÆ            AND cc.\"Cluster_ID\" IN ({placeholders})\n   581ÔåÆ    '''\n   582ÔåÆ\n   583ÔåÆ    params = [patient_pseudonym] + cluster_ids\n   584ÔåÆ\n   585ÔåÆ    if before_date:\n   586ÔåÆ        query += ' AND pc.\"EventDateTime\" < %s'\n   587ÔåÆ        params.append(before_date.isoformat())\n   588ÔåÆ\n   589ÔåÆ    query += ' LIMIT 1'\n   590ÔåÆ\n   591ÔåÆ    try:\n   592ÔåÆ        results = connector.execute_dict(query, tuple(params))\n   593ÔåÆ\n   594ÔåÆ        if results:\n   595ÔåÆ            row = results[0]\n   596ÔåÆ            return (\n   597ÔåÆ                True,\n   598ÔåÆ                row.get(\"Cluster_ID\"),\n   599ÔåÆ                row.get(\"SNOMEDCode\"),\n   600ÔåÆ                row.get(\"SNOMEDDescription\"),\n   601ÔåÆ            )\n   602ÔåÆ\n   603ÔåÆ        return False, None, None, None\n   604ÔåÆ\n   605ÔåÆ    except Exception as e:\n   606ÔåÆ        logger.error(f\"Error checking indication for patient '{patient_pseudonym}': {e}\")\n   607ÔåÆ        return False, None, None, None\n   608ÔåÆ\n   609ÔåÆ\n   610ÔåÆdef validate_indication(\n   611ÔåÆ    patient_pseudonym: str,\n   612ÔåÆ    drug_name: str,\n   613ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   614ÔåÆ    db_manager: Optional[DatabaseManager] = None,\n   615ÔåÆ    before_date: Optional[date] = None,\n   616ÔåÆ) -> IndicationValidationResult:\n   617ÔåÆ    \"\"\"\n   618ÔåÆ    Validate that a patient has an appropriate indication for a drug.\n   619ÔåÆ\n   620ÔåÆ    Full validation workflow:\n   621ÔåÆ    1. Get drug's valid indication clusters from local mapping\n   622ÔåÆ    2. Check if patient has any matching SNOMED codes in GP records\n   623ÔåÆ    3. Return detailed validation result\n   624ÔåÆ\n   625ÔåÆ    Args:\n   626ÔåÆ        patient_pseudonym: Patient's pseudonymised NHS number\n   627ÔåÆ        drug_name: Drug name to validate indication for\n   628ÔåÆ        connector: Optional SnowflakeConnector\n   629ÔåÆ        db_manager: Optional DatabaseManager\n   630ÔåÆ        before_date: Optional date - only check diagnoses before this date\n   631ÔåÆ\n   632ÔåÆ    Returns:\n   633ÔåÆ        IndicationValidationResult with validation details\n   634ÔåÆ    \"\"\"\n   635ÔåÆ    result = IndicationValidationResult(\n   636ÔåÆ        patient_pseudonym=patient_pseudonym,\n   637ÔåÆ        drug_name=drug_name,\n   638ÔåÆ        has_valid_indication=False,\n   639ÔåÆ    )\n   640ÔåÆ\n   641ÔåÆ    # Step 1: Get drug's cluster mappings\n   642ÔåÆ    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n   643ÔåÆ\n   644ÔåÆ    if not cluster_ids:\n   645ÔåÆ        result.error_message = f\"No cluster mappings found for drug '{drug_name}'\"\n   646ÔåÆ        result.source = \"NONE\"\n   647ÔåÆ        return result\n   648ÔåÆ\n   649ÔåÆ    result.checked_clusters = cluster_ids\n   650ÔåÆ\n   651ÔåÆ    # Step 2: Check Snowflake availability\n   652ÔåÆ    if not SNOWFLAKE_AVAILABLE:\n   653ÔåÆ        result.error_message = \"Snowflake connector not installed\"\n   654ÔåÆ        result.source = \"NONE\"\n   655ÔåÆ        return result\n   656ÔåÆ\n   657ÔåÆ    if not is_snowflake_configured():\n   658ÔåÆ        result.error_message = \"Snowflake not configured\"\n   659ÔåÆ        result.source = \"NONE\"\n   660ÔåÆ        return result\n   661ÔåÆ\n   662ÔåÆ    # Step 3: Check patient GP records\n   663ÔåÆ    has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n   664ÔåÆ        patient_pseudonym=patient_pseudonym,\n   665ÔåÆ        cluster_ids=cluster_ids,\n   666ÔåÆ        connector=connector,\n   667ÔåÆ        before_date=before_date,\n   668ÔåÆ    )\n   669ÔåÆ\n   670ÔåÆ    result.has_valid_indication = has_indication\n   671ÔåÆ    result.matched_cluster_id = matched_cluster\n   672ÔåÆ    result.matched_snomed_code = matched_code\n   673ÔåÆ    result.matched_snomed_description = matched_desc\n   674ÔåÆ    result.source = \"GP_SNOMED\" if has_indication else \"NONE\"\n   675ÔåÆ\n   676ÔåÆ    return result\n   677ÔåÆ\n   678ÔåÆ\n   679ÔåÆdef get_indication_match_rate(\n   680ÔåÆ    drug_name: str,\n   681ÔåÆ    patient_pseudonyms: list[str],\n   682ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   683ÔåÆ    db_manager: Optional[DatabaseManager] = None,\n   684ÔåÆ    sample_unmatched_count: int = 10,\n   685ÔåÆ) -> DrugIndicationMatchRate:\n   686ÔåÆ    \"\"\"\n   687ÔåÆ    Calculate indication match rate for a drug across a list of patients.\n   688ÔåÆ\n   689ÔåÆ    Args:\n   690ÔåÆ        drug_name: Drug name to check\n   691ÔåÆ        patient_pseudonyms: List of patient pseudonymised NHS numbers\n   692ÔåÆ        connector: Optional SnowflakeConnector\n   693ÔåÆ        db_manager: Optional DatabaseManager\n   694ÔåÆ        sample_unmatched_count: Number of unmatched patient IDs to include in sample\n   695ÔåÆ\n   696ÔåÆ    Returns:\n   697ÔåÆ        DrugIndicationMatchRate with match statistics\n   698ÔåÆ    \"\"\"\n   699ÔåÆ    if connector is None and SNOWFLAKE_AVAILABLE and is_snowflake_configured():\n   700ÔåÆ        connector = get_connector()\n   701ÔåÆ\n   702ÔåÆ    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n   703ÔåÆ\n   704ÔåÆ    total = len(patient_pseudonyms)\n   705ÔåÆ    matched = 0\n   706ÔåÆ    unmatched = 0\n   707ÔåÆ    sample_unmatched: list[str] = []\n   708ÔåÆ\n   709ÔåÆ    if not cluster_ids:\n   710ÔåÆ        logger.warning(f\"No cluster mappings for drug '{drug_name}' - all patients will be unmatched\")\n   711ÔåÆ        return DrugIndicationMatchRate(\n   712ÔåÆ            drug_name=drug_name,\n   713ÔåÆ            total_patients=total,\n   714ÔåÆ            patients_with_indication=0,\n   715ÔåÆ            patients_without_indication=total,\n   716ÔåÆ            match_rate=0.0,\n   717ÔåÆ            clusters_checked=[],\n   718ÔåÆ            sample_unmatched=patient_pseudonyms[:sample_unmatched_count],\n   719ÔåÆ        )\n   720ÔåÆ\n   721ÔåÆ    for i, pseudonym in enumerate(patient_pseudonyms):\n   722ÔåÆ        if i > 0 and i % 100 == 0:\n   723ÔåÆ            logger.info(f\"Validating indications: {i}/{total} ({100*i/total:.1f}%)\")\n   724ÔåÆ\n   725ÔåÆ        has_indication, _, _, _ = patient_has_indication(\n   726ÔåÆ            patient_pseudonym=pseudonym,\n   727ÔåÆ            cluster_ids=cluster_ids,\n   728ÔåÆ            connector=connector,\n   729ÔåÆ        )\n   730ÔåÆ\n   731ÔåÆ        if has_indication:\n   732ÔåÆ            matched += 1\n   733ÔåÆ        else:\n   734ÔåÆ            unmatched += 1\n   735ÔåÆ            if len(sample_unmatched) < sample_unmatched_count:\n   736ÔåÆ                sample_unmatched.append(pseudonym)\n   737ÔåÆ\n   738ÔåÆ    match_rate = matched / total if total > 0 else 0.0\n   739ÔåÆ\n   740ÔåÆ    logger.info(f\"Indication match rate for '{drug_name}': {100*match_rate:.1f}% ({matched}/{total})\")\n   741ÔåÆ\n   742ÔåÆ    return DrugIndicationMatchRate(\n   743ÔåÆ        drug_name=drug_name,\n   744ÔåÆ        total_patients=total,\n   745ÔåÆ        patients_with_indication=matched,\n   746ÔåÆ        patients_without_indication=unmatched,\n   747ÔåÆ        match_rate=match_rate,\n   748ÔåÆ        clusters_checked=cluster_ids,\n   749ÔåÆ        sample_unmatched=sample_unmatched,\n   750ÔåÆ    )\n   751ÔåÆ\n   752ÔåÆ\n   753ÔåÆdef batch_validate_indications(\n   754ÔåÆ    patient_drug_pairs: list[tuple[str, str]],\n   755ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   756ÔåÆ    db_manager: Optional[DatabaseManager] = None,\n   757ÔåÆ    progress_callback: Optional[Callable[[int, int], None]] = None,\n   758ÔåÆ) -> list[IndicationValidationResult]:\n   759ÔåÆ    \"\"\"\n   760ÔåÆ    Validate indications for multiple patient-drug pairs efficiently.\n   761ÔåÆ\n   762ÔåÆ    Args:\n   763ÔåÆ        patient_drug_pairs: List of (patient_pseudonym, drug_name) tuples\n   764ÔåÆ        connector: Optional SnowflakeConnector\n   765ÔåÆ        db_manager: Optional DatabaseManager\n   766ÔåÆ        progress_callback: Optional callback(current, total) for progress updates\n   767ÔåÆ\n   768ÔåÆ    Returns:\n   769ÔåÆ        List of IndicationValidationResult for each pair\n   770ÔåÆ    \"\"\"\n   771ÔåÆ    results = []\n   772ÔåÆ    total = len(patient_drug_pairs)\n   773ÔåÆ\n   774ÔåÆ    # Cache cluster lookups by drug\n   775ÔåÆ    drug_clusters_cache = {}\n   776ÔåÆ\n   777ÔåÆ    for i, (pseudonym, drug_name) in enumerate(patient_drug_pairs):\n   778ÔåÆ        if progress_callback:\n   779ÔåÆ            progress_callback(i + 1, total)\n   780ÔåÆ\n   781ÔåÆ        # Get clusters from cache or lookup\n   782ÔåÆ        drug_upper = drug_name.upper()\n   783ÔåÆ        if drug_upper not in drug_clusters_cache:\n   784ÔåÆ            drug_clusters_cache[drug_upper] = get_drug_cluster_ids(drug_name, db_manager)\n   785ÔåÆ\n   786ÔåÆ        cluster_ids = drug_clusters_cache[drug_upper]\n   787ÔåÆ\n   788ÔåÆ        if not cluster_ids:\n   789ÔåÆ            results.append(IndicationValidationResult(\n   790ÔåÆ                patient_pseudonym=pseudonym,\n   791ÔåÆ                drug_name=drug_name,\n   792ÔåÆ                has_valid_indication=False,\n   793ÔåÆ                source=\"NONE\",\n   794ÔåÆ                error_message=f\"No cluster mappings for drug '{drug_name}'\",\n   795ÔåÆ            ))\n   796ÔåÆ            continue\n   797ÔåÆ\n   798ÔåÆ        # Check patient indication\n   799ÔåÆ        has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n   800ÔåÆ            patient_pseudonym=pseudonym,\n   801ÔåÆ            cluster_ids=cluster_ids,\n   802ÔåÆ            connector=connector,\n   803ÔåÆ        )\n   804ÔåÆ\n   805ÔåÆ        results.append(IndicationValidationResult(\n   806ÔåÆ            patient_pseudonym=pseudonym,\n   807ÔåÆ            drug_name=drug_name,\n   808ÔåÆ            has_valid_indication=has_indication,\n   809ÔåÆ            matched_cluster_id=matched_cluster,\n   810ÔåÆ            matched_snomed_code=matched_code,\n   811ÔåÆ            matched_snomed_description=matched_desc,\n   812ÔåÆ            checked_clusters=cluster_ids,\n   813ÔåÆ            source=\"GP_SNOMED\" if has_indication else \"NONE\",\n   814ÔåÆ        ))\n   815ÔåÆ\n   816ÔåÆ    matched_count = sum(1 for r in results if r.has_valid_indication)\n   817ÔåÆ    logger.info(f\"Batch validation complete: {matched_count}/{total} ({100*matched_count/total:.1f}%) with valid indications\")\n   818ÔåÆ\n   819ÔåÆ    return results\n   820ÔåÆ\n   821ÔåÆ\n   822ÔåÆdef get_available_clusters(\n   823ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   824ÔåÆ) -> list[dict]:\n   825ÔåÆ    \"\"\"\n   826ÔåÆ    Get list of all available SNOMED clusters from Snowflake.\n   827ÔåÆ\n   828ÔåÆ    Returns:\n   829ÔåÆ        List of dicts with cluster_id, cluster_description, code_count\n   830ÔåÆ    \"\"\"\n   831ÔåÆ    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n   832ÔåÆ        logger.warning(\"Snowflake not available - cannot list clusters\")\n   833ÔåÆ        return []\n   834ÔåÆ\n   835ÔåÆ    if connector is None:\n   836ÔåÆ        connector = get_connector()\n   837ÔåÆ\n   838ÔåÆ    query = '''\n   839ÔåÆ        SELECT\n   840ÔåÆ            \"Cluster_ID\",\n   841ÔåÆ            \"Cluster_Description\",\n   842ÔåÆ            COUNT(DISTINCT \"SNOMEDCode\") as code_count\n   843ÔåÆ        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n   844ÔåÆ        GROUP BY \"Cluster_ID\", \"Cluster_Description\"\n   845ÔåÆ        ORDER BY \"Cluster_ID\"\n   846ÔåÆ    '''\n   847ÔåÆ\n   848ÔåÆ    try:\n   849ÔåÆ        results = connector.execute_dict(query)\n   850ÔåÆ\n   851ÔåÆ        clusters = []\n   852ÔåÆ        for row in results:\n   853ÔåÆ            clusters.append({\n   854ÔåÆ                \"cluster_id\": row.get(\"Cluster_ID\"),\n   855ÔåÆ                \"cluster_description\": row.get(\"Cluster_Description\"),\n   856ÔåÆ                \"code_count\": row.get(\"code_count\", 0),\n   857ÔåÆ            })\n   858ÔåÆ\n   859ÔåÆ        logger.info(f\"Found {len(clusters)} available SNOMED clusters\")\n   860ÔåÆ        return clusters\n   861ÔåÆ\n   862ÔåÆ    except Exception as e:\n   863ÔåÆ        logger.error(f\"Error getting available clusters: {e}\")\n   864ÔåÆ        return []\n   865ÔåÆ\n   866ÔåÆ\n   867ÔåÆdef batch_lookup_indication_groups(\n   868ÔåÆ    df: \"pd.DataFrame\",\n   869ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n   870ÔåÆ    db_manager: Optional[DatabaseManager] = None,\n   871ÔåÆ    batch_size: int = 500,\n   872ÔåÆ) -> \"pd.DataFrame\":\n   873ÔåÆ    \"\"\"\n   874ÔåÆ    Batch lookup GP diagnosis-based indication groups for a DataFrame of patients.\n   875ÔåÆ\n   876ÔåÆ    This is the efficient batch version of get_directorate_from_diagnosis().\n   877ÔåÆ    Instead of querying Snowflake per patient, it batches the lookups for performance.\n   878ÔåÆ\n   879ÔåÆ    Strategy:\n   880ÔåÆ    1. Get all unique (PersonKey, Drug Name) pairs from DataFrame\n   881ÔåÆ    2. For each unique drug, get all SNOMED codes from local SQLite\n   882ÔåÆ    3. Build batched Snowflake queries to check GP records\n   883ÔåÆ    4. Return indication_df mapping UPID ÔåÆ Indication_Group\n   884ÔåÆ\n   885ÔåÆ    For unmatched patients, Indication_Group will be their Directory (with suffix).\n   886ÔåÆ\n   887ÔåÆ    Args:\n   888ÔåÆ        df: DataFrame with columns: UPID, Drug Name, Directory, PersonKey\n   889ÔåÆ        connector: Optional SnowflakeConnector (defaults to singleton)\n   890ÔåÆ        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n   891ÔåÆ        batch_size: Number of patients per Snowflake query batch\n   892ÔåÆ\n   893ÔåÆ    Returns:\n   894ÔåÆ        DataFrame with columns: UPID, Indication_Group, Source\n   895ÔåÆ        - Indication_Group: Search_Term (if matched) or \"Directory (no GP dx)\" (if not)\n   896ÔåÆ        - Source: \"DIAGNOSIS\" or \"FALLBACK\"\n   897ÔåÆ    \"\"\"\n   898ÔåÆ    import pandas as pd\n   899ÔåÆ\n   900ÔåÆ    if db_manager is None:\n   901ÔåÆ        db_manager = default_db_manager\n   902ÔåÆ\n   903ÔåÆ    logger.info(f\"Starting batch indication lookup for {len(df)} records...\")\n   904ÔåÆ\n   905ÔåÆ    # Step 1: Get unique (UPID, Drug Name, PseudoNHSNoLinked, Directory) combinations\n   906ÔåÆ    # We need PseudoNHSNoLinked to query Snowflake - this matches PatientPseudonym in GP records\n   907ÔåÆ    # Note: PersonKey is LocalPatientID which is provider-specific and does NOT match GP records\n   908ÔåÆ    if 'PseudoNHSNoLinked' not in df.columns:\n   909ÔåÆ        logger.error(\"DataFrame missing 'PseudoNHSNoLinked' column - cannot lookup GP records\")\n   910ÔåÆ        # Return fallback for all patients\n   911ÔåÆ        result_df = df[['UPID', 'Directory']].drop_duplicates().copy()\n   912ÔåÆ        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n   913ÔåÆ        result_df['Source'] = \"FALLBACK\"\n   914ÔåÆ        return result_df[['UPID', 'Indication_Group', 'Source']]\n   915ÔåÆ\n   916ÔåÆ    # Get unique patient-drug combinations (we need one lookup per patient-drug pair)\n   917ÔåÆ    unique_pairs = df[['UPID', 'Drug Name', 'PseudoNHSNoLinked', 'Directory']].drop_duplicates()\n   918ÔåÆ    logger.info(f\"Found {len(unique_pairs)} unique patient-drug combinations\")\n   919ÔåÆ\n   920ÔåÆ    # Step 2: Get all unique drugs and their SNOMED codes\n   921ÔåÆ    unique_drugs = unique_pairs['Drug Name'].unique()\n   922ÔåÆ    logger.info(f\"Building SNOMED lookup for {len(unique_drugs)} unique drugs...\")\n   923ÔåÆ\n   924ÔåÆ    # Build drug -> list of DrugSnomedMapping dict\n   925ÔåÆ    drug_snomed_map: dict[str, list[DrugSnomedMapping]] = {}\n   926ÔåÆ    all_snomed_codes: set[str] = set()\n   927ÔåÆ    snomed_to_drug_searchterm: dict[str, list[tuple[str, str, str]]] = {}  # snomed -> [(drug, search_term, primary_dir), ...]\n   928ÔåÆ\n   929ÔåÆ    for drug_name in unique_drugs:\n   930ÔåÆ        mappings = get_drug_snomed_codes(drug_name, db_manager)\n   931ÔåÆ        drug_snomed_map[drug_name] = mappings\n   932ÔåÆ\n   933ÔåÆ        for m in mappings:\n   934ÔåÆ            all_snomed_codes.add(m.snomed_code)\n   935ÔåÆ            if m.snomed_code not in snomed_to_drug_searchterm:\n   936ÔåÆ                snomed_to_drug_searchterm[m.snomed_code] = []\n   937ÔåÆ            snomed_to_drug_searchterm[m.snomed_code].append(\n   938ÔåÆ                (drug_name, m.search_term, m.primary_directorate)\n   939ÔåÆ            )\n   940ÔåÆ\n   941ÔåÆ    logger.info(f\"Total SNOMED codes to check: {len(all_snomed_codes)}\")\n   942ÔåÆ\n   943ÔåÆ    # Step 3: Check Snowflake availability\n   944ÔåÆ    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n   945ÔåÆ        logger.warning(\"Snowflake not available - returning fallback for all patients\")\n   946ÔåÆ        result_df = unique_pairs[['UPID', 'Directory']].copy()\n   947ÔåÆ        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n   948ÔåÆ        result_df['Source'] = \"FALLBACK\"\n   949ÔåÆ        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n   950ÔåÆ\n   951ÔåÆ    if connector is None:\n   952ÔåÆ        connector = get_connector()\n   953ÔåÆ\n   954ÔåÆ    # Step 4: Query GP records for all patients in batches\n   955ÔåÆ    # The query finds the most recent matching SNOMED code for each patient\n   956ÔåÆ\n   957ÔåÆ    # Get unique PseudoNHSNoLinked values (each = one patient in GP records)\n   958ÔåÆ    unique_patients = unique_pairs[['PseudoNHSNoLinked', 'UPID', 'Directory']].drop_duplicates(subset=['PseudoNHSNoLinked'])\n   959ÔåÆ    patient_pseudonyms = unique_patients['PseudoNHSNoLinked'].tolist()\n   960ÔåÆ\n   961ÔåÆ    logger.info(f\"Querying GP records for {len(patient_pseudonyms)} unique patients in batches of {batch_size}...\")\n   962ÔåÆ\n   963ÔåÆ    # Results dict: PersonKey -> (snomed_code, event_date)\n   964ÔåÆ    gp_matches: dict[str, tuple[str, Any]] = {}\n   965ÔåÆ\n   966ÔåÆ    # Convert SNOMED codes to list for query\n   967ÔåÆ    snomed_list = list(all_snomed_codes)\n   968ÔåÆ\n   969ÔåÆ    if not snomed_list:\n   970ÔåÆ        logger.warning(\"No SNOMED codes to check - returning fallback for all patients\")\n   971ÔåÆ        result_df = unique_pairs[['UPID', 'Directory']].copy()\n   972ÔåÆ        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n   973ÔåÆ        result_df['Source'] = \"FALLBACK\"\n   974ÔåÆ        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n   975ÔåÆ\n   976ÔåÆ    # Build SNOMED IN clause (reused across batches)\n   977ÔåÆ    snomed_placeholders = \", \".join([\"%s\"] * len(snomed_list))\n   978ÔåÆ\n   979ÔåÆ    # Process patients in batches\n   980ÔåÆ    for batch_start in range(0, len(patient_pseudonyms), batch_size):\n   981ÔåÆ        batch_end = min(batch_start + batch_size, len(patient_pseudonyms))\n   982ÔåÆ        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n   983ÔåÆ\n   984ÔåÆ        logger.info(f\"Batch {batch_start//batch_size + 1}: patients {batch_start} to {batch_end}\")\n   985ÔåÆ\n   986ÔåÆ        # Build patient IN clause\n   987ÔåÆ        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n   988ÔåÆ\n   989ÔåÆ        # Query to find all matching SNOMED codes for these patients\n   990ÔåÆ        # We'll get all matches and pick the most recent per patient in Python\n   991ÔåÆ        query = f'''\n   992ÔåÆ            SELECT\n   993ÔåÆ                \"PatientPseudonym\",\n   994ÔåÆ                \"SNOMEDCode\",\n   995ÔåÆ                \"EventDateTime\"\n   996ÔåÆ            FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n   997ÔåÆ            WHERE \"PatientPseudonym\" IN ({patient_placeholders})\n   998ÔåÆ              AND \"SNOMEDCode\" IN ({snomed_placeholders})\n   999ÔåÆ            ORDER BY \"PatientPseudonym\", \"EventDateTime\" DESC\n  1000ÔåÆ        '''\n  1001ÔåÆ\n  1002ÔåÆ        params = tuple(batch_pseudonyms) + tuple(snomed_list)\n  1003ÔåÆ\n  1004ÔåÆ        try:\n  1005ÔåÆ            results = connector.execute_dict(query, params)\n  1006ÔåÆ\n  1007ÔåÆ            # Process results - pick most recent per patient\n  1008ÔåÆ            for row in results:\n  1009ÔåÆ                person_key = row.get(\"PatientPseudonym\")\n  1010ÔåÆ                snomed_code = row.get(\"SNOMEDCode\")\n  1011ÔåÆ                event_date = row.get(\"EventDateTime\")\n  1012ÔåÆ\n  1013ÔåÆ                if person_key and snomed_code:\n  1014ÔåÆ                    # Keep only if we haven't seen this patient yet (first = most recent due to ORDER BY)\n  1015ÔåÆ                    if person_key not in gp_matches:\n  1016ÔåÆ                        gp_matches[person_key] = (snomed_code, event_date)\n  1017ÔåÆ\n  1018ÔåÆ        except Exception as e:\n  1019ÔåÆ            logger.error(f\"Error querying GP records for batch: {e}\")\n  1020ÔåÆ            # Continue with other batches\n  1021ÔåÆ\n  1022ÔåÆ    logger.info(f\"Found GP matches for {len(gp_matches)} patients\")\n  1023ÔåÆ\n  1024ÔåÆ    # Step 5: Build result DataFrame\n  1025ÔåÆ    # For each unique_pair, determine Indication_Group based on match status\n  1026ÔåÆ    results_list = []\n  1027ÔåÆ\n  1028ÔåÆ    # We need to dedupe by UPID - a patient might be on multiple drugs\n  1029ÔåÆ    # Strategy: For each UPID, use the most recent match (if any)\n  1030ÔåÆ    upid_to_match: dict[str, tuple[str, str]] = {}  # UPID -> (Indication_Group, Source)\n  1031ÔåÆ\n  1032ÔåÆ    for _, row in unique_pairs.iterrows():\n  1033ÔåÆ        upid = row['UPID']\n  1034ÔåÆ        drug_name = row['Drug Name']\n  1035ÔåÆ        patient_pseudonym = row['PseudoNHSNoLinked']\n  1036ÔåÆ        directory = row['Directory']\n  1037ÔåÆ\n  1038ÔåÆ        # Check if patient has GP match (using PseudoNHSNoLinked which matches PatientPseudonym in GP)\n  1039ÔåÆ        if patient_pseudonym in gp_matches:\n  1040ÔåÆ            matched_snomed, event_date = gp_matches[patient_pseudonym]\n  1041ÔåÆ\n  1042ÔåÆ            # Find the search_term for this SNOMED code and drug\n  1043ÔåÆ            # (A SNOMED code might map to multiple drugs with different search_terms)\n  1044ÔåÆ            if matched_snomed in snomed_to_drug_searchterm:\n  1045ÔåÆ                # Look for match with current drug first\n  1046ÔåÆ                search_term = None\n  1047ÔåÆ                for drug, st, pd in snomed_to_drug_searchterm[matched_snomed]:\n  1048ÔåÆ                    if drug.upper() == drug_name.upper():\n  1049ÔåÆ                        search_term = st\n  1050ÔåÆ                        break\n  1051ÔåÆ                # If no drug-specific match, use any match\n  1052ÔåÆ                if search_term is None:\n  1053ÔåÆ                    search_term = snomed_to_drug_searchterm[matched_snomed][0][1]\n  1054ÔåÆ\n  1055ÔåÆ                # Only update if we don't have a match for this UPID yet\n  1056ÔåÆ                if upid not in upid_to_match:\n  1057ÔåÆ                    upid_to_match[upid] = (search_term, \"DIAGNOSIS\")\n  1058ÔåÆ            else:\n  1059ÔåÆ                # Shouldn't happen but fallback just in case\n  1060ÔåÆ                if upid not in upid_to_match:\n  1061ÔåÆ                    upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n  1062ÔåÆ        else:\n  1063ÔåÆ            # No GP match - use fallback\n  1064ÔåÆ            if upid not in upid_to_match:\n  1065ÔåÆ                upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n  1066ÔåÆ\n  1067ÔåÆ    # Build result DataFrame\n  1068ÔåÆ    for upid, (indication_group, source) in upid_to_match.items():\n  1069ÔåÆ        results_list.append({\n  1070ÔåÆ            'UPID': upid,\n  1071ÔåÆ            'Indication_Group': indication_group,\n  1072ÔåÆ            'Source': source,\n  1073ÔåÆ        })\n  1074ÔåÆ\n  1075ÔåÆ    result_df = pd.DataFrame(results_list)\n  1076ÔåÆ\n  1077ÔåÆ    # Log statistics\n  1078ÔåÆ    diagnosis_count = len([s for s in result_df['Source'] if s == \"DIAGNOSIS\"])\n  1079ÔåÆ    fallback_count = len([s for s in result_df['Source'] if s == \"FALLBACK\"])\n  1080ÔåÆ    total = len(result_df)\n  1081ÔåÆ\n  1082ÔåÆ    logger.info(f\"Indication lookup complete:\")\n  1083ÔåÆ    logger.info(f\"  Total unique patients: {total}\")\n  1084ÔåÆ    logger.info(f\"  DIAGNOSIS matches: {diagnosis_count} ({100*diagnosis_count/total:.1f}%)\")\n  1085ÔåÆ    logger.info(f\"  FALLBACK (no GP match): {fallback_count} ({100*fallback_count/total:.1f}%)\")\n  1086ÔåÆ\n  1087ÔåÆ    return result_df\n  1088ÔåÆ\n  1089ÔåÆ\n  1090ÔåÆ# === NEW APPROACH: Query Snowflake directly using cluster CTE ===\n  1091ÔåÆ\n  1092ÔåÆ# The cluster query mapping (embedded from snomed_indication_mapping_query.sql)\n  1093ÔåÆ# This maps Search_Term -> Cluster_ID for ~148 clinical conditions\n  1094ÔåÆCLUSTER_MAPPING_SQL = \"\"\"\n  1095ÔåÆWITH SearchTermClusters AS (\n  1096ÔåÆ    SELECT Search_Term, Cluster_ID FROM (VALUES\n  1097ÔåÆ        ('acute lymphoblastic leukaemia', 'HAEMCANMORPH_COD'),\n  1098ÔåÆ        ('acute myeloid leukaemia', 'C19HAEMCAN_COD'),\n  1099ÔåÆ        ('acute promyelocytic leukaemia', 'HAEMCANMORPH_COD'),\n  1100ÔåÆ        ('allergic asthma', 'AST_COD'),\n  1101ÔåÆ        ('allergic rhinitis', 'MILDINTAST_COD'),\n  1102ÔåÆ        ('alzheimer''s disease', 'DEMALZ_COD'),\n  1103ÔåÆ        ('amyloidosis', 'AMYLOID_COD'),\n  1104ÔåÆ        ('anaemia', 'eFI2_AnaemiaTimeSensitive'),\n  1105ÔåÆ        ('anaplastic large cell lymphoma', 'C19HAEMCAN_COD'),\n  1106ÔåÆ        ('apixaban', 'DOACCON_COD'),\n  1107ÔåÆ        ('aplastic anaemia', 'eFI2_AnaemiaEver'),\n  1108ÔåÆ        ('arthritis', 'eFI2_InflammatoryArthritis'),\n  1109ÔåÆ        ('asthma', 'eFI2_Asthma'),\n  1110ÔåÆ        ('atopic dermatitis', 'ATOPDERM_COD'),\n  1111ÔåÆ        ('atrial fibrillation', 'eFI2_AtrialFibrillation'),\n  1112ÔåÆ        ('attention deficit hyperactivity disorder', 'ADHD_COD'),\n  1113ÔåÆ        ('bipolar disorder', 'MH_COD'),\n  1114ÔåÆ        ('bladder', 'eFI2_UrinaryIncontinence'),\n  1115ÔåÆ        ('breast cancer', 'BRCANSCR_COD'),\n  1116ÔåÆ        ('cardiomyopathy', 'eFI2_HarmfulDrinking'),\n  1117ÔåÆ        ('cardiovascular disease', 'CVDRISKASS_COD'),\n  1118ÔåÆ        ('cervical cancer', 'CSDEC_COD'),\n  1119ÔåÆ        ('cholangiocarcinoma', 'eFI2_Cancer'),\n  1120ÔåÆ        ('chronic kidney disease', 'CKD_COD'),\n  1121ÔåÆ        ('chronic liver disease', 'eFI2_LiverProblems'),\n  1122ÔåÆ        ('chronic lymphocytic leukaemia', 'EPPHAEMCAN_COD'),\n  1123ÔåÆ        ('chronic myeloid leukaemia', 'EPPHAEMCAN_COD'),\n  1124ÔåÆ        ('chronic obstructive pulmonary disease', 'eFI2_COPD'),\n  1125ÔåÆ        ('colon cancer', 'eFI2_Cancer'),\n  1126ÔåÆ        ('colorectal cancer', 'GICANREF_COD'),\n  1127ÔåÆ        ('constipation', 'CHRONCONSTIP_COD'),\n  1128ÔåÆ        ('covid-19', 'POSSPOSTCOVID_COD'),\n  1129ÔåÆ        ('crohn''s disease', 'eFI2_InflammatoryBowelDisease'),\n  1130ÔåÆ        ('cutaneous t-cell lymphoma', 'C19HAEMCAN_COD'),\n  1131ÔåÆ        ('cystic fibrosis', 'CUST_ICB_CYSTIC_FIBROSIS'),\n  1132ÔåÆ        ('deep vein thrombosis', 'VTE_COD'),\n  1133ÔåÆ        ('depression', 'eFI2_Depression'),\n  1134ÔåÆ        ('diabetes', 'eFI2_DiabetesEver'),\n  1135ÔåÆ        ('diabetic retinopathy', 'DRSELIGIBILITY_COD'),\n  1136ÔåÆ        ('diffuse large b-cell lymphoma', 'C19HAEMCAN_COD'),\n  1137ÔåÆ        ('dravet syndrome', 'EPIL_COD'),\n  1138ÔåÆ        ('drug misuse', 'ILLSUBINT_COD'),\n  1139ÔåÆ        ('dyspepsia', 'eFI2_AbdominalPain'),\n  1140ÔåÆ        ('epilepsy', 'eFI2_Seizures'),\n  1141ÔåÆ        ('fallopian tube', 'STERIL_COD'),\n  1142ÔåÆ        ('follicular lymphoma', 'C19HAEMCAN_COD'),\n  1143ÔåÆ        ('gastric cancer', 'eFI2_Cancer'),\n  1144ÔåÆ        ('giant cell arteritis', 'GCA_COD'),\n  1145ÔåÆ        ('glioma', 'NHAEMCANMORPH_COD'),\n  1146ÔåÆ        ('gout', 'eFI2_InflammatoryArthritis'),\n  1147ÔåÆ        ('graft versus host disease', 'GVHD_COD'),\n  1148ÔåÆ        ('granulomatosis with polyangiitis', 'WEGENERVASC_COD'),\n  1149ÔåÆ        ('growth hormone deficiency', 'HYPOPITUITARY_COD'),\n  1150ÔåÆ        ('hand eczema', 'ECZEMA_COD'),\n  1151ÔåÆ        ('heart failure', 'eFI2_HeartFailure'),\n  1152ÔåÆ        ('hepatitis b', 'HEPBCVAC_COD'),\n  1153ÔåÆ        ('hepatocellular carcinoma', 'eFI2_Cancer'),\n  1154ÔåÆ        ('hiv', 'PREFLANG_COD'),\n  1155ÔåÆ        ('hodgkin lymphoma', 'HAEMCANMORPH_COD'),\n  1156ÔåÆ        ('hormone receptor', 'eFI2_ThyroidProblems'),\n  1157ÔåÆ        ('hypercholesterolaemia', 'CLASSFH_COD'),\n  1158ÔåÆ        ('immune thrombocytopenia', 'ITP_COD'),\n  1159ÔåÆ        ('influenza', 'FLUINVITE_COD'),\n  1160ÔåÆ        ('insomnia', 'eFI2_SleepProblems'),\n  1161ÔåÆ        ('irritable bowel syndrome', 'IBS_COD'),\n  1162ÔåÆ        ('ischaemic stroke', 'OSTR_COD'),\n  1163ÔåÆ        ('juvenile idiopathic arthritis', 'RARTHAD_COD'),\n  1164ÔåÆ        ('kidney transplant', 'RENALTRANSP_COD'),\n  1165ÔåÆ        ('leukaemia', 'eFI2_Cancer'),\n  1166ÔåÆ        ('lung cancer', 'FTCANREF_COD'),\n  1167ÔåÆ        ('lymphoma', 'C19HAEMCAN_COD'),\n  1168ÔåÆ        ('macular degeneration', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n  1169ÔåÆ        ('macular oedema', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n  1170ÔåÆ        ('major depressive episodes', 'eFI2_Depression'),\n  1171ÔåÆ        ('malignant melanoma', 'eFI2_Cancer'),\n  1172ÔåÆ        ('malignant pleural mesothelioma', 'LUNGCAN_COD'),\n  1173ÔåÆ        ('manic episode', 'MH_COD'),\n  1174ÔåÆ        ('mantle cell lymphoma', 'HAEMCANMORPH_COD'),\n  1175ÔåÆ        ('melanoma', 'eFI2_Cancer'),\n  1176ÔåÆ        ('merkel cell carcinoma', 'C19CAN_COD'),\n  1177ÔåÆ        ('migraine', 'eFI2_Headache'),\n  1178ÔåÆ        ('motor neurone disease', 'MND_COD'),\n  1179ÔåÆ        ('multiple myeloma', 'C19HAEMCAN_COD'),\n  1180ÔåÆ        ('multiple sclerosis', 'MS_COD'),\n  1181ÔåÆ        ('myelodysplastic', 'eFI2_AnaemiaEver'),\n  1182ÔåÆ        ('myelofibrosis', 'MDS_COD'),\n  1183ÔåÆ        ('myocardial infarction', 'eFI2_IschaemicHeartDisease'),\n  1184ÔåÆ        ('myotonia', 'CNDATRISK2_COD'),\n  1185ÔåÆ        ('narcolepsy', 'LD_COD'),\n  1186ÔåÆ        ('neuroendocrine tumour', 'LUNGCAN_COD'),\n  1187ÔåÆ        ('non-small cell lung cancer', 'LUNGCAN_COD'),\n  1188ÔåÆ        ('non-small-cell lung cancer', 'FTCANREF_COD'),\n  1189ÔåÆ        ('obesity', 'BMI30_COD'),\n  1190ÔåÆ        ('osteoarthritis', 'CUST_ICB_OSTEOARTHRITIS'),\n  1191ÔåÆ        ('osteoporosis', 'eFI2_Osteoporosis'),\n  1192ÔåÆ        ('osteosarcoma', 'NHAEMCANMORPH_COD'),\n  1193ÔåÆ        ('ovarian cancer', 'C19CAN_COD'),\n  1194ÔåÆ        ('peripheral arterial disease', 'PADEXC_COD'),\n  1195ÔåÆ        ('plaque psoriasis', 'PSORIASIS_COD'),\n  1196ÔåÆ        ('polycystic kidney disease', 'EPPCONGMALF_COD'),\n  1197ÔåÆ        ('polycythaemia vera', 'C19HAEMCAN_COD'),\n  1198ÔåÆ        ('pregnancy', 'C19PREG_COD'),\n  1199ÔåÆ        ('primary biliary cholangitis', 'eFI2_LiverProblems'),\n  1200ÔåÆ        ('primary hypercholesterolaemia', 'FNFHYP_COD'),\n  1201ÔåÆ        ('prostate cancer', 'EPPSOLIDCAN_COD'),\n  1202ÔåÆ        ('psoriasis', 'PSORIASIS_COD'),\n  1203ÔåÆ        ('psoriatic arthritis', 'RARTHAD_COD'),\n  1204ÔåÆ        ('pulmonary embolism', 'eFI2_RespiratoryDiseaseTimeSensitive'),\n  1205ÔåÆ        ('pulmonary fibrosis', 'ILD_COD'),\n  1206ÔåÆ        ('relapsing multiple sclerosis', 'MS_COD'),\n  1207ÔåÆ        ('renal cell carcinoma', 'C19CAN_COD'),\n  1208ÔåÆ        ('renal transplantation', 'RENALTRANSP_COD'),\n  1209ÔåÆ        ('retinal vein occlusion', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n  1210ÔåÆ        ('rheumatoid arthritis', 'eFI2_InflammatoryArthritis'),\n  1211ÔåÆ        ('rivaroxaban', 'DOACCON_COD'),\n  1212ÔåÆ        ('schizophrenia', 'MH_COD'),\n  1213ÔåÆ        ('seizures', 'LSZFREQ_COD'),\n  1214ÔåÆ        ('sepsis', 'C19ACTIVITY_COD'),\n  1215ÔåÆ        ('severe persistent allergic asthma', 'SEVAST_COD'),\n  1216ÔåÆ        ('sickle cell disease', 'SICKLE_COD'),\n  1217ÔåÆ        ('sleep apnoea', 'CUST_ICB_NON_SEVERE_LDA'),\n  1218ÔåÆ        ('smoking cessation', 'SMOKINGINT_COD'),\n  1219ÔåÆ        ('soft tissue sarcoma', 'NHAEMCANMORPH_COD'),\n  1220ÔåÆ        ('spinal muscular atrophy', 'MND_COD'),\n  1221ÔåÆ        ('squamous cell', 'C19CAN_COD'),\n  1222ÔåÆ        ('squamous cell carcinoma', 'C19CAN_COD'),\n  1223ÔåÆ        ('stem cell transplant', 'ALLOTRANSP_COD'),\n  1224ÔåÆ        ('stroke', 'eFI2_Stroke'),\n  1225ÔåÆ        ('systemic lupus erythematosus', 'SLUPUS_COD'),\n  1226ÔåÆ        ('systemic mastocytosis', 'HAEMCANMORPH_COD'),\n  1227ÔåÆ        ('thrombocytopenic purpura', 'TTP_COD'),\n  1228ÔåÆ        ('thrombotic thrombocytopenic purpura', 'TTP_COD'),\n  1229ÔåÆ        ('thyroid cancer', 'C19CAN_COD'),\n  1230ÔåÆ        ('tophaceous gout', 'CUST_ICB_OSTEOARTHRITIS'),\n  1231ÔåÆ        ('transitional cell carcinoma', 'C19CAN_COD'),\n  1232ÔåÆ        ('type 1 diabetes', 'DMTYPE1_COD'),\n  1233ÔåÆ        ('type 2 diabetes', 'DMTYPE2_COD'),\n  1234ÔåÆ        ('ulcerative colitis', 'eFI2_InflammatoryBowelDisease'),\n  1235ÔåÆ        ('urothelial carcinoma', 'NHAEMCANMORPH_COD'),\n  1236ÔåÆ        ('urticaria', 'XSAL_COD'),\n  1237ÔåÆ        ('uveitis', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n  1238ÔåÆ        ('vascular disease', 'CVDINVITE_COD'),\n  1239ÔåÆ        ('vasculitis', 'CRYOGLOBVASC_COD')\n  1240ÔåÆ    ) AS t(Search_Term, Cluster_ID)\n  1241ÔåÆ),\n  1242ÔåÆ\n  1243ÔåÆClusterCodes AS (\n  1244ÔåÆ    SELECT\n  1245ÔåÆ        stc.Search_Term,\n  1246ÔåÆ        c.\"SNOMEDCode\",\n  1247ÔåÆ        c.\"SNOMEDDescription\"\n  1248ÔåÆ    FROM SearchTermClusters stc\n  1249ÔåÆ    JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" c\n  1250ÔåÆ        ON stc.Cluster_ID = c.\"Cluster_ID\"\n  1251ÔåÆ    WHERE c.\"SNOMEDCode\" IS NOT NULL\n  1252ÔåÆ),\n  1253ÔåÆ\n  1254ÔåÆExplicitCodes AS (\n  1255ÔåÆ    SELECT Search_Term, SNOMEDCode, SNOMEDDescription FROM (VALUES\n  1256ÔåÆ        ('acute coronary syndrome', '837091000000100', 'Manual mapping'),\n  1257ÔåÆ        ('ankylosing spondylitis', '162930007', 'Manual mapping'),\n  1258ÔåÆ        ('ankylosing spondylitis', '239805001', 'Manual mapping'),\n  1259ÔåÆ        ('ankylosing spondylitis', '239810002', 'Manual mapping'),\n  1260ÔåÆ        ('ankylosing spondylitis', '239811003', 'Manual mapping'),\n  1261ÔåÆ        ('ankylosing spondylitis', '394990003', 'Manual mapping'),\n  1262ÔåÆ        ('ankylosing spondylitis', '429712009', 'Manual mapping'),\n  1263ÔåÆ        ('ankylosing spondylitis', '441562009', 'Manual mapping'),\n  1264ÔåÆ        ('ankylosing spondylitis', '441680005', 'Manual mapping'),\n  1265ÔåÆ        ('ankylosing spondylitis', '441930001', 'Manual mapping'),\n  1266ÔåÆ        ('axial spondyloarthritis', '723116002', 'Manual mapping'),\n  1267ÔåÆ        ('choroidal neovascularisation', '380621000000102', 'Manual mapping'),\n  1268ÔåÆ        ('choroidal neovascularisation', '733124000', 'Manual mapping')\n  1269ÔåÆ    ) AS t(Search_Term, SNOMEDCode, SNOMEDDescription)\n  1270ÔåÆ),\n  1271ÔåÆ\n  1272ÔåÆAllIndicationCodes AS (\n  1273ÔåÆ    SELECT Search_Term, \"SNOMEDCode\" AS SNOMEDCode, \"SNOMEDDescription\" AS SNOMEDDescription\n  1274ÔåÆ    FROM ClusterCodes\n  1275ÔåÆ    UNION ALL\n  1276ÔåÆ    SELECT Search_Term, SNOMEDCode, SNOMEDDescription\n  1277ÔåÆ    FROM ExplicitCodes\n  1278ÔåÆ)\n  1279ÔåÆ\"\"\"\n  1280ÔåÆ\n  1281ÔåÆ\n  1282ÔåÆdef get_patient_indication_groups(\n  1283ÔåÆ    patient_pseudonyms: list[str],\n  1284ÔåÆ    connector: Optional[SnowflakeConnector] = None,\n  1285ÔåÆ    batch_size: int = 500,\n  1286ÔåÆ) -> \"pd.DataFrame\":\n  1287ÔåÆ    \"\"\"\n  1288ÔåÆ    Batch lookup GP diagnosis-based indication groups using Snowflake cluster query.\n  1289ÔåÆ\n  1290ÔåÆ    This function queries Snowflake directly using the embedded cluster CTE\n  1291ÔåÆ    (from snomed_indication_mapping_query.sql) to find patients with matching\n  1292ÔåÆ    GP diagnoses. This is the NEW approach replacing the old SQLite-based lookup.\n  1293ÔåÆ\n  1294ÔåÆ    The query:\n  1295ÔåÆ    1. Uses the cluster mapping CTE to get all Search_Term -> SNOMED code mappings\n  1296ÔåÆ    2. Joins with PrimaryCareClinicalCoding to find patients with matching codes\n  1297ÔåÆ    3. Returns the most recent match per patient (by EventDateTime)\n  1298ÔåÆ\n  1299ÔåÆ    Args:\n  1300ÔåÆ        patient_pseudonyms: List of PseudoNHSNoLinked values (matches PatientPseudonym in GP records)\n  1301ÔåÆ        connector: Optional SnowflakeConnector (defaults to singleton)\n  1302ÔåÆ        batch_size: Number of patients per Snowflake query batch (default 500)\n  1303ÔåÆ\n  1304ÔåÆ    Returns:\n  1305ÔåÆ        DataFrame with columns:\n  1306ÔåÆ        - PatientPseudonym: The patient identifier (PseudoNHSNoLinked value)\n  1307ÔåÆ        - Search_Term: The matched indication (e.g., \"rheumatoid arthritis\")\n  1308ÔåÆ        - EventDateTime: Date of the GP diagnosis record\n  1309ÔåÆ\n  1310ÔåÆ        Patients not found in results have no matching GP diagnosis.\n  1311ÔåÆ    \"\"\"\n  1312ÔåÆ    import pandas as pd\n  1313ÔåÆ\n  1314ÔåÆ    logger.info(f\"Starting Snowflake-direct indication lookup for {len(patient_pseudonyms)} patients...\")\n  1315ÔåÆ\n  1316ÔåÆ    # Handle edge case: empty patient list\n  1317ÔåÆ    if not patient_pseudonyms:\n  1318ÔåÆ        logger.warning(\"Empty patient list provided\")\n  1319ÔåÆ        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n  1320ÔåÆ\n  1321ÔåÆ    # Check Snowflake availability\n  1322ÔåÆ    if not SNOWFLAKE_AVAILABLE:\n  1323ÔåÆ        logger.error(\"Snowflake connector not available - cannot lookup GP records\")\n  1324ÔåÆ        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n  1325ÔåÆ\n  1326ÔåÆ    if not is_snowflake_configured():\n  1327ÔåÆ        logger.error(\"Snowflake not configured - cannot lookup GP records\")\n  1328ÔåÆ        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n  1329ÔåÆ\n  1330ÔåÆ    if connector is None:\n  1331ÔåÆ        connector = get_connector()\n  1332ÔåÆ\n  1333ÔåÆ    # Results list to collect all matches\n  1334ÔåÆ    all_results: list[dict] = []\n  1335ÔåÆ\n  1336ÔåÆ    # Process patients in batches\n  1337ÔåÆ    total_patients = len(patient_pseudonyms)\n  1338ÔåÆ    for batch_start in range(0, total_patients, batch_size):\n  1339ÔåÆ        batch_end = min(batch_start + batch_size, total_patients)\n  1340ÔåÆ        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n  1341ÔåÆ        batch_num = batch_start // batch_size + 1\n  1342ÔåÆ        total_batches = (total_patients + batch_size - 1) // batch_size\n  1343ÔåÆ\n  1344ÔåÆ        logger.info(f\"Batch {batch_num}/{total_batches}: patients {batch_start + 1} to {batch_end}\")\n  1345ÔåÆ\n  1346ÔåÆ        # Build patient IN clause placeholders\n  1347ÔåÆ        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n  1348ÔåÆ\n  1349ÔåÆ        # Build the full query with cluster CTE\n  1350ÔåÆ        # This finds the most recent matching diagnosis for each patient\n  1351ÔåÆ        # Note: Column names must be aliased to ensure consistent casing in results\n  1352ÔåÆ        query = f\"\"\"\n  1353ÔåÆ{CLUSTER_MAPPING_SQL}\n  1354ÔåÆSELECT\n  1355ÔåÆ    pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n  1356ÔåÆ    aic.Search_Term AS \"Search_Term\",\n  1357ÔåÆ    pc.\"EventDateTime\" AS \"EventDateTime\"\n  1358ÔåÆFROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\n  1359ÔåÆINNER JOIN AllIndicationCodes aic\n  1360ÔåÆ    ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\n  1361ÔåÆWHERE pc.\"PatientPseudonym\" IN ({patient_placeholders})\n  1362ÔåÆQUALIFY ROW_NUMBER() OVER (\n  1363ÔåÆ    PARTITION BY pc.\"PatientPseudonym\"\n  1364ÔåÆ    ORDER BY pc.\"EventDateTime\" DESC\n  1365ÔåÆ) = 1\n  1366ÔåÆ\"\"\"\n  1367ÔåÆ\n  1368ÔåÆ        try:\n  1369ÔåÆ            results = connector.execute_dict(query, tuple(batch_pseudonyms))\n  1370ÔåÆ\n  1371ÔåÆ            for row in results:\n  1372ÔåÆ                all_results.append({\n  1373ÔåÆ                    'PatientPseudonym': row.get('PatientPseudonym'),\n  1374ÔåÆ                    'Search_Term': row.get('Search_Term'),\n  1375ÔåÆ                    'EventDateTime': row.get('EventDateTime'),\n  1376ÔåÆ                })\n  1377ÔåÆ\n  1378ÔåÆ            logger.debug(f\"Batch {batch_num}: found {len(results)} matches\")\n  1379ÔåÆ\n  1380ÔåÆ        except Exception as e:\n  1381ÔåÆ            logger.error(f\"Error querying GP records for batch {batch_num}: {e}\")\n  1382ÔåÆ            # Continue with other batches - partial results are better than none\n  1383ÔåÆ\n  1384ÔåÆ    # Build result DataFrame\n  1385ÔåÆ    result_df = pd.DataFrame(all_results)\n  1386ÔåÆ\n  1387ÔåÆ    # Log summary statistics\n  1388ÔåÆ    if len(result_df) > 0:\n  1389ÔåÆ        matched_count = len(result_df)\n  1390ÔåÆ        match_rate = 100 * matched_count / total_patients\n  1391ÔåÆ        unique_terms = result_df['Search_Term'].nunique()\n  1392ÔåÆ        logger.info(f\"Indication lookup complete:\")\n  1393ÔåÆ        logger.info(f\"  Total patients queried: {total_patients}\")\n  1394ÔåÆ        logger.info(f\"  Patients with GP match: {matched_count} ({match_rate:.1f}%)\")\n  1395ÔåÆ        logger.info(f\"  Unique Search_Terms found: {unique_terms}\")\n  1396ÔåÆ\n  1397ÔåÆ        # Log top Search_Terms\n  1398ÔåÆ        top_terms = result_df['Search_Term'].value_counts().head(5)\n  1399ÔåÆ        logger.info(f\"  Top 5 indications: {dict(top_terms)}\")\n  1400ÔåÆ    else:\n  1401ÔåÆ        logger.info(f\"Indication lookup complete: 0 matches from {total_patients} patients\")\n  1402ÔåÆ\n  1403ÔåÆ    return result_df\n  1404ÔåÆ\n  1405ÔåÆ\n  1406ÔåÆ# Export public API\n  1407ÔåÆ__all__ = [\n  1408ÔåÆ    # Dataclasses\n  1409ÔåÆ    \"ClusterSnomedCodes\",\n  1410ÔåÆ    \"IndicationValidationResult\",\n  1411ÔåÆ    \"DrugIndicationMatchRate\",\n  1412ÔåÆ    \"DrugSnomedMapping\",\n  1413ÔåÆ    \"DirectSnomedMatchResult\",\n  1414ÔåÆ    \"DirectorateAssignment\",\n  1415ÔåÆ    # Cluster-based lookup functions (existing)\n  1416ÔåÆ    \"get_drug_clusters\",\n  1417ÔåÆ    \"get_drug_cluster_ids\",\n  1418ÔåÆ    \"get_cluster_snomed_codes\",\n  1419ÔåÆ    \"patient_has_indication\",\n  1420ÔåÆ    \"validate_indication\",\n  1421ÔåÆ    \"get_indication_match_rate\",\n  1422ÔåÆ    \"batch_validate_indications\",\n  1423ÔåÆ    \"get_available_clusters\",\n  1424ÔåÆ    # Direct SNOMED lookup functions (new)\n  1425ÔåÆ    \"get_drug_snomed_codes\",\n  1426ÔåÆ    \"patient_has_indication_direct\",\n  1427ÔåÆ    # Diagnosis-based directorate assignment\n  1428ÔåÆ    \"get_directorate_from_diagnosis\",\n  1429ÔåÆ    # Batch lookup for indication groups\n  1430ÔåÆ    \"batch_lookup_indication_groups\",\n  1431ÔåÆ    # Snowflake-direct indication lookup (new approach)\n  1432ÔåÆ    \"get_patient_indication_groups\",\n  1433ÔåÆ    \"CLUSTER_MAPPING_SQL\",\n  1434ÔåÆ]\n  1435ÔåÆ\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"2e510dd2-b916-4227-8b1b-9a9f48a95180","tool_use_result":{"type":"text","file":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py","content":"\"\"\"\nDiagnosis lookup module for NHS Patient Pathway Analysis.\n\nProvides functions to validate patient indications by checking GP diagnosis records\nagainst SNOMED cluster codes. Uses the drug-to-cluster mapping from\ndrug_indication_clusters.csv and queries Snowflake for SNOMED codes and GP records.\n\nKey workflow:\n1. Get drug's valid indication clusters from local mapping\n2. Get all SNOMED codes for those clusters from Snowflake\n3. Check if patient has any of those SNOMED codes in GP records\n4. Report indication validation status\n\nIMPORTANT: HCD activity data indication codes are UNRELIABLE. This module uses\nGP/Primary Care data (PrimaryCareClinicalCoding) as the authoritative source.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import date, datetime\nfrom pathlib import Path\nfrom typing import Optional, Callable, Any, cast, TYPE_CHECKING\nimport csv\n\nif TYPE_CHECKING:\n    import pandas as pd\n\nfrom core.logging_config import get_logger\nfrom data_processing.database import DatabaseManager, default_db_manager\nfrom data_processing.snowflake_connector import (\n    SnowflakeConnector,\n    get_connector,\n    is_snowflake_available,\n    is_snowflake_configured,\n    SNOWFLAKE_AVAILABLE,\n)\nfrom data_processing.cache import get_cache, is_cache_enabled\n\nlogger = get_logger(__name__)\n\n\n@dataclass\nclass ClusterSnomedCodes:\n    \"\"\"SNOMED codes for a clinical coding cluster.\"\"\"\n    cluster_id: str\n    cluster_description: str\n    snomed_codes: list[str] = field(default_factory=list)\n    snomed_descriptions: dict[str, str] = field(default_factory=dict)\n\n    @property\n    def code_count(self) -> int:\n        return len(self.snomed_codes)\n\n\n@dataclass\nclass IndicationValidationResult:\n    \"\"\"Result of validating a patient's indication for a drug.\"\"\"\n    patient_pseudonym: str\n    drug_name: str\n    has_valid_indication: bool\n    matched_cluster_id: Optional[str] = None\n    matched_snomed_code: Optional[str] = None\n    matched_snomed_description: Optional[str] = None\n    checked_clusters: list[str] = field(default_factory=list)\n    total_codes_checked: int = 0\n    source: str = \"GP_SNOMED\"  # GP_SNOMED | NONE\n    error_message: Optional[str] = None\n\n\n@dataclass\nclass DrugIndicationMatchRate:\n    \"\"\"Match rate statistics for a drug's indication validation.\"\"\"\n    drug_name: str\n    total_patients: int\n    patients_with_indication: int\n    patients_without_indication: int\n    match_rate: float  # 0.0 to 1.0\n    clusters_checked: list[str] = field(default_factory=list)\n    sample_unmatched: list[str] = field(default_factory=list)  # Sample patient IDs\n\n\n@dataclass\nclass DrugSnomedMapping:\n    \"\"\"SNOMED code mapping for a drug from ref_drug_snomed_mapping.\"\"\"\n    snomed_code: str\n    snomed_description: str\n    search_term: str\n    primary_directorate: str\n    indication: str = \"\"\n    ta_id: str = \"\"\n\n\n@dataclass\nclass DirectSnomedMatchResult:\n    \"\"\"Result of direct SNOMED code lookup in GP records.\"\"\"\n    patient_pseudonym: str\n    matched: bool\n    snomed_code: Optional[str] = None\n    snomed_description: Optional[str] = None\n    search_term: Optional[str] = None\n    primary_directorate: Optional[str] = None\n    event_date: Optional[datetime] = None\n    source: str = \"DIRECT_SNOMED\"  # DIRECT_SNOMED | NONE\n\n\n@dataclass\nclass DirectorateAssignment:\n    \"\"\"Result of directorate assignment for a patient-drug combination.\"\"\"\n    upid: str\n    drug_name: str\n    directorate: Optional[str]\n    search_term: Optional[str] = None\n    source: str = \"FALLBACK\"  # DIAGNOSIS | FALLBACK\n    snomed_code: Optional[str] = None\n    event_date: Optional[datetime] = None\n\n\ndef get_drug_clusters(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[dict]:\n    \"\"\"\n    Get all SNOMED cluster mappings for a drug from local SQLite.\n\n    Args:\n        drug_name: Drug name to look up (case-insensitive)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n\n    Returns:\n        List of dicts with keys: drug_name, indication, cluster_id,\n        cluster_description, nice_ta_reference\n    \"\"\"\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    query = \"\"\"\n        SELECT drug_name, indication, cluster_id, cluster_description, nice_ta_reference\n        FROM ref_drug_indication_clusters\n        WHERE UPPER(drug_name) = UPPER(?)\n        ORDER BY indication, cluster_id\n    \"\"\"\n\n    try:\n        with db_manager.get_connection() as conn:\n            cursor = conn.execute(query, (drug_name,))\n            rows = cursor.fetchall()\n\n            results = []\n            for row in rows:\n                results.append({\n                    \"drug_name\": row[\"drug_name\"],\n                    \"indication\": row[\"indication\"],\n                    \"cluster_id\": row[\"cluster_id\"],\n                    \"cluster_description\": row[\"cluster_description\"],\n                    \"nice_ta_reference\": row[\"nice_ta_reference\"],\n                })\n\n            logger.debug(f\"Found {len(results)} cluster mappings for drug '{drug_name}'\")\n            return results\n\n    except Exception as e:\n        logger.error(f\"Error getting clusters for drug '{drug_name}': {e}\")\n        return []\n\n\ndef get_drug_cluster_ids(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[str]:\n    \"\"\"\n    Get unique cluster IDs for a drug.\n\n    Args:\n        drug_name: Drug name to look up\n        db_manager: Optional DatabaseManager\n\n    Returns:\n        List of unique cluster IDs\n    \"\"\"\n    clusters = get_drug_clusters(drug_name, db_manager)\n    return list(set(c[\"cluster_id\"] for c in clusters))\n\n\ndef get_drug_snomed_codes(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[DrugSnomedMapping]:\n    \"\"\"\n    Get all SNOMED codes for a drug from local ref_drug_snomed_mapping table.\n\n    This uses the enriched mapping CSV data loaded into SQLite, which provides\n    direct SNOMED-to-drug mappings with Search_Term and PrimaryDirectorate.\n\n    Args:\n        drug_name: Drug name to look up (case-insensitive, matches cleaned_drug_name)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n\n    Returns:\n        List of DrugSnomedMapping with snomed_code, snomed_description,\n        search_term, primary_directorate, indication, ta_id\n    \"\"\"\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    query = \"\"\"\n        SELECT DISTINCT\n            snomed_code,\n            snomed_description,\n            search_term,\n            primary_directorate,\n            indication,\n            ta_id\n        FROM ref_drug_snomed_mapping\n        WHERE UPPER(cleaned_drug_name) = UPPER(?)\n           OR UPPER(drug_name) = UPPER(?)\n        ORDER BY search_term, snomed_code\n    \"\"\"\n\n    try:\n        with db_manager.get_connection() as conn:\n            cursor = conn.execute(query, (drug_name, drug_name))\n            rows = cursor.fetchall()\n\n            results = []\n            for row in rows:\n                results.append(DrugSnomedMapping(\n                    snomed_code=row[\"snomed_code\"],\n                    snomed_description=row[\"snomed_description\"] or \"\",\n                    search_term=row[\"search_term\"] or \"\",\n                    primary_directorate=row[\"primary_directorate\"] or \"\",\n                    indication=row[\"indication\"] or \"\",\n                    ta_id=row[\"ta_id\"] or \"\",\n                ))\n\n            logger.debug(f\"Found {len(results)} SNOMED mappings for drug '{drug_name}'\")\n            return results\n\n    except Exception as e:\n        logger.error(f\"Error getting SNOMED codes for drug '{drug_name}': {e}\")\n        return []\n\n\ndef patient_has_indication_direct(\n    patient_pseudonym: str,\n    drug_snomed_mappings: list[DrugSnomedMapping],\n    connector: Optional[SnowflakeConnector] = None,\n    before_date: Optional[date] = None,\n) -> DirectSnomedMatchResult:\n    \"\"\"\n    Check if patient has any of the SNOMED codes in their GP records.\n\n    This is the direct SNOMED lookup - it queries PrimaryCareClinicalCoding\n    for exact SNOMED code matches (not via cluster). Returns the most recent\n    match by EventDateTime if multiple matches exist.\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        drug_snomed_mappings: List of DrugSnomedMapping from get_drug_snomed_codes()\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        DirectSnomedMatchResult with match details (most recent by EventDateTime)\n    \"\"\"\n    result = DirectSnomedMatchResult(\n        patient_pseudonym=patient_pseudonym,\n        matched=False,\n        source=\"NONE\",\n    )\n\n    if not drug_snomed_mappings:\n        return result\n\n    if not SNOWFLAKE_AVAILABLE:\n        logger.warning(\"Snowflake connector not available\")\n        return result\n\n    if not is_snowflake_configured():\n        logger.warning(\"Snowflake not configured - cannot check GP records\")\n        return result\n\n    if connector is None:\n        connector = get_connector()\n\n    # Build lookup dict for mapping snomed_code -> (search_term, primary_directorate, snomed_description)\n    snomed_lookup = {\n        m.snomed_code: (m.search_term, m.primary_directorate, m.snomed_description)\n        for m in drug_snomed_mappings\n    }\n\n    # Get unique SNOMED codes\n    snomed_codes = list(snomed_lookup.keys())\n\n    # Build placeholders for SNOMED codes\n    placeholders = \", \".join([\"%s\"] * len(snomed_codes))\n\n    # Query to find most recent matching SNOMED code in GP records\n    query = f'''\n        SELECT\n            \"SNOMEDCode\",\n            \"EventDateTime\"\n        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n        WHERE \"PatientPseudonym\" = %s\n            AND \"SNOMEDCode\" IN ({placeholders})\n    '''\n\n    params: list = [patient_pseudonym] + snomed_codes\n\n    if before_date:\n        query += ' AND \"EventDateTime\" < %s'\n        params.append(before_date.isoformat())\n\n    query += ' ORDER BY \"EventDateTime\" DESC LIMIT 1'\n\n    try:\n        results = connector.execute_dict(query, tuple(params))\n\n        if results:\n            row = results[0]\n            matched_code = row.get(\"SNOMEDCode\")\n            event_dt = row.get(\"EventDateTime\")\n\n            if matched_code and matched_code in snomed_lookup:\n                search_term, primary_dir, snomed_desc = snomed_lookup[matched_code]\n\n                return DirectSnomedMatchResult(\n                    patient_pseudonym=patient_pseudonym,\n                    matched=True,\n                    snomed_code=matched_code,\n                    snomed_description=snomed_desc,\n                    search_term=search_term,\n                    primary_directorate=primary_dir,\n                    event_date=event_dt,\n                    source=\"DIRECT_SNOMED\",\n                )\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"Error checking direct SNOMED for patient '{patient_pseudonym}': {e}\")\n        return result\n\n\ndef get_directorate_from_diagnosis(\n    upid: str,\n    drug_name: str,\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    before_date: Optional[date] = None,\n) -> DirectorateAssignment:\n    \"\"\"\n    Get directorate assignment for a patient-drug combination using diagnosis-based lookup.\n\n    This function attempts to assign a directorate based on the patient's GP records\n    (direct SNOMED code matching). If no match is found, it returns a FALLBACK result\n    indicating that the caller should use alternative assignment methods (e.g.,\n    department_identification() from tools/data.py).\n\n    Workflow:\n    1. Get all SNOMED codes for the drug from ref_drug_snomed_mapping\n    2. Query patient's GP records for matching SNOMED codes\n    3. If match found ÔåÆ return diagnosis-based directorate and search_term\n    4. If no match ÔåÆ return FALLBACK result (caller handles fallback logic)\n\n    Args:\n        upid: Patient's unique patient ID (Provider Code[:3] + PersonKey)\n        drug_name: Drug name to look up\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        DirectorateAssignment with directorate, search_term, and source\n    \"\"\"\n    result = DirectorateAssignment(\n        upid=upid,\n        drug_name=drug_name,\n        directorate=None,\n        source=\"FALLBACK\",\n    )\n\n    # Step 1: Get SNOMED codes for the drug\n    drug_snomed_mappings = get_drug_snomed_codes(drug_name, db_manager)\n\n    if not drug_snomed_mappings:\n        logger.debug(f\"No SNOMED mappings found for drug '{drug_name}' - using fallback\")\n        return result\n\n    # Step 2: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        logger.debug(\"Snowflake not available - using fallback\")\n        return result\n\n    if not is_snowflake_configured():\n        logger.debug(\"Snowflake not configured - using fallback\")\n        return result\n\n    # Step 3: Get patient pseudonym from UPID\n    # UPID format is Provider Code (3 chars) + PersonKey\n    # We need to query Snowflake to get the PatientPseudonym for this PersonKey\n    # However, patient_has_indication_direct expects PatientPseudonym, not UPID\n    # For now, we'll use UPID as the identifier - the actual integration\n    # will need to happen at the DataFrame level where we have PersonKey\n    #\n    # NOTE: This function will be called from the pipeline where we have\n    # access to PatientPseudonym. The UPID is passed for logging/tracking.\n\n    # Actually, looking at the pipeline, we need PatientPseudonym, not UPID.\n    # The caller should pass the PatientPseudonym or we need to look it up.\n    # For now, let's assume the caller will use this in a batch context\n    # where they can map UPID -> PatientPseudonym.\n\n    # Let me reconsider: the function signature takes UPID but we need\n    # PatientPseudonym for Snowflake. In the pipeline context (fetch_and_transform_data),\n    # we'll have the PersonKey column which IS the PatientPseudonym.\n    # So UPID = ProviderCode[:3] + PersonKey, and PersonKey = PatientPseudonym.\n    #\n    # We can extract PatientPseudonym from UPID by removing the first 3 chars.\n    patient_pseudonym = upid[3:] if len(upid) > 3 else upid\n\n    # Step 4: Check patient's GP records for matching SNOMED codes\n    match_result = patient_has_indication_direct(\n        patient_pseudonym=patient_pseudonym,\n        drug_snomed_mappings=drug_snomed_mappings,\n        connector=connector,\n        before_date=before_date,\n    )\n\n    if match_result.matched and match_result.primary_directorate:\n        return DirectorateAssignment(\n            upid=upid,\n            drug_name=drug_name,\n            directorate=match_result.primary_directorate,\n            search_term=match_result.search_term,\n            source=\"DIAGNOSIS\",\n            snomed_code=match_result.snomed_code,\n            event_date=match_result.event_date,\n        )\n\n    # No match found - return fallback result\n    return result\n\n\ndef get_cluster_snomed_codes(\n    cluster_id: str,\n    connector: Optional[SnowflakeConnector] = None,\n    use_cache: bool = True,\n) -> ClusterSnomedCodes:\n    \"\"\"\n    Get all SNOMED codes for a cluster from Snowflake.\n\n    Queries the ClinicalCodingClusterSnomedCodes table to get all SNOMED codes\n    that belong to the specified cluster.\n\n    Args:\n        cluster_id: Cluster ID to look up (e.g., 'RARTH_COD', 'PSORIASIS_COD')\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        use_cache: Whether to use cached results (default True)\n\n    Returns:\n        ClusterSnomedCodes with list of SNOMED codes and descriptions\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE:\n        logger.warning(\"Snowflake connector not available\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n    if not is_snowflake_configured():\n        logger.warning(\"Snowflake not configured - cannot get cluster codes\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n    # Check cache first\n    cache_key = f\"cluster_snomed_{cluster_id}\"\n    if use_cache and is_cache_enabled():\n        cache = get_cache()\n        cached = cache.get(cache_key)\n        if cached is not None and len(cached) > 0:\n            logger.debug(f\"Using cached SNOMED codes for cluster '{cluster_id}'\")\n            cached_dict = cached[0]  # First element is our data dict\n            return ClusterSnomedCodes(\n                cluster_id=cluster_id,\n                cluster_description=str(cached_dict.get(\"description\", \"\")),\n                snomed_codes=list(cached_dict.get(\"codes\", [])),\n                snomed_descriptions=dict(cached_dict.get(\"descriptions\", {})),\n            )\n\n    if connector is None:\n        connector = get_connector()\n\n    query = '''\n        SELECT DISTINCT\n            \"Cluster_ID\",\n            \"Cluster_Description\",\n            \"SNOMEDCode\",\n            \"SNOMEDDescription\"\n        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n        WHERE \"Cluster_ID\" = %s\n        ORDER BY \"SNOMEDCode\"\n    '''\n\n    try:\n        results = connector.execute_dict(query, (cluster_id,))\n\n        if not results:\n            logger.warning(f\"No SNOMED codes found for cluster '{cluster_id}'\")\n            return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n        codes = []\n        descriptions = {}\n        description = results[0].get(\"Cluster_Description\", \"\") if results else \"\"\n\n        for row in results:\n            code = row.get(\"SNOMEDCode\")\n            if code:\n                codes.append(code)\n                descriptions[code] = row.get(\"SNOMEDDescription\", \"\")\n\n        logger.info(f\"Found {len(codes)} SNOMED codes for cluster '{cluster_id}'\")\n\n        # Cache the results (using query-based cache with fake params)\n        if use_cache and is_cache_enabled():\n            cache = get_cache()\n            cache_data = [{\n                \"description\": description,\n                \"codes\": codes,\n                \"descriptions\": descriptions,\n            }]\n            cache.set(cache_key, None, cache_data)  # type: ignore[arg-type]\n\n        return ClusterSnomedCodes(\n            cluster_id=cluster_id,\n            cluster_description=description,\n            snomed_codes=codes,\n            snomed_descriptions=descriptions,\n        )\n\n    except Exception as e:\n        logger.error(f\"Error getting SNOMED codes for cluster '{cluster_id}': {e}\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n\ndef patient_has_indication(\n    patient_pseudonym: str,\n    cluster_ids: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    before_date: Optional[date] = None,\n) -> tuple[bool, Optional[str], Optional[str], Optional[str]]:\n    \"\"\"\n    Check if a patient has any SNOMED codes from the specified clusters in GP records.\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        cluster_ids: List of cluster IDs to check against\n        connector: Optional SnowflakeConnector\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        Tuple of (has_indication, matched_cluster_id, matched_snomed_code, matched_description)\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        return False, None, None, None\n\n    if not cluster_ids:\n        return False, None, None, None\n\n    if connector is None:\n        connector = get_connector()\n\n    # Build placeholders for cluster IDs\n    placeholders = \", \".join([\"%s\"] * len(cluster_ids))\n\n    # Query to check if patient has any matching SNOMED code\n    query = f'''\n        SELECT\n            pc.\"SNOMEDCode\",\n            cc.\"Cluster_ID\",\n            cc.\"SNOMEDDescription\"\n        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\n        INNER JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" cc\n            ON pc.\"SNOMEDCode\" = cc.\"SNOMEDCode\"\n        WHERE pc.\"PatientPseudonym\" = %s\n            AND cc.\"Cluster_ID\" IN ({placeholders})\n    '''\n\n    params = [patient_pseudonym] + cluster_ids\n\n    if before_date:\n        query += ' AND pc.\"EventDateTime\" < %s'\n        params.append(before_date.isoformat())\n\n    query += ' LIMIT 1'\n\n    try:\n        results = connector.execute_dict(query, tuple(params))\n\n        if results:\n            row = results[0]\n            return (\n                True,\n                row.get(\"Cluster_ID\"),\n                row.get(\"SNOMEDCode\"),\n                row.get(\"SNOMEDDescription\"),\n            )\n\n        return False, None, None, None\n\n    except Exception as e:\n        logger.error(f\"Error checking indication for patient '{patient_pseudonym}': {e}\")\n        return False, None, None, None\n\n\ndef validate_indication(\n    patient_pseudonym: str,\n    drug_name: str,\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    before_date: Optional[date] = None,\n) -> IndicationValidationResult:\n    \"\"\"\n    Validate that a patient has an appropriate indication for a drug.\n\n    Full validation workflow:\n    1. Get drug's valid indication clusters from local mapping\n    2. Check if patient has any matching SNOMED codes in GP records\n    3. Return detailed validation result\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        drug_name: Drug name to validate indication for\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        IndicationValidationResult with validation details\n    \"\"\"\n    result = IndicationValidationResult(\n        patient_pseudonym=patient_pseudonym,\n        drug_name=drug_name,\n        has_valid_indication=False,\n    )\n\n    # Step 1: Get drug's cluster mappings\n    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n\n    if not cluster_ids:\n        result.error_message = f\"No cluster mappings found for drug '{drug_name}'\"\n        result.source = \"NONE\"\n        return result\n\n    result.checked_clusters = cluster_ids\n\n    # Step 2: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        result.error_message = \"Snowflake connector not installed\"\n        result.source = \"NONE\"\n        return result\n\n    if not is_snowflake_configured():\n        result.error_message = \"Snowflake not configured\"\n        result.source = \"NONE\"\n        return result\n\n    # Step 3: Check patient GP records\n    has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n        patient_pseudonym=patient_pseudonym,\n        cluster_ids=cluster_ids,\n        connector=connector,\n        before_date=before_date,\n    )\n\n    result.has_valid_indication = has_indication\n    result.matched_cluster_id = matched_cluster\n    result.matched_snomed_code = matched_code\n    result.matched_snomed_description = matched_desc\n    result.source = \"GP_SNOMED\" if has_indication else \"NONE\"\n\n    return result\n\n\ndef get_indication_match_rate(\n    drug_name: str,\n    patient_pseudonyms: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    sample_unmatched_count: int = 10,\n) -> DrugIndicationMatchRate:\n    \"\"\"\n    Calculate indication match rate for a drug across a list of patients.\n\n    Args:\n        drug_name: Drug name to check\n        patient_pseudonyms: List of patient pseudonymised NHS numbers\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        sample_unmatched_count: Number of unmatched patient IDs to include in sample\n\n    Returns:\n        DrugIndicationMatchRate with match statistics\n    \"\"\"\n    if connector is None and SNOWFLAKE_AVAILABLE and is_snowflake_configured():\n        connector = get_connector()\n\n    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n\n    total = len(patient_pseudonyms)\n    matched = 0\n    unmatched = 0\n    sample_unmatched: list[str] = []\n\n    if not cluster_ids:\n        logger.warning(f\"No cluster mappings for drug '{drug_name}' - all patients will be unmatched\")\n        return DrugIndicationMatchRate(\n            drug_name=drug_name,\n            total_patients=total,\n            patients_with_indication=0,\n            patients_without_indication=total,\n            match_rate=0.0,\n            clusters_checked=[],\n            sample_unmatched=patient_pseudonyms[:sample_unmatched_count],\n        )\n\n    for i, pseudonym in enumerate(patient_pseudonyms):\n        if i > 0 and i % 100 == 0:\n            logger.info(f\"Validating indications: {i}/{total} ({100*i/total:.1f}%)\")\n\n        has_indication, _, _, _ = patient_has_indication(\n            patient_pseudonym=pseudonym,\n            cluster_ids=cluster_ids,\n            connector=connector,\n        )\n\n        if has_indication:\n            matched += 1\n        else:\n            unmatched += 1\n            if len(sample_unmatched) < sample_unmatched_count:\n                sample_unmatched.append(pseudonym)\n\n    match_rate = matched / total if total > 0 else 0.0\n\n    logger.info(f\"Indication match rate for '{drug_name}': {100*match_rate:.1f}% ({matched}/{total})\")\n\n    return DrugIndicationMatchRate(\n        drug_name=drug_name,\n        total_patients=total,\n        patients_with_indication=matched,\n        patients_without_indication=unmatched,\n        match_rate=match_rate,\n        clusters_checked=cluster_ids,\n        sample_unmatched=sample_unmatched,\n    )\n\n\ndef batch_validate_indications(\n    patient_drug_pairs: list[tuple[str, str]],\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    progress_callback: Optional[Callable[[int, int], None]] = None,\n) -> list[IndicationValidationResult]:\n    \"\"\"\n    Validate indications for multiple patient-drug pairs efficiently.\n\n    Args:\n        patient_drug_pairs: List of (patient_pseudonym, drug_name) tuples\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        progress_callback: Optional callback(current, total) for progress updates\n\n    Returns:\n        List of IndicationValidationResult for each pair\n    \"\"\"\n    results = []\n    total = len(patient_drug_pairs)\n\n    # Cache cluster lookups by drug\n    drug_clusters_cache = {}\n\n    for i, (pseudonym, drug_name) in enumerate(patient_drug_pairs):\n        if progress_callback:\n            progress_callback(i + 1, total)\n\n        # Get clusters from cache or lookup\n        drug_upper = drug_name.upper()\n        if drug_upper not in drug_clusters_cache:\n            drug_clusters_cache[drug_upper] = get_drug_cluster_ids(drug_name, db_manager)\n\n        cluster_ids = drug_clusters_cache[drug_upper]\n\n        if not cluster_ids:\n            results.append(IndicationValidationResult(\n                patient_pseudonym=pseudonym,\n                drug_name=drug_name,\n                has_valid_indication=False,\n                source=\"NONE\",\n                error_message=f\"No cluster mappings for drug '{drug_name}'\",\n            ))\n            continue\n\n        # Check patient indication\n        has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n            patient_pseudonym=pseudonym,\n            cluster_ids=cluster_ids,\n            connector=connector,\n        )\n\n        results.append(IndicationValidationResult(\n            patient_pseudonym=pseudonym,\n            drug_name=drug_name,\n            has_valid_indication=has_indication,\n            matched_cluster_id=matched_cluster,\n            matched_snomed_code=matched_code,\n            matched_snomed_description=matched_desc,\n            checked_clusters=cluster_ids,\n            source=\"GP_SNOMED\" if has_indication else \"NONE\",\n        ))\n\n    matched_count = sum(1 for r in results if r.has_valid_indication)\n    logger.info(f\"Batch validation complete: {matched_count}/{total} ({100*matched_count/total:.1f}%) with valid indications\")\n\n    return results\n\n\ndef get_available_clusters(\n    connector: Optional[SnowflakeConnector] = None,\n) -> list[dict]:\n    \"\"\"\n    Get list of all available SNOMED clusters from Snowflake.\n\n    Returns:\n        List of dicts with cluster_id, cluster_description, code_count\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        logger.warning(\"Snowflake not available - cannot list clusters\")\n        return []\n\n    if connector is None:\n        connector = get_connector()\n\n    query = '''\n        SELECT\n            \"Cluster_ID\",\n            \"Cluster_Description\",\n            COUNT(DISTINCT \"SNOMEDCode\") as code_count\n        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n        GROUP BY \"Cluster_ID\", \"Cluster_Description\"\n        ORDER BY \"Cluster_ID\"\n    '''\n\n    try:\n        results = connector.execute_dict(query)\n\n        clusters = []\n        for row in results:\n            clusters.append({\n                \"cluster_id\": row.get(\"Cluster_ID\"),\n                \"cluster_description\": row.get(\"Cluster_Description\"),\n                \"code_count\": row.get(\"code_count\", 0),\n            })\n\n        logger.info(f\"Found {len(clusters)} available SNOMED clusters\")\n        return clusters\n\n    except Exception as e:\n        logger.error(f\"Error getting available clusters: {e}\")\n        return []\n\n\ndef batch_lookup_indication_groups(\n    df: \"pd.DataFrame\",\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    batch_size: int = 500,\n) -> \"pd.DataFrame\":\n    \"\"\"\n    Batch lookup GP diagnosis-based indication groups for a DataFrame of patients.\n\n    This is the efficient batch version of get_directorate_from_diagnosis().\n    Instead of querying Snowflake per patient, it batches the lookups for performance.\n\n    Strategy:\n    1. Get all unique (PersonKey, Drug Name) pairs from DataFrame\n    2. For each unique drug, get all SNOMED codes from local SQLite\n    3. Build batched Snowflake queries to check GP records\n    4. Return indication_df mapping UPID ÔåÆ Indication_Group\n\n    For unmatched patients, Indication_Group will be their Directory (with suffix).\n\n    Args:\n        df: DataFrame with columns: UPID, Drug Name, Directory, PersonKey\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n        batch_size: Number of patients per Snowflake query batch\n\n    Returns:\n        DataFrame with columns: UPID, Indication_Group, Source\n        - Indication_Group: Search_Term (if matched) or \"Directory (no GP dx)\" (if not)\n        - Source: \"DIAGNOSIS\" or \"FALLBACK\"\n    \"\"\"\n    import pandas as pd\n\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    logger.info(f\"Starting batch indication lookup for {len(df)} records...\")\n\n    # Step 1: Get unique (UPID, Drug Name, PseudoNHSNoLinked, Directory) combinations\n    # We need PseudoNHSNoLinked to query Snowflake - this matches PatientPseudonym in GP records\n    # Note: PersonKey is LocalPatientID which is provider-specific and does NOT match GP records\n    if 'PseudoNHSNoLinked' not in df.columns:\n        logger.error(\"DataFrame missing 'PseudoNHSNoLinked' column - cannot lookup GP records\")\n        # Return fallback for all patients\n        result_df = df[['UPID', 'Directory']].drop_duplicates().copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']]\n\n    # Get unique patient-drug combinations (we need one lookup per patient-drug pair)\n    unique_pairs = df[['UPID', 'Drug Name', 'PseudoNHSNoLinked', 'Directory']].drop_duplicates()\n    logger.info(f\"Found {len(unique_pairs)} unique patient-drug combinations\")\n\n    # Step 2: Get all unique drugs and their SNOMED codes\n    unique_drugs = unique_pairs['Drug Name'].unique()\n    logger.info(f\"Building SNOMED lookup for {len(unique_drugs)} unique drugs...\")\n\n    # Build drug -> list of DrugSnomedMapping dict\n    drug_snomed_map: dict[str, list[DrugSnomedMapping]] = {}\n    all_snomed_codes: set[str] = set()\n    snomed_to_drug_searchterm: dict[str, list[tuple[str, str, str]]] = {}  # snomed -> [(drug, search_term, primary_dir), ...]\n\n    for drug_name in unique_drugs:\n        mappings = get_drug_snomed_codes(drug_name, db_manager)\n        drug_snomed_map[drug_name] = mappings\n\n        for m in mappings:\n            all_snomed_codes.add(m.snomed_code)\n            if m.snomed_code not in snomed_to_drug_searchterm:\n                snomed_to_drug_searchterm[m.snomed_code] = []\n            snomed_to_drug_searchterm[m.snomed_code].append(\n                (drug_name, m.search_term, m.primary_directorate)\n            )\n\n    logger.info(f\"Total SNOMED codes to check: {len(all_snomed_codes)}\")\n\n    # Step 3: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        logger.warning(\"Snowflake not available - returning fallback for all patients\")\n        result_df = unique_pairs[['UPID', 'Directory']].copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n\n    if connector is None:\n        connector = get_connector()\n\n    # Step 4: Query GP records for all patients in batches\n    # The query finds the most recent matching SNOMED code for each patient\n\n    # Get unique PseudoNHSNoLinked values (each = one patient in GP records)\n    unique_patients = unique_pairs[['PseudoNHSNoLinked', 'UPID', 'Directory']].drop_duplicates(subset=['PseudoNHSNoLinked'])\n    patient_pseudonyms = unique_patients['PseudoNHSNoLinked'].tolist()\n\n    logger.info(f\"Querying GP records for {len(patient_pseudonyms)} unique patients in batches of {batch_size}...\")\n\n    # Results dict: PersonKey -> (snomed_code, event_date)\n    gp_matches: dict[str, tuple[str, Any]] = {}\n\n    # Convert SNOMED codes to list for query\n    snomed_list = list(all_snomed_codes)\n\n    if not snomed_list:\n        logger.warning(\"No SNOMED codes to check - returning fallback for all patients\")\n        result_df = unique_pairs[['UPID', 'Directory']].copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n\n    # Build SNOMED IN clause (reused across batches)\n    snomed_placeholders = \", \".join([\"%s\"] * len(snomed_list))\n\n    # Process patients in batches\n    for batch_start in range(0, len(patient_pseudonyms), batch_size):\n        batch_end = min(batch_start + batch_size, len(patient_pseudonyms))\n        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n\n        logger.info(f\"Batch {batch_start//batch_size + 1}: patients {batch_start} to {batch_end}\")\n\n        # Build patient IN clause\n        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n\n        # Query to find all matching SNOMED codes for these patients\n        # We'll get all matches and pick the most recent per patient in Python\n        query = f'''\n            SELECT\n                \"PatientPseudonym\",\n                \"SNOMEDCode\",\n                \"EventDateTime\"\n            FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n            WHERE \"PatientPseudonym\" IN ({patient_placeholders})\n              AND \"SNOMEDCode\" IN ({snomed_placeholders})\n            ORDER BY \"PatientPseudonym\", \"EventDateTime\" DESC\n        '''\n\n        params = tuple(batch_pseudonyms) + tuple(snomed_list)\n\n        try:\n            results = connector.execute_dict(query, params)\n\n            # Process results - pick most recent per patient\n            for row in results:\n                person_key = row.get(\"PatientPseudonym\")\n                snomed_code = row.get(\"SNOMEDCode\")\n                event_date = row.get(\"EventDateTime\")\n\n                if person_key and snomed_code:\n                    # Keep only if we haven't seen this patient yet (first = most recent due to ORDER BY)\n                    if person_key not in gp_matches:\n                        gp_matches[person_key] = (snomed_code, event_date)\n\n        except Exception as e:\n            logger.error(f\"Error querying GP records for batch: {e}\")\n            # Continue with other batches\n\n    logger.info(f\"Found GP matches for {len(gp_matches)} patients\")\n\n    # Step 5: Build result DataFrame\n    # For each unique_pair, determine Indication_Group based on match status\n    results_list = []\n\n    # We need to dedupe by UPID - a patient might be on multiple drugs\n    # Strategy: For each UPID, use the most recent match (if any)\n    upid_to_match: dict[str, tuple[str, str]] = {}  # UPID -> (Indication_Group, Source)\n\n    for _, row in unique_pairs.iterrows():\n        upid = row['UPID']\n        drug_name = row['Drug Name']\n        patient_pseudonym = row['PseudoNHSNoLinked']\n        directory = row['Directory']\n\n        # Check if patient has GP match (using PseudoNHSNoLinked which matches PatientPseudonym in GP)\n        if patient_pseudonym in gp_matches:\n            matched_snomed, event_date = gp_matches[patient_pseudonym]\n\n            # Find the search_term for this SNOMED code and drug\n            # (A SNOMED code might map to multiple drugs with different search_terms)\n            if matched_snomed in snomed_to_drug_searchterm:\n                # Look for match with current drug first\n                search_term = None\n                for drug, st, pd in snomed_to_drug_searchterm[matched_snomed]:\n                    if drug.upper() == drug_name.upper():\n                        search_term = st\n                        break\n                # If no drug-specific match, use any match\n                if search_term is None:\n                    search_term = snomed_to_drug_searchterm[matched_snomed][0][1]\n\n                # Only update if we don't have a match for this UPID yet\n                if upid not in upid_to_match:\n                    upid_to_match[upid] = (search_term, \"DIAGNOSIS\")\n            else:\n                # Shouldn't happen but fallback just in case\n                if upid not in upid_to_match:\n                    upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n        else:\n            # No GP match - use fallback\n            if upid not in upid_to_match:\n                upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n\n    # Build result DataFrame\n    for upid, (indication_group, source) in upid_to_match.items():\n        results_list.append({\n            'UPID': upid,\n            'Indication_Group': indication_group,\n            'Source': source,\n        })\n\n    result_df = pd.DataFrame(results_list)\n\n    # Log statistics\n    diagnosis_count = len([s for s in result_df['Source'] if s == \"DIAGNOSIS\"])\n    fallback_count = len([s for s in result_df['Source'] if s == \"FALLBACK\"])\n    total = len(result_df)\n\n    logger.info(f\"Indication lookup complete:\")\n    logger.info(f\"  Total unique patients: {total}\")\n    logger.info(f\"  DIAGNOSIS matches: {diagnosis_count} ({100*diagnosis_count/total:.1f}%)\")\n    logger.info(f\"  FALLBACK (no GP match): {fallback_count} ({100*fallback_count/total:.1f}%)\")\n\n    return result_df\n\n\n# === NEW APPROACH: Query Snowflake directly using cluster CTE ===\n\n# The cluster query mapping (embedded from snomed_indication_mapping_query.sql)\n# This maps Search_Term -> Cluster_ID for ~148 clinical conditions\nCLUSTER_MAPPING_SQL = \"\"\"\nWITH SearchTermClusters AS (\n    SELECT Search_Term, Cluster_ID FROM (VALUES\n        ('acute lymphoblastic leukaemia', 'HAEMCANMORPH_COD'),\n        ('acute myeloid leukaemia', 'C19HAEMCAN_COD'),\n        ('acute promyelocytic leukaemia', 'HAEMCANMORPH_COD'),\n        ('allergic asthma', 'AST_COD'),\n        ('allergic rhinitis', 'MILDINTAST_COD'),\n        ('alzheimer''s disease', 'DEMALZ_COD'),\n        ('amyloidosis', 'AMYLOID_COD'),\n        ('anaemia', 'eFI2_AnaemiaTimeSensitive'),\n        ('anaplastic large cell lymphoma', 'C19HAEMCAN_COD'),\n        ('apixaban', 'DOACCON_COD'),\n        ('aplastic anaemia', 'eFI2_AnaemiaEver'),\n        ('arthritis', 'eFI2_InflammatoryArthritis'),\n        ('asthma', 'eFI2_Asthma'),\n        ('atopic dermatitis', 'ATOPDERM_COD'),\n        ('atrial fibrillation', 'eFI2_AtrialFibrillation'),\n        ('attention deficit hyperactivity disorder', 'ADHD_COD'),\n        ('bipolar disorder', 'MH_COD'),\n        ('bladder', 'eFI2_UrinaryIncontinence'),\n        ('breast cancer', 'BRCANSCR_COD'),\n        ('cardiomyopathy', 'eFI2_HarmfulDrinking'),\n        ('cardiovascular disease', 'CVDRISKASS_COD'),\n        ('cervical cancer', 'CSDEC_COD'),\n        ('cholangiocarcinoma', 'eFI2_Cancer'),\n        ('chronic kidney disease', 'CKD_COD'),\n        ('chronic liver disease', 'eFI2_LiverProblems'),\n        ('chronic lymphocytic leukaemia', 'EPPHAEMCAN_COD'),\n        ('chronic myeloid leukaemia', 'EPPHAEMCAN_COD'),\n        ('chronic obstructive pulmonary disease', 'eFI2_COPD'),\n        ('colon cancer', 'eFI2_Cancer'),\n        ('colorectal cancer', 'GICANREF_COD'),\n        ('constipation', 'CHRONCONSTIP_COD'),\n        ('covid-19', 'POSSPOSTCOVID_COD'),\n        ('crohn''s disease', 'eFI2_InflammatoryBowelDisease'),\n        ('cutaneous t-cell lymphoma', 'C19HAEMCAN_COD'),\n        ('cystic fibrosis', 'CUST_ICB_CYSTIC_FIBROSIS'),\n        ('deep vein thrombosis', 'VTE_COD'),\n        ('depression', 'eFI2_Depression'),\n        ('diabetes', 'eFI2_DiabetesEver'),\n        ('diabetic retinopathy', 'DRSELIGIBILITY_COD'),\n        ('diffuse large b-cell lymphoma', 'C19HAEMCAN_COD'),\n        ('dravet syndrome', 'EPIL_COD'),\n        ('drug misuse', 'ILLSUBINT_COD'),\n        ('dyspepsia', 'eFI2_AbdominalPain'),\n        ('epilepsy', 'eFI2_Seizures'),\n        ('fallopian tube', 'STERIL_COD'),\n        ('follicular lymphoma', 'C19HAEMCAN_COD'),\n        ('gastric cancer', 'eFI2_Cancer'),\n        ('giant cell arteritis', 'GCA_COD'),\n        ('glioma', 'NHAEMCANMORPH_COD'),\n        ('gout', 'eFI2_InflammatoryArthritis'),\n        ('graft versus host disease', 'GVHD_COD'),\n        ('granulomatosis with polyangiitis', 'WEGENERVASC_COD'),\n        ('growth hormone deficiency', 'HYPOPITUITARY_COD'),\n        ('hand eczema', 'ECZEMA_COD'),\n        ('heart failure', 'eFI2_HeartFailure'),\n        ('hepatitis b', 'HEPBCVAC_COD'),\n        ('hepatocellular carcinoma', 'eFI2_Cancer'),\n        ('hiv', 'PREFLANG_COD'),\n        ('hodgkin lymphoma', 'HAEMCANMORPH_COD'),\n        ('hormone receptor', 'eFI2_ThyroidProblems'),\n        ('hypercholesterolaemia', 'CLASSFH_COD'),\n        ('immune thrombocytopenia', 'ITP_COD'),\n        ('influenza', 'FLUINVITE_COD'),\n        ('insomnia', 'eFI2_SleepProblems'),\n        ('irritable bowel syndrome', 'IBS_COD'),\n        ('ischaemic stroke', 'OSTR_COD'),\n        ('juvenile idiopathic arthritis', 'RARTHAD_COD'),\n        ('kidney transplant', 'RENALTRANSP_COD'),\n        ('leukaemia', 'eFI2_Cancer'),\n        ('lung cancer', 'FTCANREF_COD'),\n        ('lymphoma', 'C19HAEMCAN_COD'),\n        ('macular degeneration', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('macular oedema', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('major depressive episodes', 'eFI2_Depression'),\n        ('malignant melanoma', 'eFI2_Cancer'),\n        ('malignant pleural mesothelioma', 'LUNGCAN_COD'),\n        ('manic episode', 'MH_COD'),\n        ('mantle cell lymphoma', 'HAEMCANMORPH_COD'),\n        ('melanoma', 'eFI2_Cancer'),\n        ('merkel cell carcinoma', 'C19CAN_COD'),\n        ('migraine', 'eFI2_Headache'),\n        ('motor neurone disease', 'MND_COD'),\n        ('multiple myeloma', 'C19HAEMCAN_COD'),\n        ('multiple sclerosis', 'MS_COD'),\n        ('myelodysplastic', 'eFI2_AnaemiaEver'),\n        ('myelofibrosis', 'MDS_COD'),\n        ('myocardial infarction', 'eFI2_IschaemicHeartDisease'),\n        ('myotonia', 'CNDATRISK2_COD'),\n        ('narcolepsy', 'LD_COD'),\n        ('neuroendocrine tumour', 'LUNGCAN_COD'),\n        ('non-small cell lung cancer', 'LUNGCAN_COD'),\n        ('non-small-cell lung cancer', 'FTCANREF_COD'),\n        ('obesity', 'BMI30_COD'),\n        ('osteoarthritis', 'CUST_ICB_OSTEOARTHRITIS'),\n        ('osteoporosis', 'eFI2_Osteoporosis'),\n        ('osteosarcoma', 'NHAEMCANMORPH_COD'),\n        ('ovarian cancer', 'C19CAN_COD'),\n        ('peripheral arterial disease', 'PADEXC_COD'),\n        ('plaque psoriasis', 'PSORIASIS_COD'),\n        ('polycystic kidney disease', 'EPPCONGMALF_COD'),\n        ('polycythaemia vera', 'C19HAEMCAN_COD'),\n        ('pregnancy', 'C19PREG_COD'),\n        ('primary biliary cholangitis', 'eFI2_LiverProblems'),\n        ('primary hypercholesterolaemia', 'FNFHYP_COD'),\n        ('prostate cancer', 'EPPSOLIDCAN_COD'),\n        ('psoriasis', 'PSORIASIS_COD'),\n        ('psoriatic arthritis', 'RARTHAD_COD'),\n        ('pulmonary embolism', 'eFI2_RespiratoryDiseaseTimeSensitive'),\n        ('pulmonary fibrosis', 'ILD_COD'),\n        ('relapsing multiple sclerosis', 'MS_COD'),\n        ('renal cell carcinoma', 'C19CAN_COD'),\n        ('renal transplantation', 'RENALTRANSP_COD'),\n        ('retinal vein occlusion', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('rheumatoid arthritis', 'eFI2_InflammatoryArthritis'),\n        ('rivaroxaban', 'DOACCON_COD'),\n        ('schizophrenia', 'MH_COD'),\n        ('seizures', 'LSZFREQ_COD'),\n        ('sepsis', 'C19ACTIVITY_COD'),\n        ('severe persistent allergic asthma', 'SEVAST_COD'),\n        ('sickle cell disease', 'SICKLE_COD'),\n        ('sleep apnoea', 'CUST_ICB_NON_SEVERE_LDA'),\n        ('smoking cessation', 'SMOKINGINT_COD'),\n        ('soft tissue sarcoma', 'NHAEMCANMORPH_COD'),\n        ('spinal muscular atrophy', 'MND_COD'),\n        ('squamous cell', 'C19CAN_COD'),\n        ('squamous cell carcinoma', 'C19CAN_COD'),\n        ('stem cell transplant', 'ALLOTRANSP_COD'),\n        ('stroke', 'eFI2_Stroke'),\n        ('systemic lupus erythematosus', 'SLUPUS_COD'),\n        ('systemic mastocytosis', 'HAEMCANMORPH_COD'),\n        ('thrombocytopenic purpura', 'TTP_COD'),\n        ('thrombotic thrombocytopenic purpura', 'TTP_COD'),\n        ('thyroid cancer', 'C19CAN_COD'),\n        ('tophaceous gout', 'CUST_ICB_OSTEOARTHRITIS'),\n        ('transitional cell carcinoma', 'C19CAN_COD'),\n        ('type 1 diabetes', 'DMTYPE1_COD'),\n        ('type 2 diabetes', 'DMTYPE2_COD'),\n        ('ulcerative colitis', 'eFI2_InflammatoryBowelDisease'),\n        ('urothelial carcinoma', 'NHAEMCANMORPH_COD'),\n        ('urticaria', 'XSAL_COD'),\n        ('uveitis', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('vascular disease', 'CVDINVITE_COD'),\n        ('vasculitis', 'CRYOGLOBVASC_COD')\n    ) AS t(Search_Term, Cluster_ID)\n),\n\nClusterCodes AS (\n    SELECT\n        stc.Search_Term,\n        c.\"SNOMEDCode\",\n        c.\"SNOMEDDescription\"\n    FROM SearchTermClusters stc\n    JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" c\n        ON stc.Cluster_ID = c.\"Cluster_ID\"\n    WHERE c.\"SNOMEDCode\" IS NOT NULL\n),\n\nExplicitCodes AS (\n    SELECT Search_Term, SNOMEDCode, SNOMEDDescription FROM (VALUES\n        ('acute coronary syndrome', '837091000000100', 'Manual mapping'),\n        ('ankylosing spondylitis', '162930007', 'Manual mapping'),\n        ('ankylosing spondylitis', '239805001', 'Manual mapping'),\n        ('ankylosing spondylitis', '239810002', 'Manual mapping'),\n        ('ankylosing spondylitis', '239811003', 'Manual mapping'),\n        ('ankylosing spondylitis', '394990003', 'Manual mapping'),\n        ('ankylosing spondylitis', '429712009', 'Manual mapping'),\n        ('ankylosing spondylitis', '441562009', 'Manual mapping'),\n        ('ankylosing spondylitis', '441680005', 'Manual mapping'),\n        ('ankylosing spondylitis', '441930001', 'Manual mapping'),\n        ('axial spondyloarthritis', '723116002', 'Manual mapping'),\n        ('choroidal neovascularisation', '380621000000102', 'Manual mapping'),\n        ('choroidal neovascularisation', '733124000', 'Manual mapping')\n    ) AS t(Search_Term, SNOMEDCode, SNOMEDDescription)\n),\n\nAllIndicationCodes AS (\n    SELECT Search_Term, \"SNOMEDCode\" AS SNOMEDCode, \"SNOMEDDescription\" AS SNOMEDDescription\n    FROM ClusterCodes\n    UNION ALL\n    SELECT Search_Term, SNOMEDCode, SNOMEDDescription\n    FROM ExplicitCodes\n)\n\"\"\"\n\n\ndef get_patient_indication_groups(\n    patient_pseudonyms: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    batch_size: int = 500,\n) -> \"pd.DataFrame\":\n    \"\"\"\n    Batch lookup GP diagnosis-based indication groups using Snowflake cluster query.\n\n    This function queries Snowflake directly using the embedded cluster CTE\n    (from snomed_indication_mapping_query.sql) to find patients with matching\n    GP diagnoses. This is the NEW approach replacing the old SQLite-based lookup.\n\n    The query:\n    1. Uses the cluster mapping CTE to get all Search_Term -> SNOMED code mappings\n    2. Joins with PrimaryCareClinicalCoding to find patients with matching codes\n    3. Returns the most recent match per patient (by EventDateTime)\n\n    Args:\n        patient_pseudonyms: List of PseudoNHSNoLinked values (matches PatientPseudonym in GP records)\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        batch_size: Number of patients per Snowflake query batch (default 500)\n\n    Returns:\n        DataFrame with columns:\n        - PatientPseudonym: The patient identifier (PseudoNHSNoLinked value)\n        - Search_Term: The matched indication (e.g., \"rheumatoid arthritis\")\n        - EventDateTime: Date of the GP diagnosis record\n\n        Patients not found in results have no matching GP diagnosis.\n    \"\"\"\n    import pandas as pd\n\n    logger.info(f\"Starting Snowflake-direct indication lookup for {len(patient_pseudonyms)} patients...\")\n\n    # Handle edge case: empty patient list\n    if not patient_pseudonyms:\n        logger.warning(\"Empty patient list provided\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    # Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        logger.error(\"Snowflake connector not available - cannot lookup GP records\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    if not is_snowflake_configured():\n        logger.error(\"Snowflake not configured - cannot lookup GP records\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    if connector is None:\n        connector = get_connector()\n\n    # Results list to collect all matches\n    all_results: list[dict] = []\n\n    # Process patients in batches\n    total_patients = len(patient_pseudonyms)\n    for batch_start in range(0, total_patients, batch_size):\n        batch_end = min(batch_start + batch_size, total_patients)\n        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n        batch_num = batch_start // batch_size + 1\n        total_batches = (total_patients + batch_size - 1) // batch_size\n\n        logger.info(f\"Batch {batch_num}/{total_batches}: patients {batch_start + 1} to {batch_end}\")\n\n        # Build patient IN clause placeholders\n        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n\n        # Build the full query with cluster CTE\n        # This finds the most recent matching diagnosis for each patient\n        # Note: Column names must be aliased to ensure consistent casing in results\n        query = f\"\"\"\n{CLUSTER_MAPPING_SQL}\nSELECT\n    pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n    aic.Search_Term AS \"Search_Term\",\n    pc.\"EventDateTime\" AS \"EventDateTime\"\nFROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\nINNER JOIN AllIndicationCodes aic\n    ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\nWHERE pc.\"PatientPseudonym\" IN ({patient_placeholders})\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY pc.\"PatientPseudonym\"\n    ORDER BY pc.\"EventDateTime\" DESC\n) = 1\n\"\"\"\n\n        try:\n            results = connector.execute_dict(query, tuple(batch_pseudonyms))\n\n            for row in results:\n                all_results.append({\n                    'PatientPseudonym': row.get('PatientPseudonym'),\n                    'Search_Term': row.get('Search_Term'),\n                    'EventDateTime': row.get('EventDateTime'),\n                })\n\n            logger.debug(f\"Batch {batch_num}: found {len(results)} matches\")\n\n        except Exception as e:\n            logger.error(f\"Error querying GP records for batch {batch_num}: {e}\")\n            # Continue with other batches - partial results are better than none\n\n    # Build result DataFrame\n    result_df = pd.DataFrame(all_results)\n\n    # Log summary statistics\n    if len(result_df) > 0:\n        matched_count = len(result_df)\n        match_rate = 100 * matched_count / total_patients\n        unique_terms = result_df['Search_Term'].nunique()\n        logger.info(f\"Indication lookup complete:\")\n        logger.info(f\"  Total patients queried: {total_patients}\")\n        logger.info(f\"  Patients with GP match: {matched_count} ({match_rate:.1f}%)\")\n        logger.info(f\"  Unique Search_Terms found: {unique_terms}\")\n\n        # Log top Search_Terms\n        top_terms = result_df['Search_Term'].value_counts().head(5)\n        logger.info(f\"  Top 5 indications: {dict(top_terms)}\")\n    else:\n        logger.info(f\"Indication lookup complete: 0 matches from {total_patients} patients\")\n\n    return result_df\n\n\n# Export public API\n__all__ = [\n    # Dataclasses\n    \"ClusterSnomedCodes\",\n    \"IndicationValidationResult\",\n    \"DrugIndicationMatchRate\",\n    \"DrugSnomedMapping\",\n    \"DirectSnomedMatchResult\",\n    \"DirectorateAssignment\",\n    # Cluster-based lookup functions (existing)\n    \"get_drug_clusters\",\n    \"get_drug_cluster_ids\",\n    \"get_cluster_snomed_codes\",\n    \"patient_has_indication\",\n    \"validate_indication\",\n    \"get_indication_match_rate\",\n    \"batch_validate_indications\",\n    \"get_available_clusters\",\n    # Direct SNOMED lookup functions (new)\n    \"get_drug_snomed_codes\",\n    \"patient_has_indication_direct\",\n    # Diagnosis-based directorate assignment\n    \"get_directorate_from_diagnosis\",\n    # Batch lookup for indication groups\n    \"batch_lookup_indication_groups\",\n    # Snowflake-direct indication lookup (new approach)\n    \"get_patient_indication_groups\",\n    \"CLUSTER_MAPPING_SQL\",\n]\n","numLines":1435,"startLine":1,"totalLines":1435}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011T86Lo6hUUXt3G8EYdq6NZ","type":"message","role":"assistant","content":[{"type":"text","text":"Good. I've read all the key files. Let me assess the situation:\n\n**This is Iteration 1.** All tasks are `[ ]`. No previous work has been done.\n\n**Task selection reasoning:**\n\nLooking at the IMPLEMENTATION_PLAN.md phases:\n- **Phase 1** (1.1 and 1.2) ÔÇö foundational: update the Snowflake query + build drug mapping\n- **Phase 2** (2.1 and 2.2) ÔÇö depends on Phase 1 outputs  \n- **Phase 3** (3.1 and 3.2) ÔÇö depends on Phase 2\n- **Phase 4** (4.1-4.3) ÔÇö depends on Phase 3\n\nThe natural starting point is **Task 1.1** (update `get_patient_indication_groups()`) AND **Task 1.2** (build drug-to-Search_Term mapping). These are independent of each other ÔÇö 1.1 modifies the Snowflake query, 1.2 loads from CSV. However, per the \"one task per iteration\" rule, I'll start with **Task 1.2** because it's self-contained, requires no Snowflake access to test, and can be validated locally. Task 1.1 modifies the Snowflake query which can't be tested without a live connection.\n\nLet me mark Task 1.2 as in-progress and implement it."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5960,"cache_creation_input_tokens":22022,"cache_read_input_tokens":78619,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22022},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"1e65503d-2d7d-49d2-b592-e0af09671275"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011T86Lo6hUUXt3G8EYdq6NZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017iKQvseZgodTNduStuPsBy","name":"TodoWrite","input":{"todos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"in_progress","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"pending","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"pending","activeForm":"Updating progress and committing changes"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5960,"cache_creation_input_tokens":22022,"cache_read_input_tokens":78619,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":22022},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"e3174850-96f6-4093-a18d-5d6b7fa62fd9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017iKQvseZgodTNduStuPsBy","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"217c0f81-5861-4c1f-a37e-a1d45757a778","tool_use_result":{"oldTodos":[],"newTodos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"in_progress","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"pending","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"pending","activeForm":"Updating progress and committing changes"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015QxChuKyziYDLvkaBJxpUJ","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me mark Task 1.2 as in-progress in IMPLEMENTATION_PLAN.md."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6507,"cache_read_input_tokens":100641,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6507},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"c32de5c9-e768-47c6-a32e-fb1f30317d2c"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015QxChuKyziYDLvkaBJxpUJ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EL1BzQHsHUXfrYLS9NY83L","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md","old_string":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [ ] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","new_string":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [~] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":6507,"cache_read_input_tokens":100641,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":6507},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"c1fef445-3485-42a2-bb85-0e0d1f203bcf"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EL1BzQHsHUXfrYLS9NY83L","type":"tool_result","content":"The file C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"eb99a87a-9bec-4285-80c0-4596d69a2e73","tool_use_result":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md","oldString":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [ ] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","newString":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [~] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","originalFile":"# Implementation Plan - Drug-Aware Indication Matching\n\n## Project Overview\n\nUpdate the indication-based pathway charts so that patient indications are matched **per drug**, not just per patient. Currently, each patient gets ONE indication (most recent GP diagnosis match). This ignores which drugs the patient is actually taking.\n\n### The Problem\n\nA patient on ADALIMUMAB + OMALIZUMAB currently gets assigned a single indication (e.g., \"rheumatoid arthritis\" ÔÇö the most recent GP match). But:\n- ADALIMUMAB is used for rheumatoid arthritis, axial spondyloarthritis, crohn's disease, etc.\n- OMALIZUMAB is used for asthma, allergic asthma, urticaria\n\nThese are different clinical pathways and should be treated as separate treatment journeys.\n\n### The Solution\n\nMatch each drug to an indication by cross-referencing:\n1. **GP diagnosis** ÔÇö which Search_Terms the patient has matching SNOMED codes for\n2. **Drug mapping** ÔÇö which Search_Terms list each drug (from `DimSearchTerm.csv`)\n\nOnly assign a drug to an indication if BOTH conditions are met. If a patient's drugs map to different indications, they become separate pathways (via modified UPID).\n\n### Key Design Decisions\n\n| Aspect | Decision |\n|--------|----------|\n| Drug-indication source | `data/DimSearchTerm.csv` ÔÇö Search_Term ÔåÆ CleanedDrugName mapping |\n| UPID modification | `{original_UPID}\\|{search_term}` for drugs with matched indication |\n| GP diagnosis matching | Return ALL matches per patient (not just most recent) |\n| Drug matching | Substring match: HCD drug name contains DimSearchTerm fragment |\n| Multiple indication matches per drug | Use highest GP code frequency as tiebreaker (COUNT of matching SNOMED codes per Search_Term) |\n| GP code time range | Only codes from MIN(Intervention Date) onwards ÔÇö restricts to HCD data window |\n| No indication match | Fallback to directory (same as current behavior) |\n| Same patient, different indications | Separate pathways via different modified UPIDs |\n\n### Examples\n\n**Patient on ADALIMUMAB + GOLIMUMAB, GP dx: axial spondyloarthritis + asthma**\n- axial spondyloarthritis drug list includes both ADALIMUMAB and GOLIMUMAB\n- ÔåÆ Both drugs grouped under \"axial spondyloarthritis\", single pathway\n- Modified UPID: `RMV12345|axial spondyloarthritis`\n\n**Patient on ADALIMUMAB + OMALIZUMAB, GP dx: axial spondyloarthritis + asthma**\n- axial spondyloarthritis lists ADALIMUMAB but not OMALIZUMAB\n- asthma lists OMALIZUMAB but not ADALIMUMAB\n- ÔåÆ Two separate pathways:\n  - `RMV12345|axial spondyloarthritis` with ADALIMUMAB\n  - `RMV12345|asthma` with OMALIZUMAB\n\n**Patient on ADALIMUMAB, GP dx: rheumatoid arthritis (47 codes) + crohn's disease (2 codes)**\n- Both Search_Terms list ADALIMUMAB AND patient has GP dx for both\n- ÔåÆ Tiebreaker: highest code frequency ÔÇö rheumatoid arthritis has 47 matching SNOMED codes vs 2 for crohn's\n- ÔåÆ Single pathway under rheumatoid arthritis (more clinical activity = more likely the treatment indication)\n\n---\n\n## Phase 1: Update Snowflake Query & Drug Mapping\n\n### 1.1 Update `get_patient_indication_groups()` to return ALL matches with frequency\n- [ ] Modify the Snowflake query in `get_patient_indication_groups()` (diagnosis_lookup.py):\n  - Remove `QUALIFY ROW_NUMBER() OVER (PARTITION BY ... ORDER BY EventDateTime DESC) = 1`\n  - Return ALL matching Search_Terms per patient with code frequency:\n    ```sql\n    SELECT pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n           aic.Search_Term AS \"Search_Term\",\n           COUNT(*) AS \"code_frequency\"\n    FROM PrimaryCareClinicalCoding pc\n    JOIN AllIndicationCodes aic ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\n    WHERE pc.\"PatientPseudonym\" IN (...)\n      AND pc.\"EventDateTime\" >= :earliest_hcd_date\n    GROUP BY pc.\"PatientPseudonym\", aic.Search_Term\n    ```\n  - `code_frequency` = number of matching SNOMED codes per Search_Term per patient\n  - Higher frequency = more clinical activity = stronger signal for tiebreaker\n  - `earliest_hcd_date` = `MIN(Intervention Date)` from the HCD DataFrame ÔÇö restricts GP codes to the HCD data window, reducing noise from old/irrelevant diagnoses\n- [ ] Accept `earliest_hcd_date` parameter in `get_patient_indication_groups()` and pass to query\n- [ ] Keep batch processing (500 patients per query)\n- [ ] Update return type: DataFrame now has multiple rows per patient (PatientPseudonym, Search_Term, code_frequency)\n- [ ] Verify: Query returns more rows than before (patients with multiple matching diagnoses)\n\n### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [ ] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`\n  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n- [ ] Add function `drug_matches_search_term(drug_name: str, search_term: str, mapping: dict) -> bool`:\n  - Checks if the drug name matches any fragment in the Search_Term's drug list\n  - Match logic: any fragment from DimSearchTerm is a substring of the drug name (case-insensitive)\n- [ ] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"\n\n---\n\n## Phase 2: Drug-Aware Indication Matching Logic\n\n### 2.1 Create `assign_drug_indications()` function\n- [ ] Add to `diagnosis_lookup.py` or `pathway_pipeline.py`:\n  ```\n  def assign_drug_indications(\n      df: pd.DataFrame,              # HCD data with UPID, Drug Name columns\n      gp_matches_df: pd.DataFrame,   # PatientPseudonym ÔåÆ list of matched Search_Terms\n      drug_mapping: dict,             # From load_drug_indication_mapping()\n  ) -> tuple[pd.DataFrame, pd.DataFrame]:\n      Returns: (modified_df, indication_df)\n      - modified_df: HCD data with UPID replaced by {UPID}|{indication}\n      - indication_df: mapping modified_UPID ÔåÆ Search_Term\n  ```\n- [ ] Logic per UPID + Drug Name pair:\n  1. Get patient's GP-matched Search_Terms with code_frequency (from gp_matches_df via PseudoNHSNoLinked)\n  2. Get which Search_Terms include this drug (from drug_mapping)\n  3. Intersection = valid indications for this drug-patient pair\n  4. If 1 match: use it\n  5. If multiple matches: use highest code_frequency as tiebreaker (most GP coding activity = most likely treatment indication)\n  6. If 0 matches: use fallback directory\n- [ ] Modify UPID in df rows: `{original_UPID}|{matched_search_term}`\n- [ ] Build indication_df: `{modified_UPID}` ÔåÆ `Search_Term` (or fallback label)\n- [ ] Verify: Function compiles, handles edge cases (no GP match, no drug match)\n\n### 2.2 Handle tiebreaker for multiple indication matches\n- [ ] When a drug matches multiple Search_Terms AND patient has GP dx for multiple:\n  - Use `code_frequency` from the GP query (COUNT of matching SNOMED codes per Search_Term)\n  - Higher code_frequency = more clinical activity for that condition = more likely treatment indication\n  - E.g., patient with 47 RA codes and 2 crohn's codes ÔåÆ ADALIMUMAB assigned to RA\n  - code_frequency is already returned by the updated query in Task 1.1\n- [ ] Verify: Tiebreaker logic correctly picks highest-frequency diagnosis\n- [ ] Verify: Tie on frequency (rare but possible) falls back to alphabetical Search_Term for determinism\n\n---\n\n## Phase 3: Pipeline Integration\n\n### 3.1 Update `refresh_pathways.py` indication processing\n- [ ] In the `elif current_chart_type == \"indication\":` block:\n  1. Call `get_patient_indication_groups()` as before (but now returns ALL matches)\n  2. Load drug mapping: `drug_mapping = load_drug_indication_mapping()`\n  3. Call `assign_drug_indications(df, gp_matches_df, drug_mapping)`\n  4. Use modified_df (with indication-aware UPIDs) for pathway processing\n  5. Use indication_df for the indication mapping\n- [ ] Pass modified_df (not original df) to `process_indication_pathway_for_date_filter()`\n- [ ] Verify: Pipeline compiles, `python -m py_compile cli/refresh_pathways.py`\n\n### 3.2 Test with dry run\n- [ ] Run `python -m cli.refresh_pathways --chart-type indication --dry-run -v`\n- [ ] Verify:\n  - Modified UPIDs appear in pipeline log (e.g., `RMV12345|rheumatoid arthritis`)\n  - Patient counts are reasonable (will be higher than before since same patient can appear under multiple indications)\n  - Drug-indication matching is logged (match rate, fallback rate)\n  - Pathway hierarchy shows drug-specific grouping under correct indications\n\n---\n\n## Phase 4: Full Refresh & Validation\n\n### 4.1 Full refresh with both chart types\n- [ ] Run `python -m cli.refresh_pathways --chart-type all`\n- [ ] Verify:\n  - Both chart types generate data\n  - Directory charts unchanged (no modified UPIDs)\n  - Indication charts reflect drug-aware matching\n\n### 4.2 Validate indication chart correctness\n- [ ] Check that drugs under an indication all appear in that Search_Term's drug list\n- [ ] Verify that a patient on drugs for different indications creates separate pathway branches\n- [ ] Verify that drugs sharing an indication are grouped in the same pathway\n- [ ] Log: patient count comparison (old vs new approach)\n\n### 4.3 Validate Reflex UI\n- [ ] Run `python -m reflex compile` to verify app compiles\n- [ ] Verify chart type toggle still works\n- [ ] Verify indication chart shows correct hierarchy\n\n---\n\n## Completion Criteria\n\nAll tasks marked `[x]` AND:\n- [ ] App compiles without errors (`reflex compile` succeeds)\n- [ ] Both chart types generate pathway data\n- [ ] Indication charts show drug-specific indication matching\n- [ ] Drugs under the same indication for the same patient are in one pathway\n- [ ] Drugs under different indications for the same patient create separate pathways\n- [ ] Fallback works for drugs with no indication match\n- [ ] Full refresh completes successfully\n- [ ] Existing directory charts are unaffected\n\n---\n\n## Reference\n\n### DimSearchTerm.csv Structure\n```\nSearch_Term,CleanedDrugName,PrimaryDirectorate\nrheumatoid arthritis,ABATACEPT|ADALIMUMAB|ANAKINRA|BARICITINIB|...,RHEUMATOLOGY\nasthma,BENRALIZUMAB|DUPILUMAB|INHALED|MEPOLIZUMAB|OMALIZUMAB|RESLIZUMAB,THORACIC MEDICINE\n```\n\n### Modified UPID Format\n```\nOriginal:  RMV12345\nModified:  RMV12345|rheumatoid arthritis\nFallback:  RMV12345|RHEUMATOLOGY (no GP dx)\n```\n\n### Current vs New Indication Flow\n```\nCURRENT:\n  Patient ÔåÆ GP dx (most recent) ÔåÆ single Search_Term ÔåÆ one pathway\n\nNEW:\n  Patient + Drug A ÔåÆ GP dx matching Drug A ÔåÆ Search_Term X\n  Patient + Drug B ÔåÆ GP dx matching Drug B ÔåÆ Search_Term Y\n  ÔåÆ If X == Y: one pathway under X\n  ÔåÆ If X != Y: two pathways (modified UPIDs)\n```\n\n### Key Files\n\n| File | Changes |\n|------|---------|\n| `data_processing/diagnosis_lookup.py` | Update query, add drug mapping functions |\n| `data_processing/pathway_pipeline.py` | Possibly minor changes for modified UPIDs |\n| `cli/refresh_pathways.py` | Integrate drug-aware matching into pipeline |\n| `data/DimSearchTerm.csv` | Reference data (read-only) |\n| `analysis/pathway_analyzer.py` | No changes expected (UPID changes are transparent) |\n| `pathways_app/pathways_app.py` | No changes expected |\n","structuredPatch":[{"oldStart":79,"oldLines":7,"newStart":79,"newLines":7,"lines":[" - [ ] Verify: Query returns more rows than before (patients with multiple matching diagnoses)"," "," ### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv","-- [ ] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","+- [~] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","   - Loads `data/DimSearchTerm.csv`","   - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`","   - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01F9U622gACXikqCnmmmkDAP","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll implement the two functions. Looking at the DimSearchTerm.csv structure:\n- `Search_Term` ÔÇö clinical condition\n- `CleanedDrugName` ÔÇö pipe-separated drug fragments  \n- `PrimaryDirectorate` ÔÇö the directorate\n\nNote: `diabetes` appears twice (DIABETIC MEDICINE and OPHTHALMOLOGY directorates). For indication charts, we use Search_Term not directorate, so the drug fragments from both rows should be combined.\n\nLet me add the functions to `diagnosis_lookup.py`. I'll add them right before the `CLUSTER_MAPPING_SQL` constant since they're logically in the \"drug mapping\" category."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":296,"cache_read_input_tokens":107148,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":296},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"50ce28bb-1d19-407a-a55e-c75259ded9e8"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01F9U622gACXikqCnmmmkDAP","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01BBvWPg9vZnrjPpc1VzRHVa","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py","old_string":"# === NEW APPROACH: Query Snowflake directly using cluster CTE ===","new_string":"# === Drug-to-indication mapping from DimSearchTerm.csv ===\n\n\ndef load_drug_indication_mapping(\n    csv_path: Optional[str] = None,\n) -> tuple[dict[str, list[str]], dict[str, list[str]]]:\n    \"\"\"\n    Load the drug-to-Search_Term mapping from DimSearchTerm.csv.\n\n    Builds two lookup dicts:\n    - fragment_to_search_terms: drug fragment (UPPERCASE) -> list of Search_Terms containing it\n    - search_term_to_fragments: search_term -> list of drug fragments (UPPERCASE)\n\n    DimSearchTerm.csv has columns: Search_Term, CleanedDrugName, PrimaryDirectorate\n    CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\").\n\n    Note: A Search_Term can appear multiple times with different PrimaryDirectorates\n    (e.g., \"diabetes\" appears under both DIABETIC MEDICINE and OPHTHALMOLOGY).\n    Drug fragments from all rows for the same Search_Term are combined.\n\n    Args:\n        csv_path: Path to DimSearchTerm.csv. Defaults to data/DimSearchTerm.csv.\n\n    Returns:\n        Tuple of (fragment_to_search_terms, search_term_to_fragments)\n    \"\"\"\n    if csv_path is None:\n        csv_path = str(Path(__file__).parent.parent / \"data\" / \"DimSearchTerm.csv\")\n\n    fragment_to_search_terms: dict[str, list[str]] = {}\n    search_term_to_fragments: dict[str, list[str]] = {}\n\n    try:\n        with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                search_term = row.get(\"Search_Term\", \"\").strip()\n                drug_names_raw = row.get(\"CleanedDrugName\", \"\").strip()\n\n                if not search_term or not drug_names_raw:\n                    continue\n\n                fragments = [frag.strip().upper() for frag in drug_names_raw.split(\"|\") if frag.strip()]\n\n                # Build search_term -> fragments (accumulate for duplicate Search_Terms)\n                if search_term not in search_term_to_fragments:\n                    search_term_to_fragments[search_term] = []\n                for frag in fragments:\n                    if frag not in search_term_to_fragments[search_term]:\n                        search_term_to_fragments[search_term].append(frag)\n\n                # Build fragment -> search_terms\n                for frag in fragments:\n                    if frag not in fragment_to_search_terms:\n                        fragment_to_search_terms[frag] = []\n                    if search_term not in fragment_to_search_terms[frag]:\n                        fragment_to_search_terms[frag].append(search_term)\n\n        logger.info(\n            f\"Loaded drug-indication mapping: {len(search_term_to_fragments)} Search_Terms, \"\n            f\"{len(fragment_to_search_terms)} drug fragments\"\n        )\n\n    except FileNotFoundError:\n        logger.error(f\"DimSearchTerm.csv not found at {csv_path}\")\n    except Exception as e:\n        logger.error(f\"Error loading DimSearchTerm.csv: {e}\")\n\n    return fragment_to_search_terms, search_term_to_fragments\n\n\ndef get_search_terms_for_drug(\n    drug_name: str,\n    search_term_to_fragments: dict[str, list[str]],\n) -> list[str]:\n    \"\"\"\n    Get all Search_Terms that list a given drug using substring matching.\n\n    Checks if any drug fragment from DimSearchTerm is a SUBSTRING of the given\n    drug name (case-insensitive). This handles both exact matches (ADALIMUMAB)\n    and partial fragments (PEGYLATED, INHALED).\n\n    Args:\n        drug_name: HCD drug name (e.g., \"ADALIMUMAB 40MG\", \"PEGYLATED LIPOSOMAL DOXORUBICIN\")\n        search_term_to_fragments: Mapping of search_term -> list of drug fragments\n\n    Returns:\n        List of Search_Terms whose drug fragments match the drug name\n    \"\"\"\n    drug_name_upper = drug_name.upper()\n    matched_terms: list[str] = []\n\n    for search_term, fragments in search_term_to_fragments.items():\n        for frag in fragments:\n            if frag in drug_name_upper:\n                matched_terms.append(search_term)\n                break  # One matching fragment is enough for this Search_Term\n\n    return matched_terms\n\n\n# === NEW APPROACH: Query Snowflake directly using cluster CTE ==="}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":296,"cache_read_input_tokens":107148,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":296},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"fe650f35-0c9b-4891-b7e3-6c3512b2d695"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01BBvWPg9vZnrjPpc1VzRHVa","type":"tool_result","content":"The file C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"bbed3f8a-ec8d-4c3e-a3e7-fd07f78d96f8","tool_use_result":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py","oldString":"# === NEW APPROACH: Query Snowflake directly using cluster CTE ===","newString":"# === Drug-to-indication mapping from DimSearchTerm.csv ===\n\n\ndef load_drug_indication_mapping(\n    csv_path: Optional[str] = None,\n) -> tuple[dict[str, list[str]], dict[str, list[str]]]:\n    \"\"\"\n    Load the drug-to-Search_Term mapping from DimSearchTerm.csv.\n\n    Builds two lookup dicts:\n    - fragment_to_search_terms: drug fragment (UPPERCASE) -> list of Search_Terms containing it\n    - search_term_to_fragments: search_term -> list of drug fragments (UPPERCASE)\n\n    DimSearchTerm.csv has columns: Search_Term, CleanedDrugName, PrimaryDirectorate\n    CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\").\n\n    Note: A Search_Term can appear multiple times with different PrimaryDirectorates\n    (e.g., \"diabetes\" appears under both DIABETIC MEDICINE and OPHTHALMOLOGY).\n    Drug fragments from all rows for the same Search_Term are combined.\n\n    Args:\n        csv_path: Path to DimSearchTerm.csv. Defaults to data/DimSearchTerm.csv.\n\n    Returns:\n        Tuple of (fragment_to_search_terms, search_term_to_fragments)\n    \"\"\"\n    if csv_path is None:\n        csv_path = str(Path(__file__).parent.parent / \"data\" / \"DimSearchTerm.csv\")\n\n    fragment_to_search_terms: dict[str, list[str]] = {}\n    search_term_to_fragments: dict[str, list[str]] = {}\n\n    try:\n        with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                search_term = row.get(\"Search_Term\", \"\").strip()\n                drug_names_raw = row.get(\"CleanedDrugName\", \"\").strip()\n\n                if not search_term or not drug_names_raw:\n                    continue\n\n                fragments = [frag.strip().upper() for frag in drug_names_raw.split(\"|\") if frag.strip()]\n\n                # Build search_term -> fragments (accumulate for duplicate Search_Terms)\n                if search_term not in search_term_to_fragments:\n                    search_term_to_fragments[search_term] = []\n                for frag in fragments:\n                    if frag not in search_term_to_fragments[search_term]:\n                        search_term_to_fragments[search_term].append(frag)\n\n                # Build fragment -> search_terms\n                for frag in fragments:\n                    if frag not in fragment_to_search_terms:\n                        fragment_to_search_terms[frag] = []\n                    if search_term not in fragment_to_search_terms[frag]:\n                        fragment_to_search_terms[frag].append(search_term)\n\n        logger.info(\n            f\"Loaded drug-indication mapping: {len(search_term_to_fragments)} Search_Terms, \"\n            f\"{len(fragment_to_search_terms)} drug fragments\"\n        )\n\n    except FileNotFoundError:\n        logger.error(f\"DimSearchTerm.csv not found at {csv_path}\")\n    except Exception as e:\n        logger.error(f\"Error loading DimSearchTerm.csv: {e}\")\n\n    return fragment_to_search_terms, search_term_to_fragments\n\n\ndef get_search_terms_for_drug(\n    drug_name: str,\n    search_term_to_fragments: dict[str, list[str]],\n) -> list[str]:\n    \"\"\"\n    Get all Search_Terms that list a given drug using substring matching.\n\n    Checks if any drug fragment from DimSearchTerm is a SUBSTRING of the given\n    drug name (case-insensitive). This handles both exact matches (ADALIMUMAB)\n    and partial fragments (PEGYLATED, INHALED).\n\n    Args:\n        drug_name: HCD drug name (e.g., \"ADALIMUMAB 40MG\", \"PEGYLATED LIPOSOMAL DOXORUBICIN\")\n        search_term_to_fragments: Mapping of search_term -> list of drug fragments\n\n    Returns:\n        List of Search_Terms whose drug fragments match the drug name\n    \"\"\"\n    drug_name_upper = drug_name.upper()\n    matched_terms: list[str] = []\n\n    for search_term, fragments in search_term_to_fragments.items():\n        for frag in fragments:\n            if frag in drug_name_upper:\n                matched_terms.append(search_term)\n                break  # One matching fragment is enough for this Search_Term\n\n    return matched_terms\n\n\n# === NEW APPROACH: Query Snowflake directly using cluster CTE ===","originalFile":"\"\"\"\nDiagnosis lookup module for NHS Patient Pathway Analysis.\n\nProvides functions to validate patient indications by checking GP diagnosis records\nagainst SNOMED cluster codes. Uses the drug-to-cluster mapping from\ndrug_indication_clusters.csv and queries Snowflake for SNOMED codes and GP records.\n\nKey workflow:\n1. Get drug's valid indication clusters from local mapping\n2. Get all SNOMED codes for those clusters from Snowflake\n3. Check if patient has any of those SNOMED codes in GP records\n4. Report indication validation status\n\nIMPORTANT: HCD activity data indication codes are UNRELIABLE. This module uses\nGP/Primary Care data (PrimaryCareClinicalCoding) as the authoritative source.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import date, datetime\nfrom pathlib import Path\nfrom typing import Optional, Callable, Any, cast, TYPE_CHECKING\nimport csv\n\nif TYPE_CHECKING:\n    import pandas as pd\n\nfrom core.logging_config import get_logger\nfrom data_processing.database import DatabaseManager, default_db_manager\nfrom data_processing.snowflake_connector import (\n    SnowflakeConnector,\n    get_connector,\n    is_snowflake_available,\n    is_snowflake_configured,\n    SNOWFLAKE_AVAILABLE,\n)\nfrom data_processing.cache import get_cache, is_cache_enabled\n\nlogger = get_logger(__name__)\n\n\n@dataclass\nclass ClusterSnomedCodes:\n    \"\"\"SNOMED codes for a clinical coding cluster.\"\"\"\n    cluster_id: str\n    cluster_description: str\n    snomed_codes: list[str] = field(default_factory=list)\n    snomed_descriptions: dict[str, str] = field(default_factory=dict)\n\n    @property\n    def code_count(self) -> int:\n        return len(self.snomed_codes)\n\n\n@dataclass\nclass IndicationValidationResult:\n    \"\"\"Result of validating a patient's indication for a drug.\"\"\"\n    patient_pseudonym: str\n    drug_name: str\n    has_valid_indication: bool\n    matched_cluster_id: Optional[str] = None\n    matched_snomed_code: Optional[str] = None\n    matched_snomed_description: Optional[str] = None\n    checked_clusters: list[str] = field(default_factory=list)\n    total_codes_checked: int = 0\n    source: str = \"GP_SNOMED\"  # GP_SNOMED | NONE\n    error_message: Optional[str] = None\n\n\n@dataclass\nclass DrugIndicationMatchRate:\n    \"\"\"Match rate statistics for a drug's indication validation.\"\"\"\n    drug_name: str\n    total_patients: int\n    patients_with_indication: int\n    patients_without_indication: int\n    match_rate: float  # 0.0 to 1.0\n    clusters_checked: list[str] = field(default_factory=list)\n    sample_unmatched: list[str] = field(default_factory=list)  # Sample patient IDs\n\n\n@dataclass\nclass DrugSnomedMapping:\n    \"\"\"SNOMED code mapping for a drug from ref_drug_snomed_mapping.\"\"\"\n    snomed_code: str\n    snomed_description: str\n    search_term: str\n    primary_directorate: str\n    indication: str = \"\"\n    ta_id: str = \"\"\n\n\n@dataclass\nclass DirectSnomedMatchResult:\n    \"\"\"Result of direct SNOMED code lookup in GP records.\"\"\"\n    patient_pseudonym: str\n    matched: bool\n    snomed_code: Optional[str] = None\n    snomed_description: Optional[str] = None\n    search_term: Optional[str] = None\n    primary_directorate: Optional[str] = None\n    event_date: Optional[datetime] = None\n    source: str = \"DIRECT_SNOMED\"  # DIRECT_SNOMED | NONE\n\n\n@dataclass\nclass DirectorateAssignment:\n    \"\"\"Result of directorate assignment for a patient-drug combination.\"\"\"\n    upid: str\n    drug_name: str\n    directorate: Optional[str]\n    search_term: Optional[str] = None\n    source: str = \"FALLBACK\"  # DIAGNOSIS | FALLBACK\n    snomed_code: Optional[str] = None\n    event_date: Optional[datetime] = None\n\n\ndef get_drug_clusters(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[dict]:\n    \"\"\"\n    Get all SNOMED cluster mappings for a drug from local SQLite.\n\n    Args:\n        drug_name: Drug name to look up (case-insensitive)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n\n    Returns:\n        List of dicts with keys: drug_name, indication, cluster_id,\n        cluster_description, nice_ta_reference\n    \"\"\"\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    query = \"\"\"\n        SELECT drug_name, indication, cluster_id, cluster_description, nice_ta_reference\n        FROM ref_drug_indication_clusters\n        WHERE UPPER(drug_name) = UPPER(?)\n        ORDER BY indication, cluster_id\n    \"\"\"\n\n    try:\n        with db_manager.get_connection() as conn:\n            cursor = conn.execute(query, (drug_name,))\n            rows = cursor.fetchall()\n\n            results = []\n            for row in rows:\n                results.append({\n                    \"drug_name\": row[\"drug_name\"],\n                    \"indication\": row[\"indication\"],\n                    \"cluster_id\": row[\"cluster_id\"],\n                    \"cluster_description\": row[\"cluster_description\"],\n                    \"nice_ta_reference\": row[\"nice_ta_reference\"],\n                })\n\n            logger.debug(f\"Found {len(results)} cluster mappings for drug '{drug_name}'\")\n            return results\n\n    except Exception as e:\n        logger.error(f\"Error getting clusters for drug '{drug_name}': {e}\")\n        return []\n\n\ndef get_drug_cluster_ids(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[str]:\n    \"\"\"\n    Get unique cluster IDs for a drug.\n\n    Args:\n        drug_name: Drug name to look up\n        db_manager: Optional DatabaseManager\n\n    Returns:\n        List of unique cluster IDs\n    \"\"\"\n    clusters = get_drug_clusters(drug_name, db_manager)\n    return list(set(c[\"cluster_id\"] for c in clusters))\n\n\ndef get_drug_snomed_codes(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[DrugSnomedMapping]:\n    \"\"\"\n    Get all SNOMED codes for a drug from local ref_drug_snomed_mapping table.\n\n    This uses the enriched mapping CSV data loaded into SQLite, which provides\n    direct SNOMED-to-drug mappings with Search_Term and PrimaryDirectorate.\n\n    Args:\n        drug_name: Drug name to look up (case-insensitive, matches cleaned_drug_name)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n\n    Returns:\n        List of DrugSnomedMapping with snomed_code, snomed_description,\n        search_term, primary_directorate, indication, ta_id\n    \"\"\"\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    query = \"\"\"\n        SELECT DISTINCT\n            snomed_code,\n            snomed_description,\n            search_term,\n            primary_directorate,\n            indication,\n            ta_id\n        FROM ref_drug_snomed_mapping\n        WHERE UPPER(cleaned_drug_name) = UPPER(?)\n           OR UPPER(drug_name) = UPPER(?)\n        ORDER BY search_term, snomed_code\n    \"\"\"\n\n    try:\n        with db_manager.get_connection() as conn:\n            cursor = conn.execute(query, (drug_name, drug_name))\n            rows = cursor.fetchall()\n\n            results = []\n            for row in rows:\n                results.append(DrugSnomedMapping(\n                    snomed_code=row[\"snomed_code\"],\n                    snomed_description=row[\"snomed_description\"] or \"\",\n                    search_term=row[\"search_term\"] or \"\",\n                    primary_directorate=row[\"primary_directorate\"] or \"\",\n                    indication=row[\"indication\"] or \"\",\n                    ta_id=row[\"ta_id\"] or \"\",\n                ))\n\n            logger.debug(f\"Found {len(results)} SNOMED mappings for drug '{drug_name}'\")\n            return results\n\n    except Exception as e:\n        logger.error(f\"Error getting SNOMED codes for drug '{drug_name}': {e}\")\n        return []\n\n\ndef patient_has_indication_direct(\n    patient_pseudonym: str,\n    drug_snomed_mappings: list[DrugSnomedMapping],\n    connector: Optional[SnowflakeConnector] = None,\n    before_date: Optional[date] = None,\n) -> DirectSnomedMatchResult:\n    \"\"\"\n    Check if patient has any of the SNOMED codes in their GP records.\n\n    This is the direct SNOMED lookup - it queries PrimaryCareClinicalCoding\n    for exact SNOMED code matches (not via cluster). Returns the most recent\n    match by EventDateTime if multiple matches exist.\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        drug_snomed_mappings: List of DrugSnomedMapping from get_drug_snomed_codes()\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        DirectSnomedMatchResult with match details (most recent by EventDateTime)\n    \"\"\"\n    result = DirectSnomedMatchResult(\n        patient_pseudonym=patient_pseudonym,\n        matched=False,\n        source=\"NONE\",\n    )\n\n    if not drug_snomed_mappings:\n        return result\n\n    if not SNOWFLAKE_AVAILABLE:\n        logger.warning(\"Snowflake connector not available\")\n        return result\n\n    if not is_snowflake_configured():\n        logger.warning(\"Snowflake not configured - cannot check GP records\")\n        return result\n\n    if connector is None:\n        connector = get_connector()\n\n    # Build lookup dict for mapping snomed_code -> (search_term, primary_directorate, snomed_description)\n    snomed_lookup = {\n        m.snomed_code: (m.search_term, m.primary_directorate, m.snomed_description)\n        for m in drug_snomed_mappings\n    }\n\n    # Get unique SNOMED codes\n    snomed_codes = list(snomed_lookup.keys())\n\n    # Build placeholders for SNOMED codes\n    placeholders = \", \".join([\"%s\"] * len(snomed_codes))\n\n    # Query to find most recent matching SNOMED code in GP records\n    query = f'''\n        SELECT\n            \"SNOMEDCode\",\n            \"EventDateTime\"\n        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n        WHERE \"PatientPseudonym\" = %s\n            AND \"SNOMEDCode\" IN ({placeholders})\n    '''\n\n    params: list = [patient_pseudonym] + snomed_codes\n\n    if before_date:\n        query += ' AND \"EventDateTime\" < %s'\n        params.append(before_date.isoformat())\n\n    query += ' ORDER BY \"EventDateTime\" DESC LIMIT 1'\n\n    try:\n        results = connector.execute_dict(query, tuple(params))\n\n        if results:\n            row = results[0]\n            matched_code = row.get(\"SNOMEDCode\")\n            event_dt = row.get(\"EventDateTime\")\n\n            if matched_code and matched_code in snomed_lookup:\n                search_term, primary_dir, snomed_desc = snomed_lookup[matched_code]\n\n                return DirectSnomedMatchResult(\n                    patient_pseudonym=patient_pseudonym,\n                    matched=True,\n                    snomed_code=matched_code,\n                    snomed_description=snomed_desc,\n                    search_term=search_term,\n                    primary_directorate=primary_dir,\n                    event_date=event_dt,\n                    source=\"DIRECT_SNOMED\",\n                )\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"Error checking direct SNOMED for patient '{patient_pseudonym}': {e}\")\n        return result\n\n\ndef get_directorate_from_diagnosis(\n    upid: str,\n    drug_name: str,\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    before_date: Optional[date] = None,\n) -> DirectorateAssignment:\n    \"\"\"\n    Get directorate assignment for a patient-drug combination using diagnosis-based lookup.\n\n    This function attempts to assign a directorate based on the patient's GP records\n    (direct SNOMED code matching). If no match is found, it returns a FALLBACK result\n    indicating that the caller should use alternative assignment methods (e.g.,\n    department_identification() from tools/data.py).\n\n    Workflow:\n    1. Get all SNOMED codes for the drug from ref_drug_snomed_mapping\n    2. Query patient's GP records for matching SNOMED codes\n    3. If match found ÔåÆ return diagnosis-based directorate and search_term\n    4. If no match ÔåÆ return FALLBACK result (caller handles fallback logic)\n\n    Args:\n        upid: Patient's unique patient ID (Provider Code[:3] + PersonKey)\n        drug_name: Drug name to look up\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        DirectorateAssignment with directorate, search_term, and source\n    \"\"\"\n    result = DirectorateAssignment(\n        upid=upid,\n        drug_name=drug_name,\n        directorate=None,\n        source=\"FALLBACK\",\n    )\n\n    # Step 1: Get SNOMED codes for the drug\n    drug_snomed_mappings = get_drug_snomed_codes(drug_name, db_manager)\n\n    if not drug_snomed_mappings:\n        logger.debug(f\"No SNOMED mappings found for drug '{drug_name}' - using fallback\")\n        return result\n\n    # Step 2: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        logger.debug(\"Snowflake not available - using fallback\")\n        return result\n\n    if not is_snowflake_configured():\n        logger.debug(\"Snowflake not configured - using fallback\")\n        return result\n\n    # Step 3: Get patient pseudonym from UPID\n    # UPID format is Provider Code (3 chars) + PersonKey\n    # We need to query Snowflake to get the PatientPseudonym for this PersonKey\n    # However, patient_has_indication_direct expects PatientPseudonym, not UPID\n    # For now, we'll use UPID as the identifier - the actual integration\n    # will need to happen at the DataFrame level where we have PersonKey\n    #\n    # NOTE: This function will be called from the pipeline where we have\n    # access to PatientPseudonym. The UPID is passed for logging/tracking.\n\n    # Actually, looking at the pipeline, we need PatientPseudonym, not UPID.\n    # The caller should pass the PatientPseudonym or we need to look it up.\n    # For now, let's assume the caller will use this in a batch context\n    # where they can map UPID -> PatientPseudonym.\n\n    # Let me reconsider: the function signature takes UPID but we need\n    # PatientPseudonym for Snowflake. In the pipeline context (fetch_and_transform_data),\n    # we'll have the PersonKey column which IS the PatientPseudonym.\n    # So UPID = ProviderCode[:3] + PersonKey, and PersonKey = PatientPseudonym.\n    #\n    # We can extract PatientPseudonym from UPID by removing the first 3 chars.\n    patient_pseudonym = upid[3:] if len(upid) > 3 else upid\n\n    # Step 4: Check patient's GP records for matching SNOMED codes\n    match_result = patient_has_indication_direct(\n        patient_pseudonym=patient_pseudonym,\n        drug_snomed_mappings=drug_snomed_mappings,\n        connector=connector,\n        before_date=before_date,\n    )\n\n    if match_result.matched and match_result.primary_directorate:\n        return DirectorateAssignment(\n            upid=upid,\n            drug_name=drug_name,\n            directorate=match_result.primary_directorate,\n            search_term=match_result.search_term,\n            source=\"DIAGNOSIS\",\n            snomed_code=match_result.snomed_code,\n            event_date=match_result.event_date,\n        )\n\n    # No match found - return fallback result\n    return result\n\n\ndef get_cluster_snomed_codes(\n    cluster_id: str,\n    connector: Optional[SnowflakeConnector] = None,\n    use_cache: bool = True,\n) -> ClusterSnomedCodes:\n    \"\"\"\n    Get all SNOMED codes for a cluster from Snowflake.\n\n    Queries the ClinicalCodingClusterSnomedCodes table to get all SNOMED codes\n    that belong to the specified cluster.\n\n    Args:\n        cluster_id: Cluster ID to look up (e.g., 'RARTH_COD', 'PSORIASIS_COD')\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        use_cache: Whether to use cached results (default True)\n\n    Returns:\n        ClusterSnomedCodes with list of SNOMED codes and descriptions\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE:\n        logger.warning(\"Snowflake connector not available\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n    if not is_snowflake_configured():\n        logger.warning(\"Snowflake not configured - cannot get cluster codes\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n    # Check cache first\n    cache_key = f\"cluster_snomed_{cluster_id}\"\n    if use_cache and is_cache_enabled():\n        cache = get_cache()\n        cached = cache.get(cache_key)\n        if cached is not None and len(cached) > 0:\n            logger.debug(f\"Using cached SNOMED codes for cluster '{cluster_id}'\")\n            cached_dict = cached[0]  # First element is our data dict\n            return ClusterSnomedCodes(\n                cluster_id=cluster_id,\n                cluster_description=str(cached_dict.get(\"description\", \"\")),\n                snomed_codes=list(cached_dict.get(\"codes\", [])),\n                snomed_descriptions=dict(cached_dict.get(\"descriptions\", {})),\n            )\n\n    if connector is None:\n        connector = get_connector()\n\n    query = '''\n        SELECT DISTINCT\n            \"Cluster_ID\",\n            \"Cluster_Description\",\n            \"SNOMEDCode\",\n            \"SNOMEDDescription\"\n        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n        WHERE \"Cluster_ID\" = %s\n        ORDER BY \"SNOMEDCode\"\n    '''\n\n    try:\n        results = connector.execute_dict(query, (cluster_id,))\n\n        if not results:\n            logger.warning(f\"No SNOMED codes found for cluster '{cluster_id}'\")\n            return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n        codes = []\n        descriptions = {}\n        description = results[0].get(\"Cluster_Description\", \"\") if results else \"\"\n\n        for row in results:\n            code = row.get(\"SNOMEDCode\")\n            if code:\n                codes.append(code)\n                descriptions[code] = row.get(\"SNOMEDDescription\", \"\")\n\n        logger.info(f\"Found {len(codes)} SNOMED codes for cluster '{cluster_id}'\")\n\n        # Cache the results (using query-based cache with fake params)\n        if use_cache and is_cache_enabled():\n            cache = get_cache()\n            cache_data = [{\n                \"description\": description,\n                \"codes\": codes,\n                \"descriptions\": descriptions,\n            }]\n            cache.set(cache_key, None, cache_data)  # type: ignore[arg-type]\n\n        return ClusterSnomedCodes(\n            cluster_id=cluster_id,\n            cluster_description=description,\n            snomed_codes=codes,\n            snomed_descriptions=descriptions,\n        )\n\n    except Exception as e:\n        logger.error(f\"Error getting SNOMED codes for cluster '{cluster_id}': {e}\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n\ndef patient_has_indication(\n    patient_pseudonym: str,\n    cluster_ids: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    before_date: Optional[date] = None,\n) -> tuple[bool, Optional[str], Optional[str], Optional[str]]:\n    \"\"\"\n    Check if a patient has any SNOMED codes from the specified clusters in GP records.\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        cluster_ids: List of cluster IDs to check against\n        connector: Optional SnowflakeConnector\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        Tuple of (has_indication, matched_cluster_id, matched_snomed_code, matched_description)\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        return False, None, None, None\n\n    if not cluster_ids:\n        return False, None, None, None\n\n    if connector is None:\n        connector = get_connector()\n\n    # Build placeholders for cluster IDs\n    placeholders = \", \".join([\"%s\"] * len(cluster_ids))\n\n    # Query to check if patient has any matching SNOMED code\n    query = f'''\n        SELECT\n            pc.\"SNOMEDCode\",\n            cc.\"Cluster_ID\",\n            cc.\"SNOMEDDescription\"\n        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\n        INNER JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" cc\n            ON pc.\"SNOMEDCode\" = cc.\"SNOMEDCode\"\n        WHERE pc.\"PatientPseudonym\" = %s\n            AND cc.\"Cluster_ID\" IN ({placeholders})\n    '''\n\n    params = [patient_pseudonym] + cluster_ids\n\n    if before_date:\n        query += ' AND pc.\"EventDateTime\" < %s'\n        params.append(before_date.isoformat())\n\n    query += ' LIMIT 1'\n\n    try:\n        results = connector.execute_dict(query, tuple(params))\n\n        if results:\n            row = results[0]\n            return (\n                True,\n                row.get(\"Cluster_ID\"),\n                row.get(\"SNOMEDCode\"),\n                row.get(\"SNOMEDDescription\"),\n            )\n\n        return False, None, None, None\n\n    except Exception as e:\n        logger.error(f\"Error checking indication for patient '{patient_pseudonym}': {e}\")\n        return False, None, None, None\n\n\ndef validate_indication(\n    patient_pseudonym: str,\n    drug_name: str,\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    before_date: Optional[date] = None,\n) -> IndicationValidationResult:\n    \"\"\"\n    Validate that a patient has an appropriate indication for a drug.\n\n    Full validation workflow:\n    1. Get drug's valid indication clusters from local mapping\n    2. Check if patient has any matching SNOMED codes in GP records\n    3. Return detailed validation result\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        drug_name: Drug name to validate indication for\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        IndicationValidationResult with validation details\n    \"\"\"\n    result = IndicationValidationResult(\n        patient_pseudonym=patient_pseudonym,\n        drug_name=drug_name,\n        has_valid_indication=False,\n    )\n\n    # Step 1: Get drug's cluster mappings\n    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n\n    if not cluster_ids:\n        result.error_message = f\"No cluster mappings found for drug '{drug_name}'\"\n        result.source = \"NONE\"\n        return result\n\n    result.checked_clusters = cluster_ids\n\n    # Step 2: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        result.error_message = \"Snowflake connector not installed\"\n        result.source = \"NONE\"\n        return result\n\n    if not is_snowflake_configured():\n        result.error_message = \"Snowflake not configured\"\n        result.source = \"NONE\"\n        return result\n\n    # Step 3: Check patient GP records\n    has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n        patient_pseudonym=patient_pseudonym,\n        cluster_ids=cluster_ids,\n        connector=connector,\n        before_date=before_date,\n    )\n\n    result.has_valid_indication = has_indication\n    result.matched_cluster_id = matched_cluster\n    result.matched_snomed_code = matched_code\n    result.matched_snomed_description = matched_desc\n    result.source = \"GP_SNOMED\" if has_indication else \"NONE\"\n\n    return result\n\n\ndef get_indication_match_rate(\n    drug_name: str,\n    patient_pseudonyms: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    sample_unmatched_count: int = 10,\n) -> DrugIndicationMatchRate:\n    \"\"\"\n    Calculate indication match rate for a drug across a list of patients.\n\n    Args:\n        drug_name: Drug name to check\n        patient_pseudonyms: List of patient pseudonymised NHS numbers\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        sample_unmatched_count: Number of unmatched patient IDs to include in sample\n\n    Returns:\n        DrugIndicationMatchRate with match statistics\n    \"\"\"\n    if connector is None and SNOWFLAKE_AVAILABLE and is_snowflake_configured():\n        connector = get_connector()\n\n    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n\n    total = len(patient_pseudonyms)\n    matched = 0\n    unmatched = 0\n    sample_unmatched: list[str] = []\n\n    if not cluster_ids:\n        logger.warning(f\"No cluster mappings for drug '{drug_name}' - all patients will be unmatched\")\n        return DrugIndicationMatchRate(\n            drug_name=drug_name,\n            total_patients=total,\n            patients_with_indication=0,\n            patients_without_indication=total,\n            match_rate=0.0,\n            clusters_checked=[],\n            sample_unmatched=patient_pseudonyms[:sample_unmatched_count],\n        )\n\n    for i, pseudonym in enumerate(patient_pseudonyms):\n        if i > 0 and i % 100 == 0:\n            logger.info(f\"Validating indications: {i}/{total} ({100*i/total:.1f}%)\")\n\n        has_indication, _, _, _ = patient_has_indication(\n            patient_pseudonym=pseudonym,\n            cluster_ids=cluster_ids,\n            connector=connector,\n        )\n\n        if has_indication:\n            matched += 1\n        else:\n            unmatched += 1\n            if len(sample_unmatched) < sample_unmatched_count:\n                sample_unmatched.append(pseudonym)\n\n    match_rate = matched / total if total > 0 else 0.0\n\n    logger.info(f\"Indication match rate for '{drug_name}': {100*match_rate:.1f}% ({matched}/{total})\")\n\n    return DrugIndicationMatchRate(\n        drug_name=drug_name,\n        total_patients=total,\n        patients_with_indication=matched,\n        patients_without_indication=unmatched,\n        match_rate=match_rate,\n        clusters_checked=cluster_ids,\n        sample_unmatched=sample_unmatched,\n    )\n\n\ndef batch_validate_indications(\n    patient_drug_pairs: list[tuple[str, str]],\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    progress_callback: Optional[Callable[[int, int], None]] = None,\n) -> list[IndicationValidationResult]:\n    \"\"\"\n    Validate indications for multiple patient-drug pairs efficiently.\n\n    Args:\n        patient_drug_pairs: List of (patient_pseudonym, drug_name) tuples\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        progress_callback: Optional callback(current, total) for progress updates\n\n    Returns:\n        List of IndicationValidationResult for each pair\n    \"\"\"\n    results = []\n    total = len(patient_drug_pairs)\n\n    # Cache cluster lookups by drug\n    drug_clusters_cache = {}\n\n    for i, (pseudonym, drug_name) in enumerate(patient_drug_pairs):\n        if progress_callback:\n            progress_callback(i + 1, total)\n\n        # Get clusters from cache or lookup\n        drug_upper = drug_name.upper()\n        if drug_upper not in drug_clusters_cache:\n            drug_clusters_cache[drug_upper] = get_drug_cluster_ids(drug_name, db_manager)\n\n        cluster_ids = drug_clusters_cache[drug_upper]\n\n        if not cluster_ids:\n            results.append(IndicationValidationResult(\n                patient_pseudonym=pseudonym,\n                drug_name=drug_name,\n                has_valid_indication=False,\n                source=\"NONE\",\n                error_message=f\"No cluster mappings for drug '{drug_name}'\",\n            ))\n            continue\n\n        # Check patient indication\n        has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n            patient_pseudonym=pseudonym,\n            cluster_ids=cluster_ids,\n            connector=connector,\n        )\n\n        results.append(IndicationValidationResult(\n            patient_pseudonym=pseudonym,\n            drug_name=drug_name,\n            has_valid_indication=has_indication,\n            matched_cluster_id=matched_cluster,\n            matched_snomed_code=matched_code,\n            matched_snomed_description=matched_desc,\n            checked_clusters=cluster_ids,\n            source=\"GP_SNOMED\" if has_indication else \"NONE\",\n        ))\n\n    matched_count = sum(1 for r in results if r.has_valid_indication)\n    logger.info(f\"Batch validation complete: {matched_count}/{total} ({100*matched_count/total:.1f}%) with valid indications\")\n\n    return results\n\n\ndef get_available_clusters(\n    connector: Optional[SnowflakeConnector] = None,\n) -> list[dict]:\n    \"\"\"\n    Get list of all available SNOMED clusters from Snowflake.\n\n    Returns:\n        List of dicts with cluster_id, cluster_description, code_count\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        logger.warning(\"Snowflake not available - cannot list clusters\")\n        return []\n\n    if connector is None:\n        connector = get_connector()\n\n    query = '''\n        SELECT\n            \"Cluster_ID\",\n            \"Cluster_Description\",\n            COUNT(DISTINCT \"SNOMEDCode\") as code_count\n        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n        GROUP BY \"Cluster_ID\", \"Cluster_Description\"\n        ORDER BY \"Cluster_ID\"\n    '''\n\n    try:\n        results = connector.execute_dict(query)\n\n        clusters = []\n        for row in results:\n            clusters.append({\n                \"cluster_id\": row.get(\"Cluster_ID\"),\n                \"cluster_description\": row.get(\"Cluster_Description\"),\n                \"code_count\": row.get(\"code_count\", 0),\n            })\n\n        logger.info(f\"Found {len(clusters)} available SNOMED clusters\")\n        return clusters\n\n    except Exception as e:\n        logger.error(f\"Error getting available clusters: {e}\")\n        return []\n\n\ndef batch_lookup_indication_groups(\n    df: \"pd.DataFrame\",\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    batch_size: int = 500,\n) -> \"pd.DataFrame\":\n    \"\"\"\n    Batch lookup GP diagnosis-based indication groups for a DataFrame of patients.\n\n    This is the efficient batch version of get_directorate_from_diagnosis().\n    Instead of querying Snowflake per patient, it batches the lookups for performance.\n\n    Strategy:\n    1. Get all unique (PersonKey, Drug Name) pairs from DataFrame\n    2. For each unique drug, get all SNOMED codes from local SQLite\n    3. Build batched Snowflake queries to check GP records\n    4. Return indication_df mapping UPID ÔåÆ Indication_Group\n\n    For unmatched patients, Indication_Group will be their Directory (with suffix).\n\n    Args:\n        df: DataFrame with columns: UPID, Drug Name, Directory, PersonKey\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n        batch_size: Number of patients per Snowflake query batch\n\n    Returns:\n        DataFrame with columns: UPID, Indication_Group, Source\n        - Indication_Group: Search_Term (if matched) or \"Directory (no GP dx)\" (if not)\n        - Source: \"DIAGNOSIS\" or \"FALLBACK\"\n    \"\"\"\n    import pandas as pd\n\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    logger.info(f\"Starting batch indication lookup for {len(df)} records...\")\n\n    # Step 1: Get unique (UPID, Drug Name, PseudoNHSNoLinked, Directory) combinations\n    # We need PseudoNHSNoLinked to query Snowflake - this matches PatientPseudonym in GP records\n    # Note: PersonKey is LocalPatientID which is provider-specific and does NOT match GP records\n    if 'PseudoNHSNoLinked' not in df.columns:\n        logger.error(\"DataFrame missing 'PseudoNHSNoLinked' column - cannot lookup GP records\")\n        # Return fallback for all patients\n        result_df = df[['UPID', 'Directory']].drop_duplicates().copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']]\n\n    # Get unique patient-drug combinations (we need one lookup per patient-drug pair)\n    unique_pairs = df[['UPID', 'Drug Name', 'PseudoNHSNoLinked', 'Directory']].drop_duplicates()\n    logger.info(f\"Found {len(unique_pairs)} unique patient-drug combinations\")\n\n    # Step 2: Get all unique drugs and their SNOMED codes\n    unique_drugs = unique_pairs['Drug Name'].unique()\n    logger.info(f\"Building SNOMED lookup for {len(unique_drugs)} unique drugs...\")\n\n    # Build drug -> list of DrugSnomedMapping dict\n    drug_snomed_map: dict[str, list[DrugSnomedMapping]] = {}\n    all_snomed_codes: set[str] = set()\n    snomed_to_drug_searchterm: dict[str, list[tuple[str, str, str]]] = {}  # snomed -> [(drug, search_term, primary_dir), ...]\n\n    for drug_name in unique_drugs:\n        mappings = get_drug_snomed_codes(drug_name, db_manager)\n        drug_snomed_map[drug_name] = mappings\n\n        for m in mappings:\n            all_snomed_codes.add(m.snomed_code)\n            if m.snomed_code not in snomed_to_drug_searchterm:\n                snomed_to_drug_searchterm[m.snomed_code] = []\n            snomed_to_drug_searchterm[m.snomed_code].append(\n                (drug_name, m.search_term, m.primary_directorate)\n            )\n\n    logger.info(f\"Total SNOMED codes to check: {len(all_snomed_codes)}\")\n\n    # Step 3: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        logger.warning(\"Snowflake not available - returning fallback for all patients\")\n        result_df = unique_pairs[['UPID', 'Directory']].copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n\n    if connector is None:\n        connector = get_connector()\n\n    # Step 4: Query GP records for all patients in batches\n    # The query finds the most recent matching SNOMED code for each patient\n\n    # Get unique PseudoNHSNoLinked values (each = one patient in GP records)\n    unique_patients = unique_pairs[['PseudoNHSNoLinked', 'UPID', 'Directory']].drop_duplicates(subset=['PseudoNHSNoLinked'])\n    patient_pseudonyms = unique_patients['PseudoNHSNoLinked'].tolist()\n\n    logger.info(f\"Querying GP records for {len(patient_pseudonyms)} unique patients in batches of {batch_size}...\")\n\n    # Results dict: PersonKey -> (snomed_code, event_date)\n    gp_matches: dict[str, tuple[str, Any]] = {}\n\n    # Convert SNOMED codes to list for query\n    snomed_list = list(all_snomed_codes)\n\n    if not snomed_list:\n        logger.warning(\"No SNOMED codes to check - returning fallback for all patients\")\n        result_df = unique_pairs[['UPID', 'Directory']].copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n\n    # Build SNOMED IN clause (reused across batches)\n    snomed_placeholders = \", \".join([\"%s\"] * len(snomed_list))\n\n    # Process patients in batches\n    for batch_start in range(0, len(patient_pseudonyms), batch_size):\n        batch_end = min(batch_start + batch_size, len(patient_pseudonyms))\n        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n\n        logger.info(f\"Batch {batch_start//batch_size + 1}: patients {batch_start} to {batch_end}\")\n\n        # Build patient IN clause\n        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n\n        # Query to find all matching SNOMED codes for these patients\n        # We'll get all matches and pick the most recent per patient in Python\n        query = f'''\n            SELECT\n                \"PatientPseudonym\",\n                \"SNOMEDCode\",\n                \"EventDateTime\"\n            FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n            WHERE \"PatientPseudonym\" IN ({patient_placeholders})\n              AND \"SNOMEDCode\" IN ({snomed_placeholders})\n            ORDER BY \"PatientPseudonym\", \"EventDateTime\" DESC\n        '''\n\n        params = tuple(batch_pseudonyms) + tuple(snomed_list)\n\n        try:\n            results = connector.execute_dict(query, params)\n\n            # Process results - pick most recent per patient\n            for row in results:\n                person_key = row.get(\"PatientPseudonym\")\n                snomed_code = row.get(\"SNOMEDCode\")\n                event_date = row.get(\"EventDateTime\")\n\n                if person_key and snomed_code:\n                    # Keep only if we haven't seen this patient yet (first = most recent due to ORDER BY)\n                    if person_key not in gp_matches:\n                        gp_matches[person_key] = (snomed_code, event_date)\n\n        except Exception as e:\n            logger.error(f\"Error querying GP records for batch: {e}\")\n            # Continue with other batches\n\n    logger.info(f\"Found GP matches for {len(gp_matches)} patients\")\n\n    # Step 5: Build result DataFrame\n    # For each unique_pair, determine Indication_Group based on match status\n    results_list = []\n\n    # We need to dedupe by UPID - a patient might be on multiple drugs\n    # Strategy: For each UPID, use the most recent match (if any)\n    upid_to_match: dict[str, tuple[str, str]] = {}  # UPID -> (Indication_Group, Source)\n\n    for _, row in unique_pairs.iterrows():\n        upid = row['UPID']\n        drug_name = row['Drug Name']\n        patient_pseudonym = row['PseudoNHSNoLinked']\n        directory = row['Directory']\n\n        # Check if patient has GP match (using PseudoNHSNoLinked which matches PatientPseudonym in GP)\n        if patient_pseudonym in gp_matches:\n            matched_snomed, event_date = gp_matches[patient_pseudonym]\n\n            # Find the search_term for this SNOMED code and drug\n            # (A SNOMED code might map to multiple drugs with different search_terms)\n            if matched_snomed in snomed_to_drug_searchterm:\n                # Look for match with current drug first\n                search_term = None\n                for drug, st, pd in snomed_to_drug_searchterm[matched_snomed]:\n                    if drug.upper() == drug_name.upper():\n                        search_term = st\n                        break\n                # If no drug-specific match, use any match\n                if search_term is None:\n                    search_term = snomed_to_drug_searchterm[matched_snomed][0][1]\n\n                # Only update if we don't have a match for this UPID yet\n                if upid not in upid_to_match:\n                    upid_to_match[upid] = (search_term, \"DIAGNOSIS\")\n            else:\n                # Shouldn't happen but fallback just in case\n                if upid not in upid_to_match:\n                    upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n        else:\n            # No GP match - use fallback\n            if upid not in upid_to_match:\n                upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n\n    # Build result DataFrame\n    for upid, (indication_group, source) in upid_to_match.items():\n        results_list.append({\n            'UPID': upid,\n            'Indication_Group': indication_group,\n            'Source': source,\n        })\n\n    result_df = pd.DataFrame(results_list)\n\n    # Log statistics\n    diagnosis_count = len([s for s in result_df['Source'] if s == \"DIAGNOSIS\"])\n    fallback_count = len([s for s in result_df['Source'] if s == \"FALLBACK\"])\n    total = len(result_df)\n\n    logger.info(f\"Indication lookup complete:\")\n    logger.info(f\"  Total unique patients: {total}\")\n    logger.info(f\"  DIAGNOSIS matches: {diagnosis_count} ({100*diagnosis_count/total:.1f}%)\")\n    logger.info(f\"  FALLBACK (no GP match): {fallback_count} ({100*fallback_count/total:.1f}%)\")\n\n    return result_df\n\n\n# === NEW APPROACH: Query Snowflake directly using cluster CTE ===\n\n# The cluster query mapping (embedded from snomed_indication_mapping_query.sql)\n# This maps Search_Term -> Cluster_ID for ~148 clinical conditions\nCLUSTER_MAPPING_SQL = \"\"\"\nWITH SearchTermClusters AS (\n    SELECT Search_Term, Cluster_ID FROM (VALUES\n        ('acute lymphoblastic leukaemia', 'HAEMCANMORPH_COD'),\n        ('acute myeloid leukaemia', 'C19HAEMCAN_COD'),\n        ('acute promyelocytic leukaemia', 'HAEMCANMORPH_COD'),\n        ('allergic asthma', 'AST_COD'),\n        ('allergic rhinitis', 'MILDINTAST_COD'),\n        ('alzheimer''s disease', 'DEMALZ_COD'),\n        ('amyloidosis', 'AMYLOID_COD'),\n        ('anaemia', 'eFI2_AnaemiaTimeSensitive'),\n        ('anaplastic large cell lymphoma', 'C19HAEMCAN_COD'),\n        ('apixaban', 'DOACCON_COD'),\n        ('aplastic anaemia', 'eFI2_AnaemiaEver'),\n        ('arthritis', 'eFI2_InflammatoryArthritis'),\n        ('asthma', 'eFI2_Asthma'),\n        ('atopic dermatitis', 'ATOPDERM_COD'),\n        ('atrial fibrillation', 'eFI2_AtrialFibrillation'),\n        ('attention deficit hyperactivity disorder', 'ADHD_COD'),\n        ('bipolar disorder', 'MH_COD'),\n        ('bladder', 'eFI2_UrinaryIncontinence'),\n        ('breast cancer', 'BRCANSCR_COD'),\n        ('cardiomyopathy', 'eFI2_HarmfulDrinking'),\n        ('cardiovascular disease', 'CVDRISKASS_COD'),\n        ('cervical cancer', 'CSDEC_COD'),\n        ('cholangiocarcinoma', 'eFI2_Cancer'),\n        ('chronic kidney disease', 'CKD_COD'),\n        ('chronic liver disease', 'eFI2_LiverProblems'),\n        ('chronic lymphocytic leukaemia', 'EPPHAEMCAN_COD'),\n        ('chronic myeloid leukaemia', 'EPPHAEMCAN_COD'),\n        ('chronic obstructive pulmonary disease', 'eFI2_COPD'),\n        ('colon cancer', 'eFI2_Cancer'),\n        ('colorectal cancer', 'GICANREF_COD'),\n        ('constipation', 'CHRONCONSTIP_COD'),\n        ('covid-19', 'POSSPOSTCOVID_COD'),\n        ('crohn''s disease', 'eFI2_InflammatoryBowelDisease'),\n        ('cutaneous t-cell lymphoma', 'C19HAEMCAN_COD'),\n        ('cystic fibrosis', 'CUST_ICB_CYSTIC_FIBROSIS'),\n        ('deep vein thrombosis', 'VTE_COD'),\n        ('depression', 'eFI2_Depression'),\n        ('diabetes', 'eFI2_DiabetesEver'),\n        ('diabetic retinopathy', 'DRSELIGIBILITY_COD'),\n        ('diffuse large b-cell lymphoma', 'C19HAEMCAN_COD'),\n        ('dravet syndrome', 'EPIL_COD'),\n        ('drug misuse', 'ILLSUBINT_COD'),\n        ('dyspepsia', 'eFI2_AbdominalPain'),\n        ('epilepsy', 'eFI2_Seizures'),\n        ('fallopian tube', 'STERIL_COD'),\n        ('follicular lymphoma', 'C19HAEMCAN_COD'),\n        ('gastric cancer', 'eFI2_Cancer'),\n        ('giant cell arteritis', 'GCA_COD'),\n        ('glioma', 'NHAEMCANMORPH_COD'),\n        ('gout', 'eFI2_InflammatoryArthritis'),\n        ('graft versus host disease', 'GVHD_COD'),\n        ('granulomatosis with polyangiitis', 'WEGENERVASC_COD'),\n        ('growth hormone deficiency', 'HYPOPITUITARY_COD'),\n        ('hand eczema', 'ECZEMA_COD'),\n        ('heart failure', 'eFI2_HeartFailure'),\n        ('hepatitis b', 'HEPBCVAC_COD'),\n        ('hepatocellular carcinoma', 'eFI2_Cancer'),\n        ('hiv', 'PREFLANG_COD'),\n        ('hodgkin lymphoma', 'HAEMCANMORPH_COD'),\n        ('hormone receptor', 'eFI2_ThyroidProblems'),\n        ('hypercholesterolaemia', 'CLASSFH_COD'),\n        ('immune thrombocytopenia', 'ITP_COD'),\n        ('influenza', 'FLUINVITE_COD'),\n        ('insomnia', 'eFI2_SleepProblems'),\n        ('irritable bowel syndrome', 'IBS_COD'),\n        ('ischaemic stroke', 'OSTR_COD'),\n        ('juvenile idiopathic arthritis', 'RARTHAD_COD'),\n        ('kidney transplant', 'RENALTRANSP_COD'),\n        ('leukaemia', 'eFI2_Cancer'),\n        ('lung cancer', 'FTCANREF_COD'),\n        ('lymphoma', 'C19HAEMCAN_COD'),\n        ('macular degeneration', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('macular oedema', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('major depressive episodes', 'eFI2_Depression'),\n        ('malignant melanoma', 'eFI2_Cancer'),\n        ('malignant pleural mesothelioma', 'LUNGCAN_COD'),\n        ('manic episode', 'MH_COD'),\n        ('mantle cell lymphoma', 'HAEMCANMORPH_COD'),\n        ('melanoma', 'eFI2_Cancer'),\n        ('merkel cell carcinoma', 'C19CAN_COD'),\n        ('migraine', 'eFI2_Headache'),\n        ('motor neurone disease', 'MND_COD'),\n        ('multiple myeloma', 'C19HAEMCAN_COD'),\n        ('multiple sclerosis', 'MS_COD'),\n        ('myelodysplastic', 'eFI2_AnaemiaEver'),\n        ('myelofibrosis', 'MDS_COD'),\n        ('myocardial infarction', 'eFI2_IschaemicHeartDisease'),\n        ('myotonia', 'CNDATRISK2_COD'),\n        ('narcolepsy', 'LD_COD'),\n        ('neuroendocrine tumour', 'LUNGCAN_COD'),\n        ('non-small cell lung cancer', 'LUNGCAN_COD'),\n        ('non-small-cell lung cancer', 'FTCANREF_COD'),\n        ('obesity', 'BMI30_COD'),\n        ('osteoarthritis', 'CUST_ICB_OSTEOARTHRITIS'),\n        ('osteoporosis', 'eFI2_Osteoporosis'),\n        ('osteosarcoma', 'NHAEMCANMORPH_COD'),\n        ('ovarian cancer', 'C19CAN_COD'),\n        ('peripheral arterial disease', 'PADEXC_COD'),\n        ('plaque psoriasis', 'PSORIASIS_COD'),\n        ('polycystic kidney disease', 'EPPCONGMALF_COD'),\n        ('polycythaemia vera', 'C19HAEMCAN_COD'),\n        ('pregnancy', 'C19PREG_COD'),\n        ('primary biliary cholangitis', 'eFI2_LiverProblems'),\n        ('primary hypercholesterolaemia', 'FNFHYP_COD'),\n        ('prostate cancer', 'EPPSOLIDCAN_COD'),\n        ('psoriasis', 'PSORIASIS_COD'),\n        ('psoriatic arthritis', 'RARTHAD_COD'),\n        ('pulmonary embolism', 'eFI2_RespiratoryDiseaseTimeSensitive'),\n        ('pulmonary fibrosis', 'ILD_COD'),\n        ('relapsing multiple sclerosis', 'MS_COD'),\n        ('renal cell carcinoma', 'C19CAN_COD'),\n        ('renal transplantation', 'RENALTRANSP_COD'),\n        ('retinal vein occlusion', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('rheumatoid arthritis', 'eFI2_InflammatoryArthritis'),\n        ('rivaroxaban', 'DOACCON_COD'),\n        ('schizophrenia', 'MH_COD'),\n        ('seizures', 'LSZFREQ_COD'),\n        ('sepsis', 'C19ACTIVITY_COD'),\n        ('severe persistent allergic asthma', 'SEVAST_COD'),\n        ('sickle cell disease', 'SICKLE_COD'),\n        ('sleep apnoea', 'CUST_ICB_NON_SEVERE_LDA'),\n        ('smoking cessation', 'SMOKINGINT_COD'),\n        ('soft tissue sarcoma', 'NHAEMCANMORPH_COD'),\n        ('spinal muscular atrophy', 'MND_COD'),\n        ('squamous cell', 'C19CAN_COD'),\n        ('squamous cell carcinoma', 'C19CAN_COD'),\n        ('stem cell transplant', 'ALLOTRANSP_COD'),\n        ('stroke', 'eFI2_Stroke'),\n        ('systemic lupus erythematosus', 'SLUPUS_COD'),\n        ('systemic mastocytosis', 'HAEMCANMORPH_COD'),\n        ('thrombocytopenic purpura', 'TTP_COD'),\n        ('thrombotic thrombocytopenic purpura', 'TTP_COD'),\n        ('thyroid cancer', 'C19CAN_COD'),\n        ('tophaceous gout', 'CUST_ICB_OSTEOARTHRITIS'),\n        ('transitional cell carcinoma', 'C19CAN_COD'),\n        ('type 1 diabetes', 'DMTYPE1_COD'),\n        ('type 2 diabetes', 'DMTYPE2_COD'),\n        ('ulcerative colitis', 'eFI2_InflammatoryBowelDisease'),\n        ('urothelial carcinoma', 'NHAEMCANMORPH_COD'),\n        ('urticaria', 'XSAL_COD'),\n        ('uveitis', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('vascular disease', 'CVDINVITE_COD'),\n        ('vasculitis', 'CRYOGLOBVASC_COD')\n    ) AS t(Search_Term, Cluster_ID)\n),\n\nClusterCodes AS (\n    SELECT\n        stc.Search_Term,\n        c.\"SNOMEDCode\",\n        c.\"SNOMEDDescription\"\n    FROM SearchTermClusters stc\n    JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" c\n        ON stc.Cluster_ID = c.\"Cluster_ID\"\n    WHERE c.\"SNOMEDCode\" IS NOT NULL\n),\n\nExplicitCodes AS (\n    SELECT Search_Term, SNOMEDCode, SNOMEDDescription FROM (VALUES\n        ('acute coronary syndrome', '837091000000100', 'Manual mapping'),\n        ('ankylosing spondylitis', '162930007', 'Manual mapping'),\n        ('ankylosing spondylitis', '239805001', 'Manual mapping'),\n        ('ankylosing spondylitis', '239810002', 'Manual mapping'),\n        ('ankylosing spondylitis', '239811003', 'Manual mapping'),\n        ('ankylosing spondylitis', '394990003', 'Manual mapping'),\n        ('ankylosing spondylitis', '429712009', 'Manual mapping'),\n        ('ankylosing spondylitis', '441562009', 'Manual mapping'),\n        ('ankylosing spondylitis', '441680005', 'Manual mapping'),\n        ('ankylosing spondylitis', '441930001', 'Manual mapping'),\n        ('axial spondyloarthritis', '723116002', 'Manual mapping'),\n        ('choroidal neovascularisation', '380621000000102', 'Manual mapping'),\n        ('choroidal neovascularisation', '733124000', 'Manual mapping')\n    ) AS t(Search_Term, SNOMEDCode, SNOMEDDescription)\n),\n\nAllIndicationCodes AS (\n    SELECT Search_Term, \"SNOMEDCode\" AS SNOMEDCode, \"SNOMEDDescription\" AS SNOMEDDescription\n    FROM ClusterCodes\n    UNION ALL\n    SELECT Search_Term, SNOMEDCode, SNOMEDDescription\n    FROM ExplicitCodes\n)\n\"\"\"\n\n\ndef get_patient_indication_groups(\n    patient_pseudonyms: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    batch_size: int = 500,\n) -> \"pd.DataFrame\":\n    \"\"\"\n    Batch lookup GP diagnosis-based indication groups using Snowflake cluster query.\n\n    This function queries Snowflake directly using the embedded cluster CTE\n    (from snomed_indication_mapping_query.sql) to find patients with matching\n    GP diagnoses. This is the NEW approach replacing the old SQLite-based lookup.\n\n    The query:\n    1. Uses the cluster mapping CTE to get all Search_Term -> SNOMED code mappings\n    2. Joins with PrimaryCareClinicalCoding to find patients with matching codes\n    3. Returns the most recent match per patient (by EventDateTime)\n\n    Args:\n        patient_pseudonyms: List of PseudoNHSNoLinked values (matches PatientPseudonym in GP records)\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        batch_size: Number of patients per Snowflake query batch (default 500)\n\n    Returns:\n        DataFrame with columns:\n        - PatientPseudonym: The patient identifier (PseudoNHSNoLinked value)\n        - Search_Term: The matched indication (e.g., \"rheumatoid arthritis\")\n        - EventDateTime: Date of the GP diagnosis record\n\n        Patients not found in results have no matching GP diagnosis.\n    \"\"\"\n    import pandas as pd\n\n    logger.info(f\"Starting Snowflake-direct indication lookup for {len(patient_pseudonyms)} patients...\")\n\n    # Handle edge case: empty patient list\n    if not patient_pseudonyms:\n        logger.warning(\"Empty patient list provided\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    # Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        logger.error(\"Snowflake connector not available - cannot lookup GP records\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    if not is_snowflake_configured():\n        logger.error(\"Snowflake not configured - cannot lookup GP records\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    if connector is None:\n        connector = get_connector()\n\n    # Results list to collect all matches\n    all_results: list[dict] = []\n\n    # Process patients in batches\n    total_patients = len(patient_pseudonyms)\n    for batch_start in range(0, total_patients, batch_size):\n        batch_end = min(batch_start + batch_size, total_patients)\n        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n        batch_num = batch_start // batch_size + 1\n        total_batches = (total_patients + batch_size - 1) // batch_size\n\n        logger.info(f\"Batch {batch_num}/{total_batches}: patients {batch_start + 1} to {batch_end}\")\n\n        # Build patient IN clause placeholders\n        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n\n        # Build the full query with cluster CTE\n        # This finds the most recent matching diagnosis for each patient\n        # Note: Column names must be aliased to ensure consistent casing in results\n        query = f\"\"\"\n{CLUSTER_MAPPING_SQL}\nSELECT\n    pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n    aic.Search_Term AS \"Search_Term\",\n    pc.\"EventDateTime\" AS \"EventDateTime\"\nFROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\nINNER JOIN AllIndicationCodes aic\n    ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\nWHERE pc.\"PatientPseudonym\" IN ({patient_placeholders})\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY pc.\"PatientPseudonym\"\n    ORDER BY pc.\"EventDateTime\" DESC\n) = 1\n\"\"\"\n\n        try:\n            results = connector.execute_dict(query, tuple(batch_pseudonyms))\n\n            for row in results:\n                all_results.append({\n                    'PatientPseudonym': row.get('PatientPseudonym'),\n                    'Search_Term': row.get('Search_Term'),\n                    'EventDateTime': row.get('EventDateTime'),\n                })\n\n            logger.debug(f\"Batch {batch_num}: found {len(results)} matches\")\n\n        except Exception as e:\n            logger.error(f\"Error querying GP records for batch {batch_num}: {e}\")\n            # Continue with other batches - partial results are better than none\n\n    # Build result DataFrame\n    result_df = pd.DataFrame(all_results)\n\n    # Log summary statistics\n    if len(result_df) > 0:\n        matched_count = len(result_df)\n        match_rate = 100 * matched_count / total_patients\n        unique_terms = result_df['Search_Term'].nunique()\n        logger.info(f\"Indication lookup complete:\")\n        logger.info(f\"  Total patients queried: {total_patients}\")\n        logger.info(f\"  Patients with GP match: {matched_count} ({match_rate:.1f}%)\")\n        logger.info(f\"  Unique Search_Terms found: {unique_terms}\")\n\n        # Log top Search_Terms\n        top_terms = result_df['Search_Term'].value_counts().head(5)\n        logger.info(f\"  Top 5 indications: {dict(top_terms)}\")\n    else:\n        logger.info(f\"Indication lookup complete: 0 matches from {total_patients} patients\")\n\n    return result_df\n\n\n# Export public API\n__all__ = [\n    # Dataclasses\n    \"ClusterSnomedCodes\",\n    \"IndicationValidationResult\",\n    \"DrugIndicationMatchRate\",\n    \"DrugSnomedMapping\",\n    \"DirectSnomedMatchResult\",\n    \"DirectorateAssignment\",\n    # Cluster-based lookup functions (existing)\n    \"get_drug_clusters\",\n    \"get_drug_cluster_ids\",\n    \"get_cluster_snomed_codes\",\n    \"patient_has_indication\",\n    \"validate_indication\",\n    \"get_indication_match_rate\",\n    \"batch_validate_indications\",\n    \"get_available_clusters\",\n    # Direct SNOMED lookup functions (new)\n    \"get_drug_snomed_codes\",\n    \"patient_has_indication_direct\",\n    # Diagnosis-based directorate assignment\n    \"get_directorate_from_diagnosis\",\n    # Batch lookup for indication groups\n    \"batch_lookup_indication_groups\",\n    # Snowflake-direct indication lookup (new approach)\n    \"get_patient_indication_groups\",\n    \"CLUSTER_MAPPING_SQL\",\n]\n","structuredPatch":[{"oldStart":1087,"oldLines":6,"newStart":1087,"newLines":107,"lines":["     return result_df"," "," ","+# === Drug-to-indication mapping from DimSearchTerm.csv ===","+","+","+def load_drug_indication_mapping(","+    csv_path: Optional[str] = None,","+) -> tuple[dict[str, list[str]], dict[str, list[str]]]:","+    \"\"\"","+    Load the drug-to-Search_Term mapping from DimSearchTerm.csv.","+","+    Builds two lookup dicts:","+    - fragment_to_search_terms: drug fragment (UPPERCASE) -> list of Search_Terms containing it","+    - search_term_to_fragments: search_term -> list of drug fragments (UPPERCASE)","+","+    DimSearchTerm.csv has columns: Search_Term, CleanedDrugName, PrimaryDirectorate","+    CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\").","+","+    Note: A Search_Term can appear multiple times with different PrimaryDirectorates","+    (e.g., \"diabetes\" appears under both DIABETIC MEDICINE and OPHTHALMOLOGY).","+    Drug fragments from all rows for the same Search_Term are combined.","+","+    Args:","+        csv_path: Path to DimSearchTerm.csv. Defaults to data/DimSearchTerm.csv.","+","+    Returns:","+        Tuple of (fragment_to_search_terms, search_term_to_fragments)","+    \"\"\"","+    if csv_path is None:","+        csv_path = str(Path(__file__).parent.parent / \"data\" / \"DimSearchTerm.csv\")","+","+    fragment_to_search_terms: dict[str, list[str]] = {}","+    search_term_to_fragments: dict[str, list[str]] = {}","+","+    try:","+        with open(csv_path, \"r\", encoding=\"utf-8\") as f:","+            reader = csv.DictReader(f)","+            for row in reader:","+                search_term = row.get(\"Search_Term\", \"\").strip()","+                drug_names_raw = row.get(\"CleanedDrugName\", \"\").strip()","+","+                if not search_term or not drug_names_raw:","+                    continue","+","+                fragments = [frag.strip().upper() for frag in drug_names_raw.split(\"|\") if frag.strip()]","+","+                # Build search_term -> fragments (accumulate for duplicate Search_Terms)","+                if search_term not in search_term_to_fragments:","+                    search_term_to_fragments[search_term] = []","+                for frag in fragments:","+                    if frag not in search_term_to_fragments[search_term]:","+                        search_term_to_fragments[search_term].append(frag)","+","+                # Build fragment -> search_terms","+                for frag in fragments:","+                    if frag not in fragment_to_search_terms:","+                        fragment_to_search_terms[frag] = []","+                    if search_term not in fragment_to_search_terms[frag]:","+                        fragment_to_search_terms[frag].append(search_term)","+","+        logger.info(","+            f\"Loaded drug-indication mapping: {len(search_term_to_fragments)} Search_Terms, \"","+            f\"{len(fragment_to_search_terms)} drug fragments\"","+        )","+","+    except FileNotFoundError:","+        logger.error(f\"DimSearchTerm.csv not found at {csv_path}\")","+    except Exception as e:","+        logger.error(f\"Error loading DimSearchTerm.csv: {e}\")","+","+    return fragment_to_search_terms, search_term_to_fragments","+","+","+def get_search_terms_for_drug(","+    drug_name: str,","+    search_term_to_fragments: dict[str, list[str]],","+) -> list[str]:","+    \"\"\"","+    Get all Search_Terms that list a given drug using substring matching.","+","+    Checks if any drug fragment from DimSearchTerm is a SUBSTRING of the given","+    drug name (case-insensitive). This handles both exact matches (ADALIMUMAB)","+    and partial fragments (PEGYLATED, INHALED).","+","+    Args:","+        drug_name: HCD drug name (e.g., \"ADALIMUMAB 40MG\", \"PEGYLATED LIPOSOMAL DOXORUBICIN\")","+        search_term_to_fragments: Mapping of search_term -> list of drug fragments","+","+    Returns:","+        List of Search_Terms whose drug fragments match the drug name","+    \"\"\"","+    drug_name_upper = drug_name.upper()","+    matched_terms: list[str] = []","+","+    for search_term, fragments in search_term_to_fragments.items():","+        for frag in fragments:","+            if frag in drug_name_upper:","+                matched_terms.append(search_term)","+                break  # One matching fragment is enough for this Search_Term","+","+    return matched_terms","+","+"," # === NEW APPROACH: Query Snowflake directly using cluster CTE ==="," "," # The cluster query mapping (embedded from snomed_indication_mapping_query.sql)"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_0161tAWHkUMXyYFZMjEzYE1A","type":"message","role":"assistant","content":[{"type":"text","text":"Now I need to add the new functions to the `__all__` export list."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1550,"cache_read_input_tokens":107444,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1550},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"3e19f74a-dd47-4e44-bbc3-d25d8a2c40d4"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_0161tAWHkUMXyYFZMjEzYE1A","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_016PoR4b1BWjSK8we3Gat174","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py","old_string":"    # Snowflake-direct indication lookup (new approach)\n    \"get_patient_indication_groups\",\n    \"CLUSTER_MAPPING_SQL\",\n]","new_string":"    # Drug-indication mapping from DimSearchTerm.csv\n    \"load_drug_indication_mapping\",\n    \"get_search_terms_for_drug\",\n    # Snowflake-direct indication lookup (new approach)\n    \"get_patient_indication_groups\",\n    \"CLUSTER_MAPPING_SQL\",\n]"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1550,"cache_read_input_tokens":107444,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1550},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"2a302703-0ad8-4ff6-82fe-de13aff4f0c3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_016PoR4b1BWjSK8we3Gat174","type":"tool_result","content":"The file C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"ceab8aaa-933f-4697-95a2-5e5529fd33c1","tool_use_result":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\data_processing\\diagnosis_lookup.py","oldString":"    # Snowflake-direct indication lookup (new approach)\n    \"get_patient_indication_groups\",\n    \"CLUSTER_MAPPING_SQL\",\n]","newString":"    # Drug-indication mapping from DimSearchTerm.csv\n    \"load_drug_indication_mapping\",\n    \"get_search_terms_for_drug\",\n    # Snowflake-direct indication lookup (new approach)\n    \"get_patient_indication_groups\",\n    \"CLUSTER_MAPPING_SQL\",\n]","originalFile":"\"\"\"\nDiagnosis lookup module for NHS Patient Pathway Analysis.\n\nProvides functions to validate patient indications by checking GP diagnosis records\nagainst SNOMED cluster codes. Uses the drug-to-cluster mapping from\ndrug_indication_clusters.csv and queries Snowflake for SNOMED codes and GP records.\n\nKey workflow:\n1. Get drug's valid indication clusters from local mapping\n2. Get all SNOMED codes for those clusters from Snowflake\n3. Check if patient has any of those SNOMED codes in GP records\n4. Report indication validation status\n\nIMPORTANT: HCD activity data indication codes are UNRELIABLE. This module uses\nGP/Primary Care data (PrimaryCareClinicalCoding) as the authoritative source.\n\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom datetime import date, datetime\nfrom pathlib import Path\nfrom typing import Optional, Callable, Any, cast, TYPE_CHECKING\nimport csv\n\nif TYPE_CHECKING:\n    import pandas as pd\n\nfrom core.logging_config import get_logger\nfrom data_processing.database import DatabaseManager, default_db_manager\nfrom data_processing.snowflake_connector import (\n    SnowflakeConnector,\n    get_connector,\n    is_snowflake_available,\n    is_snowflake_configured,\n    SNOWFLAKE_AVAILABLE,\n)\nfrom data_processing.cache import get_cache, is_cache_enabled\n\nlogger = get_logger(__name__)\n\n\n@dataclass\nclass ClusterSnomedCodes:\n    \"\"\"SNOMED codes for a clinical coding cluster.\"\"\"\n    cluster_id: str\n    cluster_description: str\n    snomed_codes: list[str] = field(default_factory=list)\n    snomed_descriptions: dict[str, str] = field(default_factory=dict)\n\n    @property\n    def code_count(self) -> int:\n        return len(self.snomed_codes)\n\n\n@dataclass\nclass IndicationValidationResult:\n    \"\"\"Result of validating a patient's indication for a drug.\"\"\"\n    patient_pseudonym: str\n    drug_name: str\n    has_valid_indication: bool\n    matched_cluster_id: Optional[str] = None\n    matched_snomed_code: Optional[str] = None\n    matched_snomed_description: Optional[str] = None\n    checked_clusters: list[str] = field(default_factory=list)\n    total_codes_checked: int = 0\n    source: str = \"GP_SNOMED\"  # GP_SNOMED | NONE\n    error_message: Optional[str] = None\n\n\n@dataclass\nclass DrugIndicationMatchRate:\n    \"\"\"Match rate statistics for a drug's indication validation.\"\"\"\n    drug_name: str\n    total_patients: int\n    patients_with_indication: int\n    patients_without_indication: int\n    match_rate: float  # 0.0 to 1.0\n    clusters_checked: list[str] = field(default_factory=list)\n    sample_unmatched: list[str] = field(default_factory=list)  # Sample patient IDs\n\n\n@dataclass\nclass DrugSnomedMapping:\n    \"\"\"SNOMED code mapping for a drug from ref_drug_snomed_mapping.\"\"\"\n    snomed_code: str\n    snomed_description: str\n    search_term: str\n    primary_directorate: str\n    indication: str = \"\"\n    ta_id: str = \"\"\n\n\n@dataclass\nclass DirectSnomedMatchResult:\n    \"\"\"Result of direct SNOMED code lookup in GP records.\"\"\"\n    patient_pseudonym: str\n    matched: bool\n    snomed_code: Optional[str] = None\n    snomed_description: Optional[str] = None\n    search_term: Optional[str] = None\n    primary_directorate: Optional[str] = None\n    event_date: Optional[datetime] = None\n    source: str = \"DIRECT_SNOMED\"  # DIRECT_SNOMED | NONE\n\n\n@dataclass\nclass DirectorateAssignment:\n    \"\"\"Result of directorate assignment for a patient-drug combination.\"\"\"\n    upid: str\n    drug_name: str\n    directorate: Optional[str]\n    search_term: Optional[str] = None\n    source: str = \"FALLBACK\"  # DIAGNOSIS | FALLBACK\n    snomed_code: Optional[str] = None\n    event_date: Optional[datetime] = None\n\n\ndef get_drug_clusters(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[dict]:\n    \"\"\"\n    Get all SNOMED cluster mappings for a drug from local SQLite.\n\n    Args:\n        drug_name: Drug name to look up (case-insensitive)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n\n    Returns:\n        List of dicts with keys: drug_name, indication, cluster_id,\n        cluster_description, nice_ta_reference\n    \"\"\"\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    query = \"\"\"\n        SELECT drug_name, indication, cluster_id, cluster_description, nice_ta_reference\n        FROM ref_drug_indication_clusters\n        WHERE UPPER(drug_name) = UPPER(?)\n        ORDER BY indication, cluster_id\n    \"\"\"\n\n    try:\n        with db_manager.get_connection() as conn:\n            cursor = conn.execute(query, (drug_name,))\n            rows = cursor.fetchall()\n\n            results = []\n            for row in rows:\n                results.append({\n                    \"drug_name\": row[\"drug_name\"],\n                    \"indication\": row[\"indication\"],\n                    \"cluster_id\": row[\"cluster_id\"],\n                    \"cluster_description\": row[\"cluster_description\"],\n                    \"nice_ta_reference\": row[\"nice_ta_reference\"],\n                })\n\n            logger.debug(f\"Found {len(results)} cluster mappings for drug '{drug_name}'\")\n            return results\n\n    except Exception as e:\n        logger.error(f\"Error getting clusters for drug '{drug_name}': {e}\")\n        return []\n\n\ndef get_drug_cluster_ids(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[str]:\n    \"\"\"\n    Get unique cluster IDs for a drug.\n\n    Args:\n        drug_name: Drug name to look up\n        db_manager: Optional DatabaseManager\n\n    Returns:\n        List of unique cluster IDs\n    \"\"\"\n    clusters = get_drug_clusters(drug_name, db_manager)\n    return list(set(c[\"cluster_id\"] for c in clusters))\n\n\ndef get_drug_snomed_codes(\n    drug_name: str,\n    db_manager: Optional[DatabaseManager] = None\n) -> list[DrugSnomedMapping]:\n    \"\"\"\n    Get all SNOMED codes for a drug from local ref_drug_snomed_mapping table.\n\n    This uses the enriched mapping CSV data loaded into SQLite, which provides\n    direct SNOMED-to-drug mappings with Search_Term and PrimaryDirectorate.\n\n    Args:\n        drug_name: Drug name to look up (case-insensitive, matches cleaned_drug_name)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n\n    Returns:\n        List of DrugSnomedMapping with snomed_code, snomed_description,\n        search_term, primary_directorate, indication, ta_id\n    \"\"\"\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    query = \"\"\"\n        SELECT DISTINCT\n            snomed_code,\n            snomed_description,\n            search_term,\n            primary_directorate,\n            indication,\n            ta_id\n        FROM ref_drug_snomed_mapping\n        WHERE UPPER(cleaned_drug_name) = UPPER(?)\n           OR UPPER(drug_name) = UPPER(?)\n        ORDER BY search_term, snomed_code\n    \"\"\"\n\n    try:\n        with db_manager.get_connection() as conn:\n            cursor = conn.execute(query, (drug_name, drug_name))\n            rows = cursor.fetchall()\n\n            results = []\n            for row in rows:\n                results.append(DrugSnomedMapping(\n                    snomed_code=row[\"snomed_code\"],\n                    snomed_description=row[\"snomed_description\"] or \"\",\n                    search_term=row[\"search_term\"] or \"\",\n                    primary_directorate=row[\"primary_directorate\"] or \"\",\n                    indication=row[\"indication\"] or \"\",\n                    ta_id=row[\"ta_id\"] or \"\",\n                ))\n\n            logger.debug(f\"Found {len(results)} SNOMED mappings for drug '{drug_name}'\")\n            return results\n\n    except Exception as e:\n        logger.error(f\"Error getting SNOMED codes for drug '{drug_name}': {e}\")\n        return []\n\n\ndef patient_has_indication_direct(\n    patient_pseudonym: str,\n    drug_snomed_mappings: list[DrugSnomedMapping],\n    connector: Optional[SnowflakeConnector] = None,\n    before_date: Optional[date] = None,\n) -> DirectSnomedMatchResult:\n    \"\"\"\n    Check if patient has any of the SNOMED codes in their GP records.\n\n    This is the direct SNOMED lookup - it queries PrimaryCareClinicalCoding\n    for exact SNOMED code matches (not via cluster). Returns the most recent\n    match by EventDateTime if multiple matches exist.\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        drug_snomed_mappings: List of DrugSnomedMapping from get_drug_snomed_codes()\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        DirectSnomedMatchResult with match details (most recent by EventDateTime)\n    \"\"\"\n    result = DirectSnomedMatchResult(\n        patient_pseudonym=patient_pseudonym,\n        matched=False,\n        source=\"NONE\",\n    )\n\n    if not drug_snomed_mappings:\n        return result\n\n    if not SNOWFLAKE_AVAILABLE:\n        logger.warning(\"Snowflake connector not available\")\n        return result\n\n    if not is_snowflake_configured():\n        logger.warning(\"Snowflake not configured - cannot check GP records\")\n        return result\n\n    if connector is None:\n        connector = get_connector()\n\n    # Build lookup dict for mapping snomed_code -> (search_term, primary_directorate, snomed_description)\n    snomed_lookup = {\n        m.snomed_code: (m.search_term, m.primary_directorate, m.snomed_description)\n        for m in drug_snomed_mappings\n    }\n\n    # Get unique SNOMED codes\n    snomed_codes = list(snomed_lookup.keys())\n\n    # Build placeholders for SNOMED codes\n    placeholders = \", \".join([\"%s\"] * len(snomed_codes))\n\n    # Query to find most recent matching SNOMED code in GP records\n    query = f'''\n        SELECT\n            \"SNOMEDCode\",\n            \"EventDateTime\"\n        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n        WHERE \"PatientPseudonym\" = %s\n            AND \"SNOMEDCode\" IN ({placeholders})\n    '''\n\n    params: list = [patient_pseudonym] + snomed_codes\n\n    if before_date:\n        query += ' AND \"EventDateTime\" < %s'\n        params.append(before_date.isoformat())\n\n    query += ' ORDER BY \"EventDateTime\" DESC LIMIT 1'\n\n    try:\n        results = connector.execute_dict(query, tuple(params))\n\n        if results:\n            row = results[0]\n            matched_code = row.get(\"SNOMEDCode\")\n            event_dt = row.get(\"EventDateTime\")\n\n            if matched_code and matched_code in snomed_lookup:\n                search_term, primary_dir, snomed_desc = snomed_lookup[matched_code]\n\n                return DirectSnomedMatchResult(\n                    patient_pseudonym=patient_pseudonym,\n                    matched=True,\n                    snomed_code=matched_code,\n                    snomed_description=snomed_desc,\n                    search_term=search_term,\n                    primary_directorate=primary_dir,\n                    event_date=event_dt,\n                    source=\"DIRECT_SNOMED\",\n                )\n\n        return result\n\n    except Exception as e:\n        logger.error(f\"Error checking direct SNOMED for patient '{patient_pseudonym}': {e}\")\n        return result\n\n\ndef get_directorate_from_diagnosis(\n    upid: str,\n    drug_name: str,\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    before_date: Optional[date] = None,\n) -> DirectorateAssignment:\n    \"\"\"\n    Get directorate assignment for a patient-drug combination using diagnosis-based lookup.\n\n    This function attempts to assign a directorate based on the patient's GP records\n    (direct SNOMED code matching). If no match is found, it returns a FALLBACK result\n    indicating that the caller should use alternative assignment methods (e.g.,\n    department_identification() from tools/data.py).\n\n    Workflow:\n    1. Get all SNOMED codes for the drug from ref_drug_snomed_mapping\n    2. Query patient's GP records for matching SNOMED codes\n    3. If match found ÔåÆ return diagnosis-based directorate and search_term\n    4. If no match ÔåÆ return FALLBACK result (caller handles fallback logic)\n\n    Args:\n        upid: Patient's unique patient ID (Provider Code[:3] + PersonKey)\n        drug_name: Drug name to look up\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        DirectorateAssignment with directorate, search_term, and source\n    \"\"\"\n    result = DirectorateAssignment(\n        upid=upid,\n        drug_name=drug_name,\n        directorate=None,\n        source=\"FALLBACK\",\n    )\n\n    # Step 1: Get SNOMED codes for the drug\n    drug_snomed_mappings = get_drug_snomed_codes(drug_name, db_manager)\n\n    if not drug_snomed_mappings:\n        logger.debug(f\"No SNOMED mappings found for drug '{drug_name}' - using fallback\")\n        return result\n\n    # Step 2: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        logger.debug(\"Snowflake not available - using fallback\")\n        return result\n\n    if not is_snowflake_configured():\n        logger.debug(\"Snowflake not configured - using fallback\")\n        return result\n\n    # Step 3: Get patient pseudonym from UPID\n    # UPID format is Provider Code (3 chars) + PersonKey\n    # We need to query Snowflake to get the PatientPseudonym for this PersonKey\n    # However, patient_has_indication_direct expects PatientPseudonym, not UPID\n    # For now, we'll use UPID as the identifier - the actual integration\n    # will need to happen at the DataFrame level where we have PersonKey\n    #\n    # NOTE: This function will be called from the pipeline where we have\n    # access to PatientPseudonym. The UPID is passed for logging/tracking.\n\n    # Actually, looking at the pipeline, we need PatientPseudonym, not UPID.\n    # The caller should pass the PatientPseudonym or we need to look it up.\n    # For now, let's assume the caller will use this in a batch context\n    # where they can map UPID -> PatientPseudonym.\n\n    # Let me reconsider: the function signature takes UPID but we need\n    # PatientPseudonym for Snowflake. In the pipeline context (fetch_and_transform_data),\n    # we'll have the PersonKey column which IS the PatientPseudonym.\n    # So UPID = ProviderCode[:3] + PersonKey, and PersonKey = PatientPseudonym.\n    #\n    # We can extract PatientPseudonym from UPID by removing the first 3 chars.\n    patient_pseudonym = upid[3:] if len(upid) > 3 else upid\n\n    # Step 4: Check patient's GP records for matching SNOMED codes\n    match_result = patient_has_indication_direct(\n        patient_pseudonym=patient_pseudonym,\n        drug_snomed_mappings=drug_snomed_mappings,\n        connector=connector,\n        before_date=before_date,\n    )\n\n    if match_result.matched and match_result.primary_directorate:\n        return DirectorateAssignment(\n            upid=upid,\n            drug_name=drug_name,\n            directorate=match_result.primary_directorate,\n            search_term=match_result.search_term,\n            source=\"DIAGNOSIS\",\n            snomed_code=match_result.snomed_code,\n            event_date=match_result.event_date,\n        )\n\n    # No match found - return fallback result\n    return result\n\n\ndef get_cluster_snomed_codes(\n    cluster_id: str,\n    connector: Optional[SnowflakeConnector] = None,\n    use_cache: bool = True,\n) -> ClusterSnomedCodes:\n    \"\"\"\n    Get all SNOMED codes for a cluster from Snowflake.\n\n    Queries the ClinicalCodingClusterSnomedCodes table to get all SNOMED codes\n    that belong to the specified cluster.\n\n    Args:\n        cluster_id: Cluster ID to look up (e.g., 'RARTH_COD', 'PSORIASIS_COD')\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        use_cache: Whether to use cached results (default True)\n\n    Returns:\n        ClusterSnomedCodes with list of SNOMED codes and descriptions\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE:\n        logger.warning(\"Snowflake connector not available\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n    if not is_snowflake_configured():\n        logger.warning(\"Snowflake not configured - cannot get cluster codes\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n    # Check cache first\n    cache_key = f\"cluster_snomed_{cluster_id}\"\n    if use_cache and is_cache_enabled():\n        cache = get_cache()\n        cached = cache.get(cache_key)\n        if cached is not None and len(cached) > 0:\n            logger.debug(f\"Using cached SNOMED codes for cluster '{cluster_id}'\")\n            cached_dict = cached[0]  # First element is our data dict\n            return ClusterSnomedCodes(\n                cluster_id=cluster_id,\n                cluster_description=str(cached_dict.get(\"description\", \"\")),\n                snomed_codes=list(cached_dict.get(\"codes\", [])),\n                snomed_descriptions=dict(cached_dict.get(\"descriptions\", {})),\n            )\n\n    if connector is None:\n        connector = get_connector()\n\n    query = '''\n        SELECT DISTINCT\n            \"Cluster_ID\",\n            \"Cluster_Description\",\n            \"SNOMEDCode\",\n            \"SNOMEDDescription\"\n        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n        WHERE \"Cluster_ID\" = %s\n        ORDER BY \"SNOMEDCode\"\n    '''\n\n    try:\n        results = connector.execute_dict(query, (cluster_id,))\n\n        if not results:\n            logger.warning(f\"No SNOMED codes found for cluster '{cluster_id}'\")\n            return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n        codes = []\n        descriptions = {}\n        description = results[0].get(\"Cluster_Description\", \"\") if results else \"\"\n\n        for row in results:\n            code = row.get(\"SNOMEDCode\")\n            if code:\n                codes.append(code)\n                descriptions[code] = row.get(\"SNOMEDDescription\", \"\")\n\n        logger.info(f\"Found {len(codes)} SNOMED codes for cluster '{cluster_id}'\")\n\n        # Cache the results (using query-based cache with fake params)\n        if use_cache and is_cache_enabled():\n            cache = get_cache()\n            cache_data = [{\n                \"description\": description,\n                \"codes\": codes,\n                \"descriptions\": descriptions,\n            }]\n            cache.set(cache_key, None, cache_data)  # type: ignore[arg-type]\n\n        return ClusterSnomedCodes(\n            cluster_id=cluster_id,\n            cluster_description=description,\n            snomed_codes=codes,\n            snomed_descriptions=descriptions,\n        )\n\n    except Exception as e:\n        logger.error(f\"Error getting SNOMED codes for cluster '{cluster_id}': {e}\")\n        return ClusterSnomedCodes(cluster_id=cluster_id, cluster_description=\"\")\n\n\ndef patient_has_indication(\n    patient_pseudonym: str,\n    cluster_ids: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    before_date: Optional[date] = None,\n) -> tuple[bool, Optional[str], Optional[str], Optional[str]]:\n    \"\"\"\n    Check if a patient has any SNOMED codes from the specified clusters in GP records.\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        cluster_ids: List of cluster IDs to check against\n        connector: Optional SnowflakeConnector\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        Tuple of (has_indication, matched_cluster_id, matched_snomed_code, matched_description)\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        return False, None, None, None\n\n    if not cluster_ids:\n        return False, None, None, None\n\n    if connector is None:\n        connector = get_connector()\n\n    # Build placeholders for cluster IDs\n    placeholders = \", \".join([\"%s\"] * len(cluster_ids))\n\n    # Query to check if patient has any matching SNOMED code\n    query = f'''\n        SELECT\n            pc.\"SNOMEDCode\",\n            cc.\"Cluster_ID\",\n            cc.\"SNOMEDDescription\"\n        FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\n        INNER JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" cc\n            ON pc.\"SNOMEDCode\" = cc.\"SNOMEDCode\"\n        WHERE pc.\"PatientPseudonym\" = %s\n            AND cc.\"Cluster_ID\" IN ({placeholders})\n    '''\n\n    params = [patient_pseudonym] + cluster_ids\n\n    if before_date:\n        query += ' AND pc.\"EventDateTime\" < %s'\n        params.append(before_date.isoformat())\n\n    query += ' LIMIT 1'\n\n    try:\n        results = connector.execute_dict(query, tuple(params))\n\n        if results:\n            row = results[0]\n            return (\n                True,\n                row.get(\"Cluster_ID\"),\n                row.get(\"SNOMEDCode\"),\n                row.get(\"SNOMEDDescription\"),\n            )\n\n        return False, None, None, None\n\n    except Exception as e:\n        logger.error(f\"Error checking indication for patient '{patient_pseudonym}': {e}\")\n        return False, None, None, None\n\n\ndef validate_indication(\n    patient_pseudonym: str,\n    drug_name: str,\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    before_date: Optional[date] = None,\n) -> IndicationValidationResult:\n    \"\"\"\n    Validate that a patient has an appropriate indication for a drug.\n\n    Full validation workflow:\n    1. Get drug's valid indication clusters from local mapping\n    2. Check if patient has any matching SNOMED codes in GP records\n    3. Return detailed validation result\n\n    Args:\n        patient_pseudonym: Patient's pseudonymised NHS number\n        drug_name: Drug name to validate indication for\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        before_date: Optional date - only check diagnoses before this date\n\n    Returns:\n        IndicationValidationResult with validation details\n    \"\"\"\n    result = IndicationValidationResult(\n        patient_pseudonym=patient_pseudonym,\n        drug_name=drug_name,\n        has_valid_indication=False,\n    )\n\n    # Step 1: Get drug's cluster mappings\n    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n\n    if not cluster_ids:\n        result.error_message = f\"No cluster mappings found for drug '{drug_name}'\"\n        result.source = \"NONE\"\n        return result\n\n    result.checked_clusters = cluster_ids\n\n    # Step 2: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        result.error_message = \"Snowflake connector not installed\"\n        result.source = \"NONE\"\n        return result\n\n    if not is_snowflake_configured():\n        result.error_message = \"Snowflake not configured\"\n        result.source = \"NONE\"\n        return result\n\n    # Step 3: Check patient GP records\n    has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n        patient_pseudonym=patient_pseudonym,\n        cluster_ids=cluster_ids,\n        connector=connector,\n        before_date=before_date,\n    )\n\n    result.has_valid_indication = has_indication\n    result.matched_cluster_id = matched_cluster\n    result.matched_snomed_code = matched_code\n    result.matched_snomed_description = matched_desc\n    result.source = \"GP_SNOMED\" if has_indication else \"NONE\"\n\n    return result\n\n\ndef get_indication_match_rate(\n    drug_name: str,\n    patient_pseudonyms: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    sample_unmatched_count: int = 10,\n) -> DrugIndicationMatchRate:\n    \"\"\"\n    Calculate indication match rate for a drug across a list of patients.\n\n    Args:\n        drug_name: Drug name to check\n        patient_pseudonyms: List of patient pseudonymised NHS numbers\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        sample_unmatched_count: Number of unmatched patient IDs to include in sample\n\n    Returns:\n        DrugIndicationMatchRate with match statistics\n    \"\"\"\n    if connector is None and SNOWFLAKE_AVAILABLE and is_snowflake_configured():\n        connector = get_connector()\n\n    cluster_ids = get_drug_cluster_ids(drug_name, db_manager)\n\n    total = len(patient_pseudonyms)\n    matched = 0\n    unmatched = 0\n    sample_unmatched: list[str] = []\n\n    if not cluster_ids:\n        logger.warning(f\"No cluster mappings for drug '{drug_name}' - all patients will be unmatched\")\n        return DrugIndicationMatchRate(\n            drug_name=drug_name,\n            total_patients=total,\n            patients_with_indication=0,\n            patients_without_indication=total,\n            match_rate=0.0,\n            clusters_checked=[],\n            sample_unmatched=patient_pseudonyms[:sample_unmatched_count],\n        )\n\n    for i, pseudonym in enumerate(patient_pseudonyms):\n        if i > 0 and i % 100 == 0:\n            logger.info(f\"Validating indications: {i}/{total} ({100*i/total:.1f}%)\")\n\n        has_indication, _, _, _ = patient_has_indication(\n            patient_pseudonym=pseudonym,\n            cluster_ids=cluster_ids,\n            connector=connector,\n        )\n\n        if has_indication:\n            matched += 1\n        else:\n            unmatched += 1\n            if len(sample_unmatched) < sample_unmatched_count:\n                sample_unmatched.append(pseudonym)\n\n    match_rate = matched / total if total > 0 else 0.0\n\n    logger.info(f\"Indication match rate for '{drug_name}': {100*match_rate:.1f}% ({matched}/{total})\")\n\n    return DrugIndicationMatchRate(\n        drug_name=drug_name,\n        total_patients=total,\n        patients_with_indication=matched,\n        patients_without_indication=unmatched,\n        match_rate=match_rate,\n        clusters_checked=cluster_ids,\n        sample_unmatched=sample_unmatched,\n    )\n\n\ndef batch_validate_indications(\n    patient_drug_pairs: list[tuple[str, str]],\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    progress_callback: Optional[Callable[[int, int], None]] = None,\n) -> list[IndicationValidationResult]:\n    \"\"\"\n    Validate indications for multiple patient-drug pairs efficiently.\n\n    Args:\n        patient_drug_pairs: List of (patient_pseudonym, drug_name) tuples\n        connector: Optional SnowflakeConnector\n        db_manager: Optional DatabaseManager\n        progress_callback: Optional callback(current, total) for progress updates\n\n    Returns:\n        List of IndicationValidationResult for each pair\n    \"\"\"\n    results = []\n    total = len(patient_drug_pairs)\n\n    # Cache cluster lookups by drug\n    drug_clusters_cache = {}\n\n    for i, (pseudonym, drug_name) in enumerate(patient_drug_pairs):\n        if progress_callback:\n            progress_callback(i + 1, total)\n\n        # Get clusters from cache or lookup\n        drug_upper = drug_name.upper()\n        if drug_upper not in drug_clusters_cache:\n            drug_clusters_cache[drug_upper] = get_drug_cluster_ids(drug_name, db_manager)\n\n        cluster_ids = drug_clusters_cache[drug_upper]\n\n        if not cluster_ids:\n            results.append(IndicationValidationResult(\n                patient_pseudonym=pseudonym,\n                drug_name=drug_name,\n                has_valid_indication=False,\n                source=\"NONE\",\n                error_message=f\"No cluster mappings for drug '{drug_name}'\",\n            ))\n            continue\n\n        # Check patient indication\n        has_indication, matched_cluster, matched_code, matched_desc = patient_has_indication(\n            patient_pseudonym=pseudonym,\n            cluster_ids=cluster_ids,\n            connector=connector,\n        )\n\n        results.append(IndicationValidationResult(\n            patient_pseudonym=pseudonym,\n            drug_name=drug_name,\n            has_valid_indication=has_indication,\n            matched_cluster_id=matched_cluster,\n            matched_snomed_code=matched_code,\n            matched_snomed_description=matched_desc,\n            checked_clusters=cluster_ids,\n            source=\"GP_SNOMED\" if has_indication else \"NONE\",\n        ))\n\n    matched_count = sum(1 for r in results if r.has_valid_indication)\n    logger.info(f\"Batch validation complete: {matched_count}/{total} ({100*matched_count/total:.1f}%) with valid indications\")\n\n    return results\n\n\ndef get_available_clusters(\n    connector: Optional[SnowflakeConnector] = None,\n) -> list[dict]:\n    \"\"\"\n    Get list of all available SNOMED clusters from Snowflake.\n\n    Returns:\n        List of dicts with cluster_id, cluster_description, code_count\n    \"\"\"\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        logger.warning(\"Snowflake not available - cannot list clusters\")\n        return []\n\n    if connector is None:\n        connector = get_connector()\n\n    query = '''\n        SELECT\n            \"Cluster_ID\",\n            \"Cluster_Description\",\n            COUNT(DISTINCT \"SNOMEDCode\") as code_count\n        FROM DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\"\n        GROUP BY \"Cluster_ID\", \"Cluster_Description\"\n        ORDER BY \"Cluster_ID\"\n    '''\n\n    try:\n        results = connector.execute_dict(query)\n\n        clusters = []\n        for row in results:\n            clusters.append({\n                \"cluster_id\": row.get(\"Cluster_ID\"),\n                \"cluster_description\": row.get(\"Cluster_Description\"),\n                \"code_count\": row.get(\"code_count\", 0),\n            })\n\n        logger.info(f\"Found {len(clusters)} available SNOMED clusters\")\n        return clusters\n\n    except Exception as e:\n        logger.error(f\"Error getting available clusters: {e}\")\n        return []\n\n\ndef batch_lookup_indication_groups(\n    df: \"pd.DataFrame\",\n    connector: Optional[SnowflakeConnector] = None,\n    db_manager: Optional[DatabaseManager] = None,\n    batch_size: int = 500,\n) -> \"pd.DataFrame\":\n    \"\"\"\n    Batch lookup GP diagnosis-based indication groups for a DataFrame of patients.\n\n    This is the efficient batch version of get_directorate_from_diagnosis().\n    Instead of querying Snowflake per patient, it batches the lookups for performance.\n\n    Strategy:\n    1. Get all unique (PersonKey, Drug Name) pairs from DataFrame\n    2. For each unique drug, get all SNOMED codes from local SQLite\n    3. Build batched Snowflake queries to check GP records\n    4. Return indication_df mapping UPID ÔåÆ Indication_Group\n\n    For unmatched patients, Indication_Group will be their Directory (with suffix).\n\n    Args:\n        df: DataFrame with columns: UPID, Drug Name, Directory, PersonKey\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        db_manager: Optional DatabaseManager (defaults to default_db_manager)\n        batch_size: Number of patients per Snowflake query batch\n\n    Returns:\n        DataFrame with columns: UPID, Indication_Group, Source\n        - Indication_Group: Search_Term (if matched) or \"Directory (no GP dx)\" (if not)\n        - Source: \"DIAGNOSIS\" or \"FALLBACK\"\n    \"\"\"\n    import pandas as pd\n\n    if db_manager is None:\n        db_manager = default_db_manager\n\n    logger.info(f\"Starting batch indication lookup for {len(df)} records...\")\n\n    # Step 1: Get unique (UPID, Drug Name, PseudoNHSNoLinked, Directory) combinations\n    # We need PseudoNHSNoLinked to query Snowflake - this matches PatientPseudonym in GP records\n    # Note: PersonKey is LocalPatientID which is provider-specific and does NOT match GP records\n    if 'PseudoNHSNoLinked' not in df.columns:\n        logger.error(\"DataFrame missing 'PseudoNHSNoLinked' column - cannot lookup GP records\")\n        # Return fallback for all patients\n        result_df = df[['UPID', 'Directory']].drop_duplicates().copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']]\n\n    # Get unique patient-drug combinations (we need one lookup per patient-drug pair)\n    unique_pairs = df[['UPID', 'Drug Name', 'PseudoNHSNoLinked', 'Directory']].drop_duplicates()\n    logger.info(f\"Found {len(unique_pairs)} unique patient-drug combinations\")\n\n    # Step 2: Get all unique drugs and their SNOMED codes\n    unique_drugs = unique_pairs['Drug Name'].unique()\n    logger.info(f\"Building SNOMED lookup for {len(unique_drugs)} unique drugs...\")\n\n    # Build drug -> list of DrugSnomedMapping dict\n    drug_snomed_map: dict[str, list[DrugSnomedMapping]] = {}\n    all_snomed_codes: set[str] = set()\n    snomed_to_drug_searchterm: dict[str, list[tuple[str, str, str]]] = {}  # snomed -> [(drug, search_term, primary_dir), ...]\n\n    for drug_name in unique_drugs:\n        mappings = get_drug_snomed_codes(drug_name, db_manager)\n        drug_snomed_map[drug_name] = mappings\n\n        for m in mappings:\n            all_snomed_codes.add(m.snomed_code)\n            if m.snomed_code not in snomed_to_drug_searchterm:\n                snomed_to_drug_searchterm[m.snomed_code] = []\n            snomed_to_drug_searchterm[m.snomed_code].append(\n                (drug_name, m.search_term, m.primary_directorate)\n            )\n\n    logger.info(f\"Total SNOMED codes to check: {len(all_snomed_codes)}\")\n\n    # Step 3: Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE or not is_snowflake_configured():\n        logger.warning(\"Snowflake not available - returning fallback for all patients\")\n        result_df = unique_pairs[['UPID', 'Directory']].copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n\n    if connector is None:\n        connector = get_connector()\n\n    # Step 4: Query GP records for all patients in batches\n    # The query finds the most recent matching SNOMED code for each patient\n\n    # Get unique PseudoNHSNoLinked values (each = one patient in GP records)\n    unique_patients = unique_pairs[['PseudoNHSNoLinked', 'UPID', 'Directory']].drop_duplicates(subset=['PseudoNHSNoLinked'])\n    patient_pseudonyms = unique_patients['PseudoNHSNoLinked'].tolist()\n\n    logger.info(f\"Querying GP records for {len(patient_pseudonyms)} unique patients in batches of {batch_size}...\")\n\n    # Results dict: PersonKey -> (snomed_code, event_date)\n    gp_matches: dict[str, tuple[str, Any]] = {}\n\n    # Convert SNOMED codes to list for query\n    snomed_list = list(all_snomed_codes)\n\n    if not snomed_list:\n        logger.warning(\"No SNOMED codes to check - returning fallback for all patients\")\n        result_df = unique_pairs[['UPID', 'Directory']].copy()\n        result_df['Indication_Group'] = result_df['Directory'] + \" (no GP dx)\"\n        result_df['Source'] = \"FALLBACK\"\n        return result_df[['UPID', 'Indication_Group', 'Source']].drop_duplicates(subset=['UPID'])\n\n    # Build SNOMED IN clause (reused across batches)\n    snomed_placeholders = \", \".join([\"%s\"] * len(snomed_list))\n\n    # Process patients in batches\n    for batch_start in range(0, len(patient_pseudonyms), batch_size):\n        batch_end = min(batch_start + batch_size, len(patient_pseudonyms))\n        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n\n        logger.info(f\"Batch {batch_start//batch_size + 1}: patients {batch_start} to {batch_end}\")\n\n        # Build patient IN clause\n        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n\n        # Query to find all matching SNOMED codes for these patients\n        # We'll get all matches and pick the most recent per patient in Python\n        query = f'''\n            SELECT\n                \"PatientPseudonym\",\n                \"SNOMEDCode\",\n                \"EventDateTime\"\n            FROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\"\n            WHERE \"PatientPseudonym\" IN ({patient_placeholders})\n              AND \"SNOMEDCode\" IN ({snomed_placeholders})\n            ORDER BY \"PatientPseudonym\", \"EventDateTime\" DESC\n        '''\n\n        params = tuple(batch_pseudonyms) + tuple(snomed_list)\n\n        try:\n            results = connector.execute_dict(query, params)\n\n            # Process results - pick most recent per patient\n            for row in results:\n                person_key = row.get(\"PatientPseudonym\")\n                snomed_code = row.get(\"SNOMEDCode\")\n                event_date = row.get(\"EventDateTime\")\n\n                if person_key and snomed_code:\n                    # Keep only if we haven't seen this patient yet (first = most recent due to ORDER BY)\n                    if person_key not in gp_matches:\n                        gp_matches[person_key] = (snomed_code, event_date)\n\n        except Exception as e:\n            logger.error(f\"Error querying GP records for batch: {e}\")\n            # Continue with other batches\n\n    logger.info(f\"Found GP matches for {len(gp_matches)} patients\")\n\n    # Step 5: Build result DataFrame\n    # For each unique_pair, determine Indication_Group based on match status\n    results_list = []\n\n    # We need to dedupe by UPID - a patient might be on multiple drugs\n    # Strategy: For each UPID, use the most recent match (if any)\n    upid_to_match: dict[str, tuple[str, str]] = {}  # UPID -> (Indication_Group, Source)\n\n    for _, row in unique_pairs.iterrows():\n        upid = row['UPID']\n        drug_name = row['Drug Name']\n        patient_pseudonym = row['PseudoNHSNoLinked']\n        directory = row['Directory']\n\n        # Check if patient has GP match (using PseudoNHSNoLinked which matches PatientPseudonym in GP)\n        if patient_pseudonym in gp_matches:\n            matched_snomed, event_date = gp_matches[patient_pseudonym]\n\n            # Find the search_term for this SNOMED code and drug\n            # (A SNOMED code might map to multiple drugs with different search_terms)\n            if matched_snomed in snomed_to_drug_searchterm:\n                # Look for match with current drug first\n                search_term = None\n                for drug, st, pd in snomed_to_drug_searchterm[matched_snomed]:\n                    if drug.upper() == drug_name.upper():\n                        search_term = st\n                        break\n                # If no drug-specific match, use any match\n                if search_term is None:\n                    search_term = snomed_to_drug_searchterm[matched_snomed][0][1]\n\n                # Only update if we don't have a match for this UPID yet\n                if upid not in upid_to_match:\n                    upid_to_match[upid] = (search_term, \"DIAGNOSIS\")\n            else:\n                # Shouldn't happen but fallback just in case\n                if upid not in upid_to_match:\n                    upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n        else:\n            # No GP match - use fallback\n            if upid not in upid_to_match:\n                upid_to_match[upid] = (directory + \" (no GP dx)\", \"FALLBACK\")\n\n    # Build result DataFrame\n    for upid, (indication_group, source) in upid_to_match.items():\n        results_list.append({\n            'UPID': upid,\n            'Indication_Group': indication_group,\n            'Source': source,\n        })\n\n    result_df = pd.DataFrame(results_list)\n\n    # Log statistics\n    diagnosis_count = len([s for s in result_df['Source'] if s == \"DIAGNOSIS\"])\n    fallback_count = len([s for s in result_df['Source'] if s == \"FALLBACK\"])\n    total = len(result_df)\n\n    logger.info(f\"Indication lookup complete:\")\n    logger.info(f\"  Total unique patients: {total}\")\n    logger.info(f\"  DIAGNOSIS matches: {diagnosis_count} ({100*diagnosis_count/total:.1f}%)\")\n    logger.info(f\"  FALLBACK (no GP match): {fallback_count} ({100*fallback_count/total:.1f}%)\")\n\n    return result_df\n\n\n# === Drug-to-indication mapping from DimSearchTerm.csv ===\n\n\ndef load_drug_indication_mapping(\n    csv_path: Optional[str] = None,\n) -> tuple[dict[str, list[str]], dict[str, list[str]]]:\n    \"\"\"\n    Load the drug-to-Search_Term mapping from DimSearchTerm.csv.\n\n    Builds two lookup dicts:\n    - fragment_to_search_terms: drug fragment (UPPERCASE) -> list of Search_Terms containing it\n    - search_term_to_fragments: search_term -> list of drug fragments (UPPERCASE)\n\n    DimSearchTerm.csv has columns: Search_Term, CleanedDrugName, PrimaryDirectorate\n    CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\").\n\n    Note: A Search_Term can appear multiple times with different PrimaryDirectorates\n    (e.g., \"diabetes\" appears under both DIABETIC MEDICINE and OPHTHALMOLOGY).\n    Drug fragments from all rows for the same Search_Term are combined.\n\n    Args:\n        csv_path: Path to DimSearchTerm.csv. Defaults to data/DimSearchTerm.csv.\n\n    Returns:\n        Tuple of (fragment_to_search_terms, search_term_to_fragments)\n    \"\"\"\n    if csv_path is None:\n        csv_path = str(Path(__file__).parent.parent / \"data\" / \"DimSearchTerm.csv\")\n\n    fragment_to_search_terms: dict[str, list[str]] = {}\n    search_term_to_fragments: dict[str, list[str]] = {}\n\n    try:\n        with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                search_term = row.get(\"Search_Term\", \"\").strip()\n                drug_names_raw = row.get(\"CleanedDrugName\", \"\").strip()\n\n                if not search_term or not drug_names_raw:\n                    continue\n\n                fragments = [frag.strip().upper() for frag in drug_names_raw.split(\"|\") if frag.strip()]\n\n                # Build search_term -> fragments (accumulate for duplicate Search_Terms)\n                if search_term not in search_term_to_fragments:\n                    search_term_to_fragments[search_term] = []\n                for frag in fragments:\n                    if frag not in search_term_to_fragments[search_term]:\n                        search_term_to_fragments[search_term].append(frag)\n\n                # Build fragment -> search_terms\n                for frag in fragments:\n                    if frag not in fragment_to_search_terms:\n                        fragment_to_search_terms[frag] = []\n                    if search_term not in fragment_to_search_terms[frag]:\n                        fragment_to_search_terms[frag].append(search_term)\n\n        logger.info(\n            f\"Loaded drug-indication mapping: {len(search_term_to_fragments)} Search_Terms, \"\n            f\"{len(fragment_to_search_terms)} drug fragments\"\n        )\n\n    except FileNotFoundError:\n        logger.error(f\"DimSearchTerm.csv not found at {csv_path}\")\n    except Exception as e:\n        logger.error(f\"Error loading DimSearchTerm.csv: {e}\")\n\n    return fragment_to_search_terms, search_term_to_fragments\n\n\ndef get_search_terms_for_drug(\n    drug_name: str,\n    search_term_to_fragments: dict[str, list[str]],\n) -> list[str]:\n    \"\"\"\n    Get all Search_Terms that list a given drug using substring matching.\n\n    Checks if any drug fragment from DimSearchTerm is a SUBSTRING of the given\n    drug name (case-insensitive). This handles both exact matches (ADALIMUMAB)\n    and partial fragments (PEGYLATED, INHALED).\n\n    Args:\n        drug_name: HCD drug name (e.g., \"ADALIMUMAB 40MG\", \"PEGYLATED LIPOSOMAL DOXORUBICIN\")\n        search_term_to_fragments: Mapping of search_term -> list of drug fragments\n\n    Returns:\n        List of Search_Terms whose drug fragments match the drug name\n    \"\"\"\n    drug_name_upper = drug_name.upper()\n    matched_terms: list[str] = []\n\n    for search_term, fragments in search_term_to_fragments.items():\n        for frag in fragments:\n            if frag in drug_name_upper:\n                matched_terms.append(search_term)\n                break  # One matching fragment is enough for this Search_Term\n\n    return matched_terms\n\n\n# === NEW APPROACH: Query Snowflake directly using cluster CTE ===\n\n# The cluster query mapping (embedded from snomed_indication_mapping_query.sql)\n# This maps Search_Term -> Cluster_ID for ~148 clinical conditions\nCLUSTER_MAPPING_SQL = \"\"\"\nWITH SearchTermClusters AS (\n    SELECT Search_Term, Cluster_ID FROM (VALUES\n        ('acute lymphoblastic leukaemia', 'HAEMCANMORPH_COD'),\n        ('acute myeloid leukaemia', 'C19HAEMCAN_COD'),\n        ('acute promyelocytic leukaemia', 'HAEMCANMORPH_COD'),\n        ('allergic asthma', 'AST_COD'),\n        ('allergic rhinitis', 'MILDINTAST_COD'),\n        ('alzheimer''s disease', 'DEMALZ_COD'),\n        ('amyloidosis', 'AMYLOID_COD'),\n        ('anaemia', 'eFI2_AnaemiaTimeSensitive'),\n        ('anaplastic large cell lymphoma', 'C19HAEMCAN_COD'),\n        ('apixaban', 'DOACCON_COD'),\n        ('aplastic anaemia', 'eFI2_AnaemiaEver'),\n        ('arthritis', 'eFI2_InflammatoryArthritis'),\n        ('asthma', 'eFI2_Asthma'),\n        ('atopic dermatitis', 'ATOPDERM_COD'),\n        ('atrial fibrillation', 'eFI2_AtrialFibrillation'),\n        ('attention deficit hyperactivity disorder', 'ADHD_COD'),\n        ('bipolar disorder', 'MH_COD'),\n        ('bladder', 'eFI2_UrinaryIncontinence'),\n        ('breast cancer', 'BRCANSCR_COD'),\n        ('cardiomyopathy', 'eFI2_HarmfulDrinking'),\n        ('cardiovascular disease', 'CVDRISKASS_COD'),\n        ('cervical cancer', 'CSDEC_COD'),\n        ('cholangiocarcinoma', 'eFI2_Cancer'),\n        ('chronic kidney disease', 'CKD_COD'),\n        ('chronic liver disease', 'eFI2_LiverProblems'),\n        ('chronic lymphocytic leukaemia', 'EPPHAEMCAN_COD'),\n        ('chronic myeloid leukaemia', 'EPPHAEMCAN_COD'),\n        ('chronic obstructive pulmonary disease', 'eFI2_COPD'),\n        ('colon cancer', 'eFI2_Cancer'),\n        ('colorectal cancer', 'GICANREF_COD'),\n        ('constipation', 'CHRONCONSTIP_COD'),\n        ('covid-19', 'POSSPOSTCOVID_COD'),\n        ('crohn''s disease', 'eFI2_InflammatoryBowelDisease'),\n        ('cutaneous t-cell lymphoma', 'C19HAEMCAN_COD'),\n        ('cystic fibrosis', 'CUST_ICB_CYSTIC_FIBROSIS'),\n        ('deep vein thrombosis', 'VTE_COD'),\n        ('depression', 'eFI2_Depression'),\n        ('diabetes', 'eFI2_DiabetesEver'),\n        ('diabetic retinopathy', 'DRSELIGIBILITY_COD'),\n        ('diffuse large b-cell lymphoma', 'C19HAEMCAN_COD'),\n        ('dravet syndrome', 'EPIL_COD'),\n        ('drug misuse', 'ILLSUBINT_COD'),\n        ('dyspepsia', 'eFI2_AbdominalPain'),\n        ('epilepsy', 'eFI2_Seizures'),\n        ('fallopian tube', 'STERIL_COD'),\n        ('follicular lymphoma', 'C19HAEMCAN_COD'),\n        ('gastric cancer', 'eFI2_Cancer'),\n        ('giant cell arteritis', 'GCA_COD'),\n        ('glioma', 'NHAEMCANMORPH_COD'),\n        ('gout', 'eFI2_InflammatoryArthritis'),\n        ('graft versus host disease', 'GVHD_COD'),\n        ('granulomatosis with polyangiitis', 'WEGENERVASC_COD'),\n        ('growth hormone deficiency', 'HYPOPITUITARY_COD'),\n        ('hand eczema', 'ECZEMA_COD'),\n        ('heart failure', 'eFI2_HeartFailure'),\n        ('hepatitis b', 'HEPBCVAC_COD'),\n        ('hepatocellular carcinoma', 'eFI2_Cancer'),\n        ('hiv', 'PREFLANG_COD'),\n        ('hodgkin lymphoma', 'HAEMCANMORPH_COD'),\n        ('hormone receptor', 'eFI2_ThyroidProblems'),\n        ('hypercholesterolaemia', 'CLASSFH_COD'),\n        ('immune thrombocytopenia', 'ITP_COD'),\n        ('influenza', 'FLUINVITE_COD'),\n        ('insomnia', 'eFI2_SleepProblems'),\n        ('irritable bowel syndrome', 'IBS_COD'),\n        ('ischaemic stroke', 'OSTR_COD'),\n        ('juvenile idiopathic arthritis', 'RARTHAD_COD'),\n        ('kidney transplant', 'RENALTRANSP_COD'),\n        ('leukaemia', 'eFI2_Cancer'),\n        ('lung cancer', 'FTCANREF_COD'),\n        ('lymphoma', 'C19HAEMCAN_COD'),\n        ('macular degeneration', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('macular oedema', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('major depressive episodes', 'eFI2_Depression'),\n        ('malignant melanoma', 'eFI2_Cancer'),\n        ('malignant pleural mesothelioma', 'LUNGCAN_COD'),\n        ('manic episode', 'MH_COD'),\n        ('mantle cell lymphoma', 'HAEMCANMORPH_COD'),\n        ('melanoma', 'eFI2_Cancer'),\n        ('merkel cell carcinoma', 'C19CAN_COD'),\n        ('migraine', 'eFI2_Headache'),\n        ('motor neurone disease', 'MND_COD'),\n        ('multiple myeloma', 'C19HAEMCAN_COD'),\n        ('multiple sclerosis', 'MS_COD'),\n        ('myelodysplastic', 'eFI2_AnaemiaEver'),\n        ('myelofibrosis', 'MDS_COD'),\n        ('myocardial infarction', 'eFI2_IschaemicHeartDisease'),\n        ('myotonia', 'CNDATRISK2_COD'),\n        ('narcolepsy', 'LD_COD'),\n        ('neuroendocrine tumour', 'LUNGCAN_COD'),\n        ('non-small cell lung cancer', 'LUNGCAN_COD'),\n        ('non-small-cell lung cancer', 'FTCANREF_COD'),\n        ('obesity', 'BMI30_COD'),\n        ('osteoarthritis', 'CUST_ICB_OSTEOARTHRITIS'),\n        ('osteoporosis', 'eFI2_Osteoporosis'),\n        ('osteosarcoma', 'NHAEMCANMORPH_COD'),\n        ('ovarian cancer', 'C19CAN_COD'),\n        ('peripheral arterial disease', 'PADEXC_COD'),\n        ('plaque psoriasis', 'PSORIASIS_COD'),\n        ('polycystic kidney disease', 'EPPCONGMALF_COD'),\n        ('polycythaemia vera', 'C19HAEMCAN_COD'),\n        ('pregnancy', 'C19PREG_COD'),\n        ('primary biliary cholangitis', 'eFI2_LiverProblems'),\n        ('primary hypercholesterolaemia', 'FNFHYP_COD'),\n        ('prostate cancer', 'EPPSOLIDCAN_COD'),\n        ('psoriasis', 'PSORIASIS_COD'),\n        ('psoriatic arthritis', 'RARTHAD_COD'),\n        ('pulmonary embolism', 'eFI2_RespiratoryDiseaseTimeSensitive'),\n        ('pulmonary fibrosis', 'ILD_COD'),\n        ('relapsing multiple sclerosis', 'MS_COD'),\n        ('renal cell carcinoma', 'C19CAN_COD'),\n        ('renal transplantation', 'RENALTRANSP_COD'),\n        ('retinal vein occlusion', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('rheumatoid arthritis', 'eFI2_InflammatoryArthritis'),\n        ('rivaroxaban', 'DOACCON_COD'),\n        ('schizophrenia', 'MH_COD'),\n        ('seizures', 'LSZFREQ_COD'),\n        ('sepsis', 'C19ACTIVITY_COD'),\n        ('severe persistent allergic asthma', 'SEVAST_COD'),\n        ('sickle cell disease', 'SICKLE_COD'),\n        ('sleep apnoea', 'CUST_ICB_NON_SEVERE_LDA'),\n        ('smoking cessation', 'SMOKINGINT_COD'),\n        ('soft tissue sarcoma', 'NHAEMCANMORPH_COD'),\n        ('spinal muscular atrophy', 'MND_COD'),\n        ('squamous cell', 'C19CAN_COD'),\n        ('squamous cell carcinoma', 'C19CAN_COD'),\n        ('stem cell transplant', 'ALLOTRANSP_COD'),\n        ('stroke', 'eFI2_Stroke'),\n        ('systemic lupus erythematosus', 'SLUPUS_COD'),\n        ('systemic mastocytosis', 'HAEMCANMORPH_COD'),\n        ('thrombocytopenic purpura', 'TTP_COD'),\n        ('thrombotic thrombocytopenic purpura', 'TTP_COD'),\n        ('thyroid cancer', 'C19CAN_COD'),\n        ('tophaceous gout', 'CUST_ICB_OSTEOARTHRITIS'),\n        ('transitional cell carcinoma', 'C19CAN_COD'),\n        ('type 1 diabetes', 'DMTYPE1_COD'),\n        ('type 2 diabetes', 'DMTYPE2_COD'),\n        ('ulcerative colitis', 'eFI2_InflammatoryBowelDisease'),\n        ('urothelial carcinoma', 'NHAEMCANMORPH_COD'),\n        ('urticaria', 'XSAL_COD'),\n        ('uveitis', 'CUST_ICB_VISUAL_IMPAIRMENT'),\n        ('vascular disease', 'CVDINVITE_COD'),\n        ('vasculitis', 'CRYOGLOBVASC_COD')\n    ) AS t(Search_Term, Cluster_ID)\n),\n\nClusterCodes AS (\n    SELECT\n        stc.Search_Term,\n        c.\"SNOMEDCode\",\n        c.\"SNOMEDDescription\"\n    FROM SearchTermClusters stc\n    JOIN DATA_HUB.PHM.\"ClinicalCodingClusterSnomedCodes\" c\n        ON stc.Cluster_ID = c.\"Cluster_ID\"\n    WHERE c.\"SNOMEDCode\" IS NOT NULL\n),\n\nExplicitCodes AS (\n    SELECT Search_Term, SNOMEDCode, SNOMEDDescription FROM (VALUES\n        ('acute coronary syndrome', '837091000000100', 'Manual mapping'),\n        ('ankylosing spondylitis', '162930007', 'Manual mapping'),\n        ('ankylosing spondylitis', '239805001', 'Manual mapping'),\n        ('ankylosing spondylitis', '239810002', 'Manual mapping'),\n        ('ankylosing spondylitis', '239811003', 'Manual mapping'),\n        ('ankylosing spondylitis', '394990003', 'Manual mapping'),\n        ('ankylosing spondylitis', '429712009', 'Manual mapping'),\n        ('ankylosing spondylitis', '441562009', 'Manual mapping'),\n        ('ankylosing spondylitis', '441680005', 'Manual mapping'),\n        ('ankylosing spondylitis', '441930001', 'Manual mapping'),\n        ('axial spondyloarthritis', '723116002', 'Manual mapping'),\n        ('choroidal neovascularisation', '380621000000102', 'Manual mapping'),\n        ('choroidal neovascularisation', '733124000', 'Manual mapping')\n    ) AS t(Search_Term, SNOMEDCode, SNOMEDDescription)\n),\n\nAllIndicationCodes AS (\n    SELECT Search_Term, \"SNOMEDCode\" AS SNOMEDCode, \"SNOMEDDescription\" AS SNOMEDDescription\n    FROM ClusterCodes\n    UNION ALL\n    SELECT Search_Term, SNOMEDCode, SNOMEDDescription\n    FROM ExplicitCodes\n)\n\"\"\"\n\n\ndef get_patient_indication_groups(\n    patient_pseudonyms: list[str],\n    connector: Optional[SnowflakeConnector] = None,\n    batch_size: int = 500,\n) -> \"pd.DataFrame\":\n    \"\"\"\n    Batch lookup GP diagnosis-based indication groups using Snowflake cluster query.\n\n    This function queries Snowflake directly using the embedded cluster CTE\n    (from snomed_indication_mapping_query.sql) to find patients with matching\n    GP diagnoses. This is the NEW approach replacing the old SQLite-based lookup.\n\n    The query:\n    1. Uses the cluster mapping CTE to get all Search_Term -> SNOMED code mappings\n    2. Joins with PrimaryCareClinicalCoding to find patients with matching codes\n    3. Returns the most recent match per patient (by EventDateTime)\n\n    Args:\n        patient_pseudonyms: List of PseudoNHSNoLinked values (matches PatientPseudonym in GP records)\n        connector: Optional SnowflakeConnector (defaults to singleton)\n        batch_size: Number of patients per Snowflake query batch (default 500)\n\n    Returns:\n        DataFrame with columns:\n        - PatientPseudonym: The patient identifier (PseudoNHSNoLinked value)\n        - Search_Term: The matched indication (e.g., \"rheumatoid arthritis\")\n        - EventDateTime: Date of the GP diagnosis record\n\n        Patients not found in results have no matching GP diagnosis.\n    \"\"\"\n    import pandas as pd\n\n    logger.info(f\"Starting Snowflake-direct indication lookup for {len(patient_pseudonyms)} patients...\")\n\n    # Handle edge case: empty patient list\n    if not patient_pseudonyms:\n        logger.warning(\"Empty patient list provided\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    # Check Snowflake availability\n    if not SNOWFLAKE_AVAILABLE:\n        logger.error(\"Snowflake connector not available - cannot lookup GP records\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    if not is_snowflake_configured():\n        logger.error(\"Snowflake not configured - cannot lookup GP records\")\n        return pd.DataFrame(columns=['PatientPseudonym', 'Search_Term', 'EventDateTime'])\n\n    if connector is None:\n        connector = get_connector()\n\n    # Results list to collect all matches\n    all_results: list[dict] = []\n\n    # Process patients in batches\n    total_patients = len(patient_pseudonyms)\n    for batch_start in range(0, total_patients, batch_size):\n        batch_end = min(batch_start + batch_size, total_patients)\n        batch_pseudonyms = patient_pseudonyms[batch_start:batch_end]\n        batch_num = batch_start // batch_size + 1\n        total_batches = (total_patients + batch_size - 1) // batch_size\n\n        logger.info(f\"Batch {batch_num}/{total_batches}: patients {batch_start + 1} to {batch_end}\")\n\n        # Build patient IN clause placeholders\n        patient_placeholders = \", \".join([\"%s\"] * len(batch_pseudonyms))\n\n        # Build the full query with cluster CTE\n        # This finds the most recent matching diagnosis for each patient\n        # Note: Column names must be aliased to ensure consistent casing in results\n        query = f\"\"\"\n{CLUSTER_MAPPING_SQL}\nSELECT\n    pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n    aic.Search_Term AS \"Search_Term\",\n    pc.\"EventDateTime\" AS \"EventDateTime\"\nFROM DATA_HUB.PHM.\"PrimaryCareClinicalCoding\" pc\nINNER JOIN AllIndicationCodes aic\n    ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\nWHERE pc.\"PatientPseudonym\" IN ({patient_placeholders})\nQUALIFY ROW_NUMBER() OVER (\n    PARTITION BY pc.\"PatientPseudonym\"\n    ORDER BY pc.\"EventDateTime\" DESC\n) = 1\n\"\"\"\n\n        try:\n            results = connector.execute_dict(query, tuple(batch_pseudonyms))\n\n            for row in results:\n                all_results.append({\n                    'PatientPseudonym': row.get('PatientPseudonym'),\n                    'Search_Term': row.get('Search_Term'),\n                    'EventDateTime': row.get('EventDateTime'),\n                })\n\n            logger.debug(f\"Batch {batch_num}: found {len(results)} matches\")\n\n        except Exception as e:\n            logger.error(f\"Error querying GP records for batch {batch_num}: {e}\")\n            # Continue with other batches - partial results are better than none\n\n    # Build result DataFrame\n    result_df = pd.DataFrame(all_results)\n\n    # Log summary statistics\n    if len(result_df) > 0:\n        matched_count = len(result_df)\n        match_rate = 100 * matched_count / total_patients\n        unique_terms = result_df['Search_Term'].nunique()\n        logger.info(f\"Indication lookup complete:\")\n        logger.info(f\"  Total patients queried: {total_patients}\")\n        logger.info(f\"  Patients with GP match: {matched_count} ({match_rate:.1f}%)\")\n        logger.info(f\"  Unique Search_Terms found: {unique_terms}\")\n\n        # Log top Search_Terms\n        top_terms = result_df['Search_Term'].value_counts().head(5)\n        logger.info(f\"  Top 5 indications: {dict(top_terms)}\")\n    else:\n        logger.info(f\"Indication lookup complete: 0 matches from {total_patients} patients\")\n\n    return result_df\n\n\n# Export public API\n__all__ = [\n    # Dataclasses\n    \"ClusterSnomedCodes\",\n    \"IndicationValidationResult\",\n    \"DrugIndicationMatchRate\",\n    \"DrugSnomedMapping\",\n    \"DirectSnomedMatchResult\",\n    \"DirectorateAssignment\",\n    # Cluster-based lookup functions (existing)\n    \"get_drug_clusters\",\n    \"get_drug_cluster_ids\",\n    \"get_cluster_snomed_codes\",\n    \"patient_has_indication\",\n    \"validate_indication\",\n    \"get_indication_match_rate\",\n    \"batch_validate_indications\",\n    \"get_available_clusters\",\n    # Direct SNOMED lookup functions (new)\n    \"get_drug_snomed_codes\",\n    \"patient_has_indication_direct\",\n    # Diagnosis-based directorate assignment\n    \"get_directorate_from_diagnosis\",\n    # Batch lookup for indication groups\n    \"batch_lookup_indication_groups\",\n    # Snowflake-direct indication lookup (new approach)\n    \"get_patient_indication_groups\",\n    \"CLUSTER_MAPPING_SQL\",\n]\n","structuredPatch":[{"oldStart":1529,"oldLines":6,"newStart":1529,"newLines":9,"lines":["     \"get_directorate_from_diagnosis\",","     # Batch lookup for indication groups","     \"batch_lookup_indication_groups\",","+    # Drug-indication mapping from DimSearchTerm.csv","+    \"load_drug_indication_mapping\",","+    \"get_search_terms_for_drug\",","     # Snowflake-direct indication lookup (new approach)","     \"get_patient_indication_groups\",","     \"CLUSTER_MAPPING_SQL\","]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015xf9qpgHDjqtN4jZgDBxzd","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me validate the code. First a syntax check, then import check, then a functionality test."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":315,"cache_read_input_tokens":108994,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":315},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"4b05599a-5f6c-4a79-b640-789f614b9336"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015xf9qpgHDjqtN4jZgDBxzd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SBtaiGYk19X2ZVWLATjGvk","name":"TodoWrite","input":{"todos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"in_progress","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"pending","activeForm":"Updating progress and committing changes"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":315,"cache_read_input_tokens":108994,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":315},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"763c1602-de88-478b-ab36-e46ac6207555"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SBtaiGYk19X2ZVWLATjGvk","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"41a0cf01-8d7f-4402-82fc-d742860c55f4","tool_use_result":{"oldTodos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"in_progress","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"pending","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"pending","activeForm":"Updating progress and committing changes"}],"newTodos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"in_progress","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"pending","activeForm":"Updating progress and committing changes"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01HJC2oQwwmJZ1fQ59PwznuW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015XThAtXRyzwjtpcSUwAqtp","name":"Bash","input":{"command":"cd \"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\" && python -m py_compile data_processing/diagnosis_lookup.py","description":"Syntax check diagnosis_lookup.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":242,"cache_read_input_tokens":109309,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":242},"output_tokens":26,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"855249df-ef6c-42cc-881d-6486e564c351"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015XThAtXRyzwjtpcSUwAqtp","type":"tool_result","content":"","is_error":false}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"43ce97a9-3717-468d-898b-48026eec5825","tool_use_result":{"stdout":"","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_013NAfSkaK3aMEfSP2ix6NuD","type":"message","role":"assistant","content":[{"type":"text","text":"Syntax check passed. Now import check."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":138,"cache_read_input_tokens":109551,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":138},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"16bd2beb-1fb5-446f-a039-c050da682e1a"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_013NAfSkaK3aMEfSP2ix6NuD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01FrnAmtaaVMk7mffMN9ijBz","name":"Bash","input":{"command":"cd \"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\" && python -c \"from data_processing.diagnosis_lookup import load_drug_indication_mapping, get_search_terms_for_drug; print('Import OK')\"","description":"Import check for new functions"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":138,"cache_read_input_tokens":109551,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":138},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"3d819324-707c-492a-b332-83477010ea1e"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01FrnAmtaaVMk7mffMN9ijBz","type":"tool_result","content":"Import OK","is_error":false}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"65003e45-b32a-4e9a-a784-fad73f24f63f","tool_use_result":{"stdout":"Import OK\r","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01GCjuV7rYKt7NfmCYMssErC","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me run a functionality test to verify the mapping loads correctly and drug matching works."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":155,"cache_read_input_tokens":109689,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":155},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"85b4c9f6-ef58-427c-ba01-7b56ac833709"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01GCjuV7rYKt7NfmCYMssErC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014KUTQcBtTvyT7n71WcLfr1","name":"Bash","input":{"command":"cd \"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\" && python -c \"\nfrom data_processing.diagnosis_lookup import load_drug_indication_mapping, get_search_terms_for_drug\n\nfrag_to_st, st_to_frag = load_drug_indication_mapping()\n\nprint(f'Search_Terms: {len(st_to_frag)}')\nprint(f'Drug fragments: {len(frag_to_st)}')\n\n# Test: ADALIMUMAB should match several indications\nada_matches = get_search_terms_for_drug('ADALIMUMAB', st_to_frag)\nprint(f'\\nADALIMUMAB matches ({len(ada_matches)}): {sorted(ada_matches)}')\n\n# Test: OMALIZUMAB should match asthma-related\noma_matches = get_search_terms_for_drug('OMALIZUMAB', st_to_frag)\nprint(f'\\nOMALIZUMAB matches ({len(oma_matches)}): {sorted(oma_matches)}')\n\n# Test: Substring matching - PEGYLATED LIPOSOMAL DOXORUBICIN should match entries with PEGYLATED\npeg_matches = get_search_terms_for_drug('PEGYLATED LIPOSOMAL DOXORUBICIN', st_to_frag)\nprint(f'\\nPEGYLATED LIPOSOMAL DOXORUBICIN matches ({len(peg_matches)}): {sorted(peg_matches)}')\n\n# Test: Drug with dosage info\nada40_matches = get_search_terms_for_drug('ADALIMUMAB 40MG', st_to_frag)\nprint(f'\\nADALIMUMAB 40MG matches ({len(ada40_matches)}): {sorted(ada40_matches)}')\n\n# Test: Verify diabetes appears once (combined from two rows)\nprint(f'\\nDiabetes fragments: {st_to_frag.get(\\\"diabetes\\\", [])}')\n\n# Test: Verify reverse lookup\nprint(f'\\nADALIMUMAB fragment maps to: {frag_to_st.get(\\\"ADALIMUMAB\\\", [])}')\n\"\n","description":"Functionality test for drug-indication mapping"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":155,"cache_read_input_tokens":109689,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":155},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"c24ef622-3cee-43be-b6fd-98f6da4b338f"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014KUTQcBtTvyT7n71WcLfr1","type":"tool_result","content":"Search_Terms: 164\r\nDrug fragments: 346\r\n\r\nADALIMUMAB matches (7): ['ankylosing spondylitis', 'axial spondyloarthritis', 'plaque psoriasis', 'psoriatic arthritis', 'rheumatoid arthritis', 'ulcerative colitis', 'uveitis']\r\n\r\nOMALIZUMAB matches (4): ['allergic asthma', 'asthma', 'severe persistent allergic asthma', 'urticaria']\r\n\r\nPEGYLATED LIPOSOMAL DOXORUBICIN matches (4): ['acute myeloid leukaemia', 'hepatitis c', 'ovarian cancer', 'pancreatic cancer']\r\n\r\nADALIMUMAB 40MG matches (7): ['ankylosing spondylitis', 'axial spondyloarthritis', 'plaque psoriasis', 'psoriatic arthritis', 'rheumatoid arthritis', 'ulcerative colitis', 'uveitis']\r\n\r\nDiabetes fragments: ['ERTUGLIFLOZIN', 'INHALED', 'AFLIBERCEPT', 'BROLUCIZUMAB', 'DEXAMETHASONE', 'FARICIMAB', 'FLUOCINOLONE', 'RANIBIZUMAB']\r\n\r\nADALIMUMAB fragment maps to: ['ankylosing spondylitis', 'axial spondyloarthritis', 'plaque psoriasis', 'psoriatic arthritis', 'rheumatoid arthritis', 'ulcerative colitis', 'uveitis']","is_error":false}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"7ea36131-6b4e-4c2a-a53e-dcf883813917","tool_use_result":{"stdout":"Search_Terms: 164\r\nDrug fragments: 346\r\n\r\nADALIMUMAB matches (7): ['ankylosing spondylitis', 'axial spondyloarthritis', 'plaque psoriasis', 'psoriatic arthritis', 'rheumatoid arthritis', 'ulcerative colitis', 'uveitis']\r\n\r\nOMALIZUMAB matches (4): ['allergic asthma', 'asthma', 'severe persistent allergic asthma', 'urticaria']\r\n\r\nPEGYLATED LIPOSOMAL DOXORUBICIN matches (4): ['acute myeloid leukaemia', 'hepatitis c', 'ovarian cancer', 'pancreatic cancer']\r\n\r\nADALIMUMAB 40MG matches (7): ['ankylosing spondylitis', 'axial spondyloarthritis', 'plaque psoriasis', 'psoriatic arthritis', 'rheumatoid arthritis', 'ulcerative colitis', 'uveitis']\r\n\r\nDiabetes fragments: ['ERTUGLIFLOZIN', 'INHALED', 'AFLIBERCEPT', 'BROLUCIZUMAB', 'DEXAMETHASONE', 'FARICIMAB', 'FLUOCINOLONE', 'RANIBIZUMAB']\r\n\r\nADALIMUMAB fragment maps to: ['ankylosing spondylitis', 'axial spondyloarthritis', 'plaque psoriasis', 'psoriatic arthritis', 'rheumatoid arthritis', 'ulcerative colitis', 'uveitis']\r","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01AxMSgkr7LBogAcn89u3yJ9","type":"message","role":"assistant","content":[{"type":"text","text":"All tests pass:\n\n- **164 Search_Terms** loaded (close to expected ~165 ÔÇö the slightly lower count is because `diabetes` appears twice with different directorates but is correctly combined into one entry)\n- **346 drug fragments** loaded\n- **ADALIMUMAB** correctly matches 7 indications (rheumatoid arthritis, plaque psoriasis, etc.)\n- **OMALIZUMAB** matches 4 asthma/urticaria-related indications  \n- **Substring matching works**: \"PEGYLATED LIPOSOMAL DOXORUBICIN\" matches via the \"PEGYLATED\" fragment\n- **Drug name with dosage works**: \"ADALIMUMAB 40MG\" matches the same 7 indications as plain \"ADALIMUMAB\"\n- **Duplicate Search_Term handling works**: `diabetes` drug fragments combined from both CSV rows\n- **Reverse lookup works**: `ADALIMUMAB` fragment correctly maps back to all 7 Search_Terms\n\nNote the PEGYLATED match includes hepatitis c and acute myeloid leukaemia ÔÇö these broad fragments will be constrained by the GP diagnosis requirement in Phase 2 (a patient must have GP dx for the condition AND the drug must be listed for that condition). This is exactly as designed.\n\nLet me also verify the IMPLEMENTATION_PLAN.md subtasks for 1.2:\n\n1. `load_drug_indication_mapping()` ÔÇö Done, builds both dicts\n2. `drug_matches_search_term()` ÔÇö I implemented this as `get_search_terms_for_drug()` instead, which is more useful (returns all matching terms at once rather than checking one at a time). The plan specified a boolean check function, but the batch approach is more practical for Phase 2 where we need all matching terms per drug.\n3. Verify: ADALIMUMAB matches \"axial spondyloarthritis\" ÔÇö Confirmed. OMALIZUMAB matches \"asthma\" ÔÇö Confirmed.\n\nNow let me mark the subtasks complete and update IMPLEMENTATION_PLAN.md."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1047,"cache_read_input_tokens":109844,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1047},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"f6143554-9d08-499f-a56e-29cdbd8340c2"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01AxMSgkr7LBogAcn89u3yJ9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GgCpueZbmABk9ZJn2AUCjD","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md","old_string":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [~] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`\n  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n- [ ] Add function `drug_matches_search_term(drug_name: str, search_term: str, mapping: dict) -> bool`:\n  - Checks if the drug name matches any fragment in the Search_Term's drug list\n  - Match logic: any fragment from DimSearchTerm is a substring of the drug name (case-insensitive)\n- [ ] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"","new_string":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [x] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`\n  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n- [x] Add function `get_search_terms_for_drug(drug_name, search_term_to_fragments) -> list[str]`:\n  - Returns all Search_Terms whose drug fragments are substrings of the drug name (case-insensitive)\n  - More practical than per-term boolean check ÔÇö returns all matches at once for Phase 2 use\n- [x] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\""}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1047,"cache_read_input_tokens":109844,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1047},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"ab071359-6140-406b-a7fe-a4c475aad494"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GgCpueZbmABk9ZJn2AUCjD","type":"tool_result","content":"The file C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"fb89b948-e9ae-4c3d-8761-7e246b8a7a8f","tool_use_result":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\IMPLEMENTATION_PLAN.md","oldString":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [~] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`\n  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n- [ ] Add function `drug_matches_search_term(drug_name: str, search_term: str, mapping: dict) -> bool`:\n  - Checks if the drug name matches any fragment in the Search_Term's drug list\n  - Match logic: any fragment from DimSearchTerm is a substring of the drug name (case-insensitive)\n- [ ] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"","newString":"### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [x] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`\n  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n- [x] Add function `get_search_terms_for_drug(drug_name, search_term_to_fragments) -> list[str]`:\n  - Returns all Search_Terms whose drug fragments are substrings of the drug name (case-insensitive)\n  - More practical than per-term boolean check ÔÇö returns all matches at once for Phase 2 use\n- [x] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"","originalFile":"# Implementation Plan - Drug-Aware Indication Matching\n\n## Project Overview\n\nUpdate the indication-based pathway charts so that patient indications are matched **per drug**, not just per patient. Currently, each patient gets ONE indication (most recent GP diagnosis match). This ignores which drugs the patient is actually taking.\n\n### The Problem\n\nA patient on ADALIMUMAB + OMALIZUMAB currently gets assigned a single indication (e.g., \"rheumatoid arthritis\" ÔÇö the most recent GP match). But:\n- ADALIMUMAB is used for rheumatoid arthritis, axial spondyloarthritis, crohn's disease, etc.\n- OMALIZUMAB is used for asthma, allergic asthma, urticaria\n\nThese are different clinical pathways and should be treated as separate treatment journeys.\n\n### The Solution\n\nMatch each drug to an indication by cross-referencing:\n1. **GP diagnosis** ÔÇö which Search_Terms the patient has matching SNOMED codes for\n2. **Drug mapping** ÔÇö which Search_Terms list each drug (from `DimSearchTerm.csv`)\n\nOnly assign a drug to an indication if BOTH conditions are met. If a patient's drugs map to different indications, they become separate pathways (via modified UPID).\n\n### Key Design Decisions\n\n| Aspect | Decision |\n|--------|----------|\n| Drug-indication source | `data/DimSearchTerm.csv` ÔÇö Search_Term ÔåÆ CleanedDrugName mapping |\n| UPID modification | `{original_UPID}\\|{search_term}` for drugs with matched indication |\n| GP diagnosis matching | Return ALL matches per patient (not just most recent) |\n| Drug matching | Substring match: HCD drug name contains DimSearchTerm fragment |\n| Multiple indication matches per drug | Use highest GP code frequency as tiebreaker (COUNT of matching SNOMED codes per Search_Term) |\n| GP code time range | Only codes from MIN(Intervention Date) onwards ÔÇö restricts to HCD data window |\n| No indication match | Fallback to directory (same as current behavior) |\n| Same patient, different indications | Separate pathways via different modified UPIDs |\n\n### Examples\n\n**Patient on ADALIMUMAB + GOLIMUMAB, GP dx: axial spondyloarthritis + asthma**\n- axial spondyloarthritis drug list includes both ADALIMUMAB and GOLIMUMAB\n- ÔåÆ Both drugs grouped under \"axial spondyloarthritis\", single pathway\n- Modified UPID: `RMV12345|axial spondyloarthritis`\n\n**Patient on ADALIMUMAB + OMALIZUMAB, GP dx: axial spondyloarthritis + asthma**\n- axial spondyloarthritis lists ADALIMUMAB but not OMALIZUMAB\n- asthma lists OMALIZUMAB but not ADALIMUMAB\n- ÔåÆ Two separate pathways:\n  - `RMV12345|axial spondyloarthritis` with ADALIMUMAB\n  - `RMV12345|asthma` with OMALIZUMAB\n\n**Patient on ADALIMUMAB, GP dx: rheumatoid arthritis (47 codes) + crohn's disease (2 codes)**\n- Both Search_Terms list ADALIMUMAB AND patient has GP dx for both\n- ÔåÆ Tiebreaker: highest code frequency ÔÇö rheumatoid arthritis has 47 matching SNOMED codes vs 2 for crohn's\n- ÔåÆ Single pathway under rheumatoid arthritis (more clinical activity = more likely the treatment indication)\n\n---\n\n## Phase 1: Update Snowflake Query & Drug Mapping\n\n### 1.1 Update `get_patient_indication_groups()` to return ALL matches with frequency\n- [ ] Modify the Snowflake query in `get_patient_indication_groups()` (diagnosis_lookup.py):\n  - Remove `QUALIFY ROW_NUMBER() OVER (PARTITION BY ... ORDER BY EventDateTime DESC) = 1`\n  - Return ALL matching Search_Terms per patient with code frequency:\n    ```sql\n    SELECT pc.\"PatientPseudonym\" AS \"PatientPseudonym\",\n           aic.Search_Term AS \"Search_Term\",\n           COUNT(*) AS \"code_frequency\"\n    FROM PrimaryCareClinicalCoding pc\n    JOIN AllIndicationCodes aic ON pc.\"SNOMEDCode\" = aic.SNOMEDCode\n    WHERE pc.\"PatientPseudonym\" IN (...)\n      AND pc.\"EventDateTime\" >= :earliest_hcd_date\n    GROUP BY pc.\"PatientPseudonym\", aic.Search_Term\n    ```\n  - `code_frequency` = number of matching SNOMED codes per Search_Term per patient\n  - Higher frequency = more clinical activity = stronger signal for tiebreaker\n  - `earliest_hcd_date` = `MIN(Intervention Date)` from the HCD DataFrame ÔÇö restricts GP codes to the HCD data window, reducing noise from old/irrelevant diagnoses\n- [ ] Accept `earliest_hcd_date` parameter in `get_patient_indication_groups()` and pass to query\n- [ ] Keep batch processing (500 patients per query)\n- [ ] Update return type: DataFrame now has multiple rows per patient (PatientPseudonym, Search_Term, code_frequency)\n- [ ] Verify: Query returns more rows than before (patients with multiple matching diagnoses)\n\n### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv\n- [~] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`\n  - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`\n  - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`\n  - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")\n- [ ] Add function `drug_matches_search_term(drug_name: str, search_term: str, mapping: dict) -> bool`:\n  - Checks if the drug name matches any fragment in the Search_Term's drug list\n  - Match logic: any fragment from DimSearchTerm is a substring of the drug name (case-insensitive)\n- [ ] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"\n\n---\n\n## Phase 2: Drug-Aware Indication Matching Logic\n\n### 2.1 Create `assign_drug_indications()` function\n- [ ] Add to `diagnosis_lookup.py` or `pathway_pipeline.py`:\n  ```\n  def assign_drug_indications(\n      df: pd.DataFrame,              # HCD data with UPID, Drug Name columns\n      gp_matches_df: pd.DataFrame,   # PatientPseudonym ÔåÆ list of matched Search_Terms\n      drug_mapping: dict,             # From load_drug_indication_mapping()\n  ) -> tuple[pd.DataFrame, pd.DataFrame]:\n      Returns: (modified_df, indication_df)\n      - modified_df: HCD data with UPID replaced by {UPID}|{indication}\n      - indication_df: mapping modified_UPID ÔåÆ Search_Term\n  ```\n- [ ] Logic per UPID + Drug Name pair:\n  1. Get patient's GP-matched Search_Terms with code_frequency (from gp_matches_df via PseudoNHSNoLinked)\n  2. Get which Search_Terms include this drug (from drug_mapping)\n  3. Intersection = valid indications for this drug-patient pair\n  4. If 1 match: use it\n  5. If multiple matches: use highest code_frequency as tiebreaker (most GP coding activity = most likely treatment indication)\n  6. If 0 matches: use fallback directory\n- [ ] Modify UPID in df rows: `{original_UPID}|{matched_search_term}`\n- [ ] Build indication_df: `{modified_UPID}` ÔåÆ `Search_Term` (or fallback label)\n- [ ] Verify: Function compiles, handles edge cases (no GP match, no drug match)\n\n### 2.2 Handle tiebreaker for multiple indication matches\n- [ ] When a drug matches multiple Search_Terms AND patient has GP dx for multiple:\n  - Use `code_frequency` from the GP query (COUNT of matching SNOMED codes per Search_Term)\n  - Higher code_frequency = more clinical activity for that condition = more likely treatment indication\n  - E.g., patient with 47 RA codes and 2 crohn's codes ÔåÆ ADALIMUMAB assigned to RA\n  - code_frequency is already returned by the updated query in Task 1.1\n- [ ] Verify: Tiebreaker logic correctly picks highest-frequency diagnosis\n- [ ] Verify: Tie on frequency (rare but possible) falls back to alphabetical Search_Term for determinism\n\n---\n\n## Phase 3: Pipeline Integration\n\n### 3.1 Update `refresh_pathways.py` indication processing\n- [ ] In the `elif current_chart_type == \"indication\":` block:\n  1. Call `get_patient_indication_groups()` as before (but now returns ALL matches)\n  2. Load drug mapping: `drug_mapping = load_drug_indication_mapping()`\n  3. Call `assign_drug_indications(df, gp_matches_df, drug_mapping)`\n  4. Use modified_df (with indication-aware UPIDs) for pathway processing\n  5. Use indication_df for the indication mapping\n- [ ] Pass modified_df (not original df) to `process_indication_pathway_for_date_filter()`\n- [ ] Verify: Pipeline compiles, `python -m py_compile cli/refresh_pathways.py`\n\n### 3.2 Test with dry run\n- [ ] Run `python -m cli.refresh_pathways --chart-type indication --dry-run -v`\n- [ ] Verify:\n  - Modified UPIDs appear in pipeline log (e.g., `RMV12345|rheumatoid arthritis`)\n  - Patient counts are reasonable (will be higher than before since same patient can appear under multiple indications)\n  - Drug-indication matching is logged (match rate, fallback rate)\n  - Pathway hierarchy shows drug-specific grouping under correct indications\n\n---\n\n## Phase 4: Full Refresh & Validation\n\n### 4.1 Full refresh with both chart types\n- [ ] Run `python -m cli.refresh_pathways --chart-type all`\n- [ ] Verify:\n  - Both chart types generate data\n  - Directory charts unchanged (no modified UPIDs)\n  - Indication charts reflect drug-aware matching\n\n### 4.2 Validate indication chart correctness\n- [ ] Check that drugs under an indication all appear in that Search_Term's drug list\n- [ ] Verify that a patient on drugs for different indications creates separate pathway branches\n- [ ] Verify that drugs sharing an indication are grouped in the same pathway\n- [ ] Log: patient count comparison (old vs new approach)\n\n### 4.3 Validate Reflex UI\n- [ ] Run `python -m reflex compile` to verify app compiles\n- [ ] Verify chart type toggle still works\n- [ ] Verify indication chart shows correct hierarchy\n\n---\n\n## Completion Criteria\n\nAll tasks marked `[x]` AND:\n- [ ] App compiles without errors (`reflex compile` succeeds)\n- [ ] Both chart types generate pathway data\n- [ ] Indication charts show drug-specific indication matching\n- [ ] Drugs under the same indication for the same patient are in one pathway\n- [ ] Drugs under different indications for the same patient create separate pathways\n- [ ] Fallback works for drugs with no indication match\n- [ ] Full refresh completes successfully\n- [ ] Existing directory charts are unaffected\n\n---\n\n## Reference\n\n### DimSearchTerm.csv Structure\n```\nSearch_Term,CleanedDrugName,PrimaryDirectorate\nrheumatoid arthritis,ABATACEPT|ADALIMUMAB|ANAKINRA|BARICITINIB|...,RHEUMATOLOGY\nasthma,BENRALIZUMAB|DUPILUMAB|INHALED|MEPOLIZUMAB|OMALIZUMAB|RESLIZUMAB,THORACIC MEDICINE\n```\n\n### Modified UPID Format\n```\nOriginal:  RMV12345\nModified:  RMV12345|rheumatoid arthritis\nFallback:  RMV12345|RHEUMATOLOGY (no GP dx)\n```\n\n### Current vs New Indication Flow\n```\nCURRENT:\n  Patient ÔåÆ GP dx (most recent) ÔåÆ single Search_Term ÔåÆ one pathway\n\nNEW:\n  Patient + Drug A ÔåÆ GP dx matching Drug A ÔåÆ Search_Term X\n  Patient + Drug B ÔåÆ GP dx matching Drug B ÔåÆ Search_Term Y\n  ÔåÆ If X == Y: one pathway under X\n  ÔåÆ If X != Y: two pathways (modified UPIDs)\n```\n\n### Key Files\n\n| File | Changes |\n|------|---------|\n| `data_processing/diagnosis_lookup.py` | Update query, add drug mapping functions |\n| `data_processing/pathway_pipeline.py` | Possibly minor changes for modified UPIDs |\n| `cli/refresh_pathways.py` | Integrate drug-aware matching into pipeline |\n| `data/DimSearchTerm.csv` | Reference data (read-only) |\n| `analysis/pathway_analyzer.py` | No changes expected (UPID changes are transparent) |\n| `pathways_app/pathways_app.py` | No changes expected |\n","structuredPatch":[{"oldStart":79,"oldLines":15,"newStart":79,"newLines":15,"lines":[" - [ ] Verify: Query returns more rows than before (patients with multiple matching diagnoses)"," "," ### 1.2 Build drug-to-Search_Term lookup from DimSearchTerm.csv","-- [~] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","+- [x] Add function `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","   - Loads `data/DimSearchTerm.csv`","   - Builds dict: `drug_fragment (uppercase) ÔåÆ list[Search_Term]`","   - Also builds reverse: `search_term ÔåÆ list[drug_fragments]`","   - CleanedDrugName is pipe-separated (e.g., \"ADALIMUMAB|GOLIMUMAB|IXEKIZUMAB\")","-- [ ] Add function `drug_matches_search_term(drug_name: str, search_term: str, mapping: dict) -> bool`:","-  - Checks if the drug name matches any fragment in the Search_Term's drug list","-  - Match logic: any fragment from DimSearchTerm is a substring of the drug name (case-insensitive)","-- [ ] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\"","+- [x] Add function `get_search_terms_for_drug(drug_name, search_term_to_fragments) -> list[str]`:","+  - Returns all Search_Terms whose drug fragments are substrings of the drug name (case-insensitive)","+  - More practical than per-term boolean check ÔÇö returns all matches at once for Phase 2 use","+- [x] Verify: ADALIMUMAB matches \"axial spondyloarthritis\", OMALIZUMAB matches \"asthma\""," "," ---"," "]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WUGzjfokDZCBJgrRUtSmPV","type":"message","role":"assistant","content":[{"type":"text","text":"Now commit, then update progress.txt."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1184,"cache_read_input_tokens":110891,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1184},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"8d01cea1-7b4f-4ef4-a9f8-ea10604d6685"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WUGzjfokDZCBJgrRUtSmPV","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01T4XoS6aRJsqjTiP218qcCD","name":"TodoWrite","input":{"todos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"completed","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"in_progress","activeForm":"Updating progress and committing changes"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1184,"cache_read_input_tokens":110891,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1184},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"2dca73a4-ef1c-4da6-a5de-0fd96219bda9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01T4XoS6aRJsqjTiP218qcCD","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"aa08cad8-4dc8-4f3c-8347-e19ef62281ec","tool_use_result":{"oldTodos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"in_progress","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"pending","activeForm":"Updating progress and committing changes"}],"newTodos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"completed","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"in_progress","activeForm":"Updating progress and committing changes"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01YLhAG3LGzKnqY3ijxA4Vc1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WAwPK1mdu7uEWGNsBqYNTC","name":"Bash","input":{"command":"cd \"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\" && git add data_processing/diagnosis_lookup.py IMPLEMENTATION_PLAN.md && git status","description":"Stage changed files for commit"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":230,"cache_read_input_tokens":112075,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":230},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"67e70069-c939-49b8-bcd2-db9af8e1b072"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WAwPK1mdu7uEWGNsBqYNTC","type":"tool_result","content":"On branch feature/snomed-indication-mapping\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n\tmodified:   IMPLEMENTATION_PLAN.md\n\tmodified:   data_processing/diagnosis_lookup.py\n\nChanges not staged for commit:\n  (use \"git add/rm <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   .claude/settings.local.json\n\tmodified:   DESIGN_SYSTEM.md\n\tmodified:   RALPH_PROMPT.md\n\tmodified:   guardrails.md\n\tmodified:   pathways_app/__init__.py\n\tdeleted:    pathways_app/app_v2.py\n\tmodified:   progress.txt\n\tmodified:   ralph.ps1\n\tmodified:   uv.lock\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tdata/DimSearchTerm.csv\n\tdata/LookupSearchTermCleanedDrugName.csv\n\tdata/condition_directorate_mapping.csv\n\tdata/drug_indication_clusters.csv\n\tdata/drug_snomed_mapping_enriched.csv\n\tdata/na_directory_rows.csv\n\tpathways_app/pathways_app_old.py.bak\n\tsnomed_indication_mapping_query.sql","is_error":false}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"b5f149b7-f252-4356-bcc2-0b5259bc0f63","tool_use_result":{"stdout":"On branch feature/snomed-indication-mapping\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n\tmodified:   IMPLEMENTATION_PLAN.md\n\tmodified:   data_processing/diagnosis_lookup.py\n\nChanges not staged for commit:\n  (use \"git add/rm <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   .claude/settings.local.json\n\tmodified:   DESIGN_SYSTEM.md\n\tmodified:   RALPH_PROMPT.md\n\tmodified:   guardrails.md\n\tmodified:   pathways_app/__init__.py\n\tdeleted:    pathways_app/app_v2.py\n\tmodified:   progress.txt\n\tmodified:   ralph.ps1\n\tmodified:   uv.lock\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\tdata/DimSearchTerm.csv\n\tdata/LookupSearchTermCleanedDrugName.csv\n\tdata/condition_directorate_mapping.csv\n\tdata/drug_indication_clusters.csv\n\tdata/drug_snomed_mapping_enriched.csv\n\tdata/na_directory_rows.csv\n\tpathways_app/pathways_app_old.py.bak\n\tsnomed_indication_mapping_query.sql\r","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01E1qqo8SGzbdkxE9muNv398","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013Gb83Zr7XeLAyW9s1Hqs17","name":"Bash","input":{"command":"cd \"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\" && git commit -m \"$(cat <<'EOF'\nfeat: add drug-to-indication mapping from DimSearchTerm.csv (Task 1.2)\n\nAdd load_drug_indication_mapping() and get_search_terms_for_drug() to\ndiagnosis_lookup.py. Loads DimSearchTerm.csv to build bidirectional\nlookup between drug name fragments and Search_Terms. Uses substring\nmatching for drug fragments (handles both exact names like ADALIMUMAB\nand partial fragments like PEGYLATED). Handles duplicate Search_Terms\n(e.g., diabetes appearing under two directorates) by combining fragments.\nEOF\n)\"","description":"Commit Task 1.2 implementation"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":468,"cache_read_input_tokens":112305,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":468},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"494febc4-facc-4d54-809a-c3ea3a411bf0"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013Gb83Zr7XeLAyW9s1Hqs17","type":"tool_result","content":"[feature/snomed-indication-mapping 0779df7] feat: add drug-to-indication mapping from DimSearchTerm.csv (Task 1.2)\n 2 files changed, 286 insertions(+), 212 deletions(-)","is_error":false}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"27cdcab7-171b-423b-9cf6-b1fc88417a0f","tool_use_result":{"stdout":"[feature/snomed-indication-mapping 0779df7] feat: add drug-to-indication mapping from DimSearchTerm.csv (Task 1.2)\n 2 files changed, 286 insertions(+), 212 deletions(-)\r","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WSDpZhaxuV7mzEmD1xWNe4","type":"message","role":"assistant","content":[{"type":"text","text":"Good, committed as `0779df7`. Now update progress.txt."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":315,"cache_read_input_tokens":112773,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":315},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"275739d8-b764-4c75-8459-1c594282d014"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01WSDpZhaxuV7mzEmD1xWNe4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017WTgvzmVaRxSCeMsfJYVg5","name":"Edit","input":{"replace_all":false,"file_path":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\progress.txt","old_string":"## Iteration Log","new_string":"## Iteration Log\n\n## Iteration 1 ÔÇö 2026-02-05\n### Task: 1.2 ÔÇö Build drug-to-Search_Term lookup from DimSearchTerm.csv\n### Why this task:\n- First iteration, chose Phase 1 foundations. Task 1.2 (CSV loading) is self-contained and testable locally without Snowflake.\n- Task 1.1 (Snowflake query update) can't be verified without a live connection ÔÇö better to do 1.2 first.\n- Both 1.1 and 1.2 are independent, so order doesn't matter for dependencies.\n### Status: COMPLETE\n### What was done:\n- Added `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`, builds two dicts:\n    - `fragment_to_search_terms`: drug fragment (UPPER) ÔåÆ list of Search_Terms\n    - `search_term_to_fragments`: search_term ÔåÆ list of drug fragments (UPPER)\n  - Handles duplicate Search_Terms (e.g., \"diabetes\" rows combined)\n  - Result: 164 Search_Terms, 346 drug fragments\n- Added `get_search_terms_for_drug()` to `diagnosis_lookup.py`:\n  - Returns all Search_Terms whose drug fragments are substrings of the drug name (case-insensitive)\n  - Named differently from plan's `drug_matches_search_term()` ÔÇö returns all matches at once rather than single boolean, more practical for Phase 2\n- Updated `__all__` exports\n### Validation results:\n- Tier 1 (Code): py_compile passed, import check passed\n- Tier 2 (Data): ADALIMUMAB ÔåÆ 7 indications (including axial spondyloarthritis, rheumatoid arthritis), OMALIZUMAB ÔåÆ 4 indications (asthma, allergic asthma, etc.), PEGYLATED LIPOSOMAL DOXORUBICIN ÔåÆ 4 matches via substring, \"ADALIMUMAB 40MG\" matches correctly with dosage info, diabetes fragments combined from 2 CSV rows\n- Tier 3 (Functional): N/A (no UI changes)\n### Files changed:\n- data_processing/diagnosis_lookup.py (added load_drug_indication_mapping, get_search_terms_for_drug)\n- IMPLEMENTATION_PLAN.md (marked 1.2 subtasks [x])\n### Committed: 0779df7 \"feat: add drug-to-indication mapping from DimSearchTerm.csv (Task 1.2)\"\n### Patterns discovered:\n- DimSearchTerm.csv has 164 unique Search_Terms (not 165 as noted) because diabetes appears twice with different directorates but same Search_Term\n- Some drug fragments are very generic: INHALED, CONTINUOUS, ORAL, STANDARD-DOSE, INTRAVENOUS, PEGYLATED, ROUTINE, INDUCTION ÔÇö these will match broadly but are constrained by the GP diagnosis requirement in Phase 2\n- Function signatures for Phase 2: `get_search_terms_for_drug(drug_name, search_term_to_fragments)` returns list[str] ÔÇö use this to get candidate indications per drug\n### Next iteration should:\n- Work on Task 1.1: Update `get_patient_indication_groups()` to return ALL matches with code_frequency\n  - The current query at line ~1352 of diagnosis_lookup.py uses `QUALIFY ROW_NUMBER() OVER (PARTITION BY pc.\"PatientPseudonym\" ORDER BY pc.\"EventDateTime\" DESC) = 1` ÔÇö this must be replaced with GROUP BY + COUNT(*)\n  - Add `earliest_hcd_date` parameter to restrict GP codes to HCD data window\n  - Return columns: PatientPseudonym, Search_Term, code_frequency (not EventDateTime)\n- OR if Snowflake isn't available to test, skip to Task 2.1 (assign_drug_indications function) which can be built and tested with mock data\n### Blocked items:\n- None"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":315,"cache_read_input_tokens":112773,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":315},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"204f91c7-dee2-4056-999a-ea03513774aa"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017WTgvzmVaRxSCeMsfJYVg5","type":"tool_result","content":"The file C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\progress.txt has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"33d68632-21da-4c9a-a946-2d940d76e190","tool_use_result":{"filePath":"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\\progress.txt","oldString":"## Iteration Log","newString":"## Iteration Log\n\n## Iteration 1 ÔÇö 2026-02-05\n### Task: 1.2 ÔÇö Build drug-to-Search_Term lookup from DimSearchTerm.csv\n### Why this task:\n- First iteration, chose Phase 1 foundations. Task 1.2 (CSV loading) is self-contained and testable locally without Snowflake.\n- Task 1.1 (Snowflake query update) can't be verified without a live connection ÔÇö better to do 1.2 first.\n- Both 1.1 and 1.2 are independent, so order doesn't matter for dependencies.\n### Status: COMPLETE\n### What was done:\n- Added `load_drug_indication_mapping()` to `diagnosis_lookup.py`:\n  - Loads `data/DimSearchTerm.csv`, builds two dicts:\n    - `fragment_to_search_terms`: drug fragment (UPPER) ÔåÆ list of Search_Terms\n    - `search_term_to_fragments`: search_term ÔåÆ list of drug fragments (UPPER)\n  - Handles duplicate Search_Terms (e.g., \"diabetes\" rows combined)\n  - Result: 164 Search_Terms, 346 drug fragments\n- Added `get_search_terms_for_drug()` to `diagnosis_lookup.py`:\n  - Returns all Search_Terms whose drug fragments are substrings of the drug name (case-insensitive)\n  - Named differently from plan's `drug_matches_search_term()` ÔÇö returns all matches at once rather than single boolean, more practical for Phase 2\n- Updated `__all__` exports\n### Validation results:\n- Tier 1 (Code): py_compile passed, import check passed\n- Tier 2 (Data): ADALIMUMAB ÔåÆ 7 indications (including axial spondyloarthritis, rheumatoid arthritis), OMALIZUMAB ÔåÆ 4 indications (asthma, allergic asthma, etc.), PEGYLATED LIPOSOMAL DOXORUBICIN ÔåÆ 4 matches via substring, \"ADALIMUMAB 40MG\" matches correctly with dosage info, diabetes fragments combined from 2 CSV rows\n- Tier 3 (Functional): N/A (no UI changes)\n### Files changed:\n- data_processing/diagnosis_lookup.py (added load_drug_indication_mapping, get_search_terms_for_drug)\n- IMPLEMENTATION_PLAN.md (marked 1.2 subtasks [x])\n### Committed: 0779df7 \"feat: add drug-to-indication mapping from DimSearchTerm.csv (Task 1.2)\"\n### Patterns discovered:\n- DimSearchTerm.csv has 164 unique Search_Terms (not 165 as noted) because diabetes appears twice with different directorates but same Search_Term\n- Some drug fragments are very generic: INHALED, CONTINUOUS, ORAL, STANDARD-DOSE, INTRAVENOUS, PEGYLATED, ROUTINE, INDUCTION ÔÇö these will match broadly but are constrained by the GP diagnosis requirement in Phase 2\n- Function signatures for Phase 2: `get_search_terms_for_drug(drug_name, search_term_to_fragments)` returns list[str] ÔÇö use this to get candidate indications per drug\n### Next iteration should:\n- Work on Task 1.1: Update `get_patient_indication_groups()` to return ALL matches with code_frequency\n  - The current query at line ~1352 of diagnosis_lookup.py uses `QUALIFY ROW_NUMBER() OVER (PARTITION BY pc.\"PatientPseudonym\" ORDER BY pc.\"EventDateTime\" DESC) = 1` ÔÇö this must be replaced with GROUP BY + COUNT(*)\n  - Add `earliest_hcd_date` parameter to restrict GP codes to HCD data window\n  - Return columns: PatientPseudonym, Search_Term, code_frequency (not EventDateTime)\n- OR if Snowflake isn't available to test, skip to Task 2.1 (assign_drug_indications function) which can be built and tested with mock data\n### Blocked items:\n- None","originalFile":"# Progress Log - Drug-Aware Indication Matching\n\n## Project Context\n\nThis project extends the indication-based pathway charts (Phase 1-5 complete) with drug-aware matching.\n\n**Previous state**: Patients get ONE indication based on their most recent GP diagnosis match (SNOMED cluster codes). This ignores which drugs the patient is taking.\n\n**New goal**: Match each drug to an indication by cross-referencing the patient's GP diagnoses AND the drug's Search_Term mapping from DimSearchTerm.csv.\n\n## Key Data/Patterns\n\n### DimSearchTerm.csv\n- Located at `data/DimSearchTerm.csv`\n- Columns: Search_Term, CleanedDrugName (pipe-separated), PrimaryDirectorate\n- ~165 rows mapping clinical conditions to drug name fragments\n- Drug fragments are substrings that match standardized drug names from HCD data\n- Some entries have generic fragments: INHALED, CONTINUOUS, STANDARD-DOSE, PEGYLATED\n\n### Current get_patient_indication_groups() in diagnosis_lookup.py\n- Uses CLUSTER_MAPPING_SQL as CTE in Snowflake query\n- Returns ONLY the most recent match per patient (QUALIFY ROW_NUMBER() = 1)\n- Needs to return ALL matching Search_Terms per patient (remove QUALIFY)\n- Batches 500 patients per query\n\n### Modified UPID approach\n- Current: UPID = Provider Code[:3] + PersonKey (e.g., \"RMV12345\")\n- New: UPID = original + \"|\" + search_term (e.g., \"RMV12345|rheumatoid arthritis\")\n- The pipe delimiter \"|\" is safe because existing UPIDs are alphanumeric\n- generate_icicle_chart_indication() treats UPID as an opaque identifier ÔÇö modified UPIDs work transparently\n- The \" - \" delimiter in pathway ids is used for hierarchy levels, not within UPIDs\n\n### PseudoNHSNoLinked mapping\n- HCD data has PseudoNHSNoLinked column that matches PatientPseudonym in GP records\n- PersonKey is provider-specific local ID ÔÇö do NOT use for GP matching\n- One PseudoNHSNoLinked can map to multiple UPIDs (multi-provider patients)\n- GP match lookup: PseudoNHSNoLinked ÔåÆ list of matched Search_Terms\n\n### Drug matching logic\n- For each HCD row (UPID + Drug Name):\n  1. Get patient's GP-matched Search_Terms with code_frequency (via PseudoNHSNoLinked)\n  2. Get which Search_Terms list this drug (from DimSearchTerm.csv)\n  3. Intersection = valid indications\n  4. If 1: use it. If multiple: pick highest code_frequency (most GP coding = most likely indication). If 0: fallback to directory.\n- Modified UPID groups drugs under same indication together naturally\n- code_frequency = COUNT(*) of matching SNOMED codes per Search_Term per patient in GP records\n- GP code time range: only count codes from MIN(Intervention Date) onwards (the HCD data window)\n  - Reduces noise from old/irrelevant diagnoses, makes frequency more meaningful\n  - Pass earliest_hcd_date as parameter to get_patient_indication_groups()\n- Tiebreaker rationale: 47 RA codes vs 2 crohn's codes ÔåÆ RA is clearly the active condition\n\n### Known edge cases\n- Some DimSearchTerm drug fragments are generic (INHALED, ORAL, CONTINUOUS)\n  - These could match broadly but are constrained by GP diagnosis requirement\n- A patient visiting multiple providers has multiple UPIDs\n  - Each UPID gets its own drug-indication matching independently\n- Same Search_Term appears twice in DimSearchTerm.csv with different directorates\n  - e.g., \"diabetes\" ÔåÆ DIABETIC MEDICINE and OPHTHALMOLOGY\n  - For indication charts, we use Search_Term not directorate, so this is fine\n\n## Iteration Log\n","structuredPatch":[{"oldStart":59,"oldLines":3,"newStart":59,"newLines":42,"lines":["   - For indication charts, we use Search_Term not directorate, so this is fine"," "," ## Iteration Log","+","+## Iteration 1 ÔÇö 2026-02-05","+### Task: 1.2 ÔÇö Build drug-to-Search_Term lookup from DimSearchTerm.csv","+### Why this task:","+- First iteration, chose Phase 1 foundations. Task 1.2 (CSV loading) is self-contained and testable locally without Snowflake.","+- Task 1.1 (Snowflake query update) can't be verified without a live connection ÔÇö better to do 1.2 first.","+- Both 1.1 and 1.2 are independent, so order doesn't matter for dependencies.","+### Status: COMPLETE","+### What was done:","+- Added `load_drug_indication_mapping()` to `diagnosis_lookup.py`:","+  - Loads `data/DimSearchTerm.csv`, builds two dicts:","+    - `fragment_to_search_terms`: drug fragment (UPPER) ÔåÆ list of Search_Terms","+    - `search_term_to_fragments`: search_term ÔåÆ list of drug fragments (UPPER)","+  - Handles duplicate Search_Terms (e.g., \"diabetes\" rows combined)","+  - Result: 164 Search_Terms, 346 drug fragments","+- Added `get_search_terms_for_drug()` to `diagnosis_lookup.py`:","+  - Returns all Search_Terms whose drug fragments are substrings of the drug name (case-insensitive)","+  - Named differently from plan's `drug_matches_search_term()` ÔÇö returns all matches at once rather than single boolean, more practical for Phase 2","+- Updated `__all__` exports","+### Validation results:","+- Tier 1 (Code): py_compile passed, import check passed","+- Tier 2 (Data): ADALIMUMAB ÔåÆ 7 indications (including axial spondyloarthritis, rheumatoid arthritis), OMALIZUMAB ÔåÆ 4 indications (asthma, allergic asthma, etc.), PEGYLATED LIPOSOMAL DOXORUBICIN ÔåÆ 4 matches via substring, \"ADALIMUMAB 40MG\" matches correctly with dosage info, diabetes fragments combined from 2 CSV rows","+- Tier 3 (Functional): N/A (no UI changes)","+### Files changed:","+- data_processing/diagnosis_lookup.py (added load_drug_indication_mapping, get_search_terms_for_drug)","+- IMPLEMENTATION_PLAN.md (marked 1.2 subtasks [x])","+### Committed: 0779df7 \"feat: add drug-to-indication mapping from DimSearchTerm.csv (Task 1.2)\"","+### Patterns discovered:","+- DimSearchTerm.csv has 164 unique Search_Terms (not 165 as noted) because diabetes appears twice with different directorates but same Search_Term","+- Some drug fragments are very generic: INHALED, CONTINUOUS, ORAL, STANDARD-DOSE, INTRAVENOUS, PEGYLATED, ROUTINE, INDUCTION ÔÇö these will match broadly but are constrained by the GP diagnosis requirement in Phase 2","+- Function signatures for Phase 2: `get_search_terms_for_drug(drug_name, search_term_to_fragments)` returns list[str] ÔÇö use this to get candidate indications per drug","+### Next iteration should:","+- Work on Task 1.1: Update `get_patient_indication_groups()` to return ALL matches with code_frequency","+  - The current query at line ~1352 of diagnosis_lookup.py uses `QUALIFY ROW_NUMBER() OVER (PARTITION BY pc.\"PatientPseudonym\" ORDER BY pc.\"EventDateTime\" DESC) = 1` ÔÇö this must be replaced with GROUP BY + COUNT(*)","+  - Add `earliest_hcd_date` parameter to restrict GP codes to HCD data window","+  - Return columns: PatientPseudonym, Search_Term, code_frequency (not EventDateTime)","+- OR if Snowflake isn't available to test, skip to Task 2.1 (assign_drug_indications function) which can be built and tested with mock data","+### Blocked items:","+- None"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015cNQCY5kS6AhgynQ1HyuaU","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01VV9jBxvGa9b2MycLpqddkG","name":"Bash","input":{"command":"cd \"C:\\Users\\charlwoodand\\Ralph local\\Tasks\\UI Redesign\" && git add progress.txt && git commit -m \"$(cat <<'EOF'\ndocs: update progress.txt with Iteration 1 results (Task 1.2)\nEOF\n)\"","description":"Commit progress update"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1171,"cache_read_input_tokens":113088,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1171},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"ebc1a9fa-a184-4918-be59-5fbb89b5e953"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01VV9jBxvGa9b2MycLpqddkG","type":"tool_result","content":"[feature/snomed-indication-mapping c85aae4] docs: update progress.txt with Iteration 1 results (Task 1.2)\n 1 file changed, 84 insertions(+), 470 deletions(-)","is_error":false}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"27f363cf-a373-4ff9-8218-6c45ff30076c","tool_use_result":{"stdout":"[feature/snomed-indication-mapping c85aae4] docs: update progress.txt with Iteration 1 results (Task 1.2)\n 1 file changed, 84 insertions(+), 470 deletions(-)\r","stderr":"","interrupted":false,"isImage":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01NepNfJdZGi2JTGimZkSYRE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014TfTt84Ha76VZTc3ASsntp","name":"TodoWrite","input":{"todos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"completed","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"completed","activeForm":"Updating progress and committing changes"}]}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":202,"cache_read_input_tokens":114259,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":202},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"8c463b58-4d89-4df4-b23a-6f994a4d5fb4"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014TfTt84Ha76VZTc3ASsntp","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"48c41fdf-390f-4f8f-ab5c-7ffb09608a6f","tool_use_result":{"oldTodos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"completed","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"in_progress","activeForm":"Updating progress and committing changes"}],"newTodos":[{"content":"Implement Task 1.2: Build drug-to-Search_Term lookup from DimSearchTerm.csv","status":"completed","activeForm":"Implementing drug-to-Search_Term mapping functions"},{"content":"Validate: syntax check, import check, basic functionality test","status":"completed","activeForm":"Validating code compiles and works correctly"},{"content":"Update progress.txt and commit","status":"completed","activeForm":"Updating progress and committing changes"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01TPhGp1NUWGHh6rH1RRMnMv","type":"message","role":"assistant","content":[{"type":"text","text":"**Iteration 1 complete.**\n\n**Summary:**\n- **Task 1.2** ÔÇö Build drug-to-Search_Term lookup from DimSearchTerm.csv ÔÇö DONE\n- Added `load_drug_indication_mapping()` and `get_search_terms_for_drug()` to `diagnosis_lookup.py`\n- 164 Search_Terms, 346 drug fragments loaded\n- Substring matching verified: ADALIMUMAB ÔåÆ 7 indications, OMALIZUMAB ÔåÆ 4, PEGYLATED LIPOSOMAL DOXORUBICIN ÔåÆ 4\n- Committed as `0779df7`\n\n**Next iteration should:** Work on Task 1.1 (update Snowflake query to return ALL matches with code_frequency) or Task 2.1 (assign_drug_indications function) if Snowflake isn't available for testing."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":218,"cache_read_input_tokens":114461,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":218},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","uuid":"28cf850a-4b2e-4dae-8b49-8105446099ba"}
{"type":"result","subtype":"success","is_error":false,"duration_ms":222207,"duration_api_ms":199481,"num_turns":22,"result":"**Iteration 1 complete.**\n\n**Summary:**\n- **Task 1.2** ÔÇö Build drug-to-Search_Term lookup from DimSearchTerm.csv ÔÇö DONE\n- Added `load_drug_indication_mapping()` and `get_search_terms_for_drug()` to `diagnosis_lookup.py`\n- 164 Search_Terms, 346 drug fragments loaded\n- Substring matching verified: ADALIMUMAB ÔåÆ 7 indications, OMALIZUMAB ÔåÆ 4, PEGYLATED LIPOSOMAL DOXORUBICIN ÔåÆ 4\n- Committed as `0779df7`\n\n**Next iteration should:** Work on Task 1.1 (update Snowflake query to return ALL matches with code_frequency) or Task 2.1 (assign_drug_indications function) if Snowflake isn't available for testing.","stop_reason":null,"session_id":"50d8895c-a9a4-4ad0-9690-37ae4e036ed7","total_cost_usd":1.8441917500000002,"usage":{"input_tokens":5978,"cache_creation_input_tokens":114679,"cache_read_input_tokens":1800784,"output_tokens":7444,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":114679,"ephemeral_5m_input_tokens":0}},"modelUsage":{"claude-opus-4-6":{"inputTokens":5978,"outputTokens":7444,"cacheReadInputTokens":1800784,"cacheCreationInputTokens":114679,"webSearchRequests":0,"costUSD":1.8331257499999998,"contextWindow":200000,"maxOutputTokens":32000},"claude-haiku-4-5-20251001":{"inputTokens":9666,"outputTokens":280,"cacheReadInputTokens":0,"cacheCreationInputTokens":0,"webSearchRequests":0,"costUSD":0.011066,"contextWindow":200000,"maxOutputTokens":64000}},"permission_denials":[],"uuid":"ed78b671-d682-48ca-a642-c4903ac68257"}
